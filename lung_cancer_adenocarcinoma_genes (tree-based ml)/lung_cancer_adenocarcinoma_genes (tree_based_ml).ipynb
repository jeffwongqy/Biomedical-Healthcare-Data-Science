{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Predictive Modeling of Lung Cancer Adenocarcinoma Genes Using Tree-Based Approaches**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Project Background**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lung cancer** remains one of the most prevalent and lethal forms of cancer worldwide, with adenocarcinoma being its most common subtype. Despite advancements in treatment, the prognosis for lung adenocarcinoma patients often remains poor due to late-stage diagnoses and limited understanding of the molecular mechanisms driving the disease.\n",
    "\n",
    "Recent breakthroughs in genomic sequencing have provided researchers with vast amounts of data on the genetic alterations associated with lung adenocarcinoma. However, the complexity and heterogeneity of these genomic profiles present significant challenges in identifying key genes and pathways involved in the development and progression of the disease.\n",
    "\n",
    "In this context, predictive modeling techniques offer a promising approach to uncovering the genetic signatures underlying lung adenocarcinoma. By leveraging tree-based approaches, such as decision trees, random forests, and gradient boosting machines, researchers can analyze large-scale genomic datasets to identify biomarkers, molecular pathways, and potential therapeutic targets with greater accuracy and efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Project Objectives**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The primary objective of this project is to develop and validate predictive models for identifying key genes associated with lung adenocarcinoma using tree-based approaches. Specifically, the project aims to:\n",
    "\n",
    "**1. Data Collection and Preprocessing:** Gather comprehensive genomic datasets, including gene expression profiles, somatic mutations, copy number variations, and clinical data, from public repositories and research cohorts. Preprocess the data to remove noise, correct for batch effects, and standardize features for compatibility with tree-based algorithms.\n",
    "\n",
    "**2. Feature Selection and Model Training:** Employ various tree-based algorithms, such as decision trees, random forests, and gradient boosting machines, to select informative features and build predictive models. Explore different parameter settings and ensemble techniques to optimize model performance and generalization across diverse datasets.\n",
    "\n",
    "**3. Model Evaluation and Interpretation:** Assess the predictive accuracy, robustness, and generalizability of the developed models using cross-validation, independent validation cohorts, and performance metrics such as area under the receiver operating characteristic curve (AUC-ROC) and precision-recall curve. Interpret the models to identify key genes, molecular pathways, and biological insights underlying lung adenocarcinoma progression.\n",
    "\n",
    "**4. Clinical Translation and Validation:** Validate the predictive models in clinical settings using patient-derived samples and real-world data. Evaluate the models' utility in predicting patient outcomes, treatment response, and disease prognosis, and assess their potential for guiding personalized therapeutic interventions and clinical decision-making."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jeffr\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix, roc_curve, make_scorer, f1_score, accuracy_score, balanced_accuracy_score\n",
    "from imblearn.combine import SMOTETomek\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier, AdaBoostClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Collection**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collected data from BARRA:CuRDa (https://sbcb.inf.ufrgs.br/barracurda) is to utilize a curated RNA-seq database specifically tailored for cancer research, ensuring high-quality and relevant genomic data for analysis and modeling in the context of lung cancer adenocarcinoma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>class</th>\n",
       "      <th>ENSG00000000003</th>\n",
       "      <th>ENSG00000000005</th>\n",
       "      <th>ENSG00000000419</th>\n",
       "      <th>ENSG00000000457</th>\n",
       "      <th>ENSG00000000460</th>\n",
       "      <th>ENSG00000000938</th>\n",
       "      <th>ENSG00000000971</th>\n",
       "      <th>ENSG00000001036</th>\n",
       "      <th>...</th>\n",
       "      <th>ENSG00000285985</th>\n",
       "      <th>ENSG00000285986</th>\n",
       "      <th>ENSG00000285987</th>\n",
       "      <th>ENSG00000285988</th>\n",
       "      <th>ENSG00000285989</th>\n",
       "      <th>ENSG00000285990</th>\n",
       "      <th>ENSG00000285991</th>\n",
       "      <th>ENSG00000285992</th>\n",
       "      <th>ENSG00000285993</th>\n",
       "      <th>ENSG00000285994</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SRR4296063</td>\n",
       "      <td>Normal</td>\n",
       "      <td>10.728260</td>\n",
       "      <td>4.668142</td>\n",
       "      <td>10.278195</td>\n",
       "      <td>10.184036</td>\n",
       "      <td>8.215333</td>\n",
       "      <td>11.310861</td>\n",
       "      <td>13.178872</td>\n",
       "      <td>11.469473</td>\n",
       "      <td>...</td>\n",
       "      <td>2.329988</td>\n",
       "      <td>2.329988</td>\n",
       "      <td>2.329988</td>\n",
       "      <td>2.329988</td>\n",
       "      <td>2.329988</td>\n",
       "      <td>2.329988</td>\n",
       "      <td>4.877783</td>\n",
       "      <td>2.329988</td>\n",
       "      <td>2.916440</td>\n",
       "      <td>3.332160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SRR4296064</td>\n",
       "      <td>Tumor</td>\n",
       "      <td>11.332606</td>\n",
       "      <td>2.329988</td>\n",
       "      <td>10.127734</td>\n",
       "      <td>10.167900</td>\n",
       "      <td>8.174060</td>\n",
       "      <td>10.399611</td>\n",
       "      <td>13.208972</td>\n",
       "      <td>11.510862</td>\n",
       "      <td>...</td>\n",
       "      <td>2.329988</td>\n",
       "      <td>2.329988</td>\n",
       "      <td>2.931826</td>\n",
       "      <td>2.329988</td>\n",
       "      <td>2.329988</td>\n",
       "      <td>3.375017</td>\n",
       "      <td>4.644066</td>\n",
       "      <td>2.329988</td>\n",
       "      <td>2.329988</td>\n",
       "      <td>3.509185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SRR4296065</td>\n",
       "      <td>Normal</td>\n",
       "      <td>9.951182</td>\n",
       "      <td>4.264426</td>\n",
       "      <td>10.288874</td>\n",
       "      <td>10.093258</td>\n",
       "      <td>8.011385</td>\n",
       "      <td>11.814572</td>\n",
       "      <td>14.038661</td>\n",
       "      <td>11.651766</td>\n",
       "      <td>...</td>\n",
       "      <td>2.329988</td>\n",
       "      <td>2.329988</td>\n",
       "      <td>2.931948</td>\n",
       "      <td>2.329988</td>\n",
       "      <td>2.329988</td>\n",
       "      <td>2.329988</td>\n",
       "      <td>5.169625</td>\n",
       "      <td>2.932519</td>\n",
       "      <td>2.329988</td>\n",
       "      <td>3.640437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SRR4296066</td>\n",
       "      <td>Tumor</td>\n",
       "      <td>12.185680</td>\n",
       "      <td>2.798643</td>\n",
       "      <td>10.178582</td>\n",
       "      <td>10.401606</td>\n",
       "      <td>8.902321</td>\n",
       "      <td>10.294009</td>\n",
       "      <td>13.170466</td>\n",
       "      <td>11.546855</td>\n",
       "      <td>...</td>\n",
       "      <td>2.329988</td>\n",
       "      <td>2.329988</td>\n",
       "      <td>3.397771</td>\n",
       "      <td>2.329988</td>\n",
       "      <td>2.329988</td>\n",
       "      <td>2.874488</td>\n",
       "      <td>4.548259</td>\n",
       "      <td>2.329988</td>\n",
       "      <td>2.329988</td>\n",
       "      <td>3.720906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SRR4296067</td>\n",
       "      <td>Normal</td>\n",
       "      <td>9.875179</td>\n",
       "      <td>2.922071</td>\n",
       "      <td>10.444479</td>\n",
       "      <td>10.435843</td>\n",
       "      <td>8.692961</td>\n",
       "      <td>12.604934</td>\n",
       "      <td>13.538341</td>\n",
       "      <td>11.733252</td>\n",
       "      <td>...</td>\n",
       "      <td>2.329988</td>\n",
       "      <td>2.329988</td>\n",
       "      <td>2.329988</td>\n",
       "      <td>2.329988</td>\n",
       "      <td>2.329988</td>\n",
       "      <td>2.329988</td>\n",
       "      <td>4.055185</td>\n",
       "      <td>2.329988</td>\n",
       "      <td>3.015702</td>\n",
       "      <td>4.348411</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58737 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID    class  ENSG00000000003  ENSG00000000005  ENSG00000000419  \\\n",
       "0  SRR4296063   Normal        10.728260         4.668142        10.278195   \n",
       "1  SRR4296064    Tumor        11.332606         2.329988        10.127734   \n",
       "2  SRR4296065   Normal         9.951182         4.264426        10.288874   \n",
       "3  SRR4296066    Tumor        12.185680         2.798643        10.178582   \n",
       "4  SRR4296067   Normal         9.875179         2.922071        10.444479   \n",
       "\n",
       "   ENSG00000000457  ENSG00000000460  ENSG00000000938  ENSG00000000971  \\\n",
       "0        10.184036         8.215333        11.310861        13.178872   \n",
       "1        10.167900         8.174060        10.399611        13.208972   \n",
       "2        10.093258         8.011385        11.814572        14.038661   \n",
       "3        10.401606         8.902321        10.294009        13.170466   \n",
       "4        10.435843         8.692961        12.604934        13.538341   \n",
       "\n",
       "   ENSG00000001036  ...  ENSG00000285985  ENSG00000285986  ENSG00000285987  \\\n",
       "0        11.469473  ...         2.329988         2.329988         2.329988   \n",
       "1        11.510862  ...         2.329988         2.329988         2.931826   \n",
       "2        11.651766  ...         2.329988         2.329988         2.931948   \n",
       "3        11.546855  ...         2.329988         2.329988         3.397771   \n",
       "4        11.733252  ...         2.329988         2.329988         2.329988   \n",
       "\n",
       "   ENSG00000285988  ENSG00000285989  ENSG00000285990  ENSG00000285991  \\\n",
       "0         2.329988         2.329988         2.329988         4.877783   \n",
       "1         2.329988         2.329988         3.375017         4.644066   \n",
       "2         2.329988         2.329988         2.329988         5.169625   \n",
       "3         2.329988         2.329988         2.874488         4.548259   \n",
       "4         2.329988         2.329988         2.329988         4.055185   \n",
       "\n",
       "   ENSG00000285992  ENSG00000285993  ENSG00000285994  \n",
       "0         2.329988         2.916440         3.332160  \n",
       "1         2.329988         2.329988         3.509185  \n",
       "2         2.932519         2.329988         3.640437  \n",
       "3         2.329988         2.329988         3.720906  \n",
       "4         2.329988         3.015702         4.348411  \n",
       "\n",
       "[5 rows x 58737 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the data file \n",
    "lung_df1 = pd.read_csv(\"GSE87340.csv\")\n",
    "# display the first five rows\n",
    "lung_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>class</th>\n",
       "      <th>ENSG00000000003</th>\n",
       "      <th>ENSG00000000005</th>\n",
       "      <th>ENSG00000000419</th>\n",
       "      <th>ENSG00000000457</th>\n",
       "      <th>ENSG00000000460</th>\n",
       "      <th>ENSG00000000938</th>\n",
       "      <th>ENSG00000000971</th>\n",
       "      <th>ENSG00000001036</th>\n",
       "      <th>...</th>\n",
       "      <th>ENSG00000285985</th>\n",
       "      <th>ENSG00000285986</th>\n",
       "      <th>ENSG00000285987</th>\n",
       "      <th>ENSG00000285988</th>\n",
       "      <th>ENSG00000285989</th>\n",
       "      <th>ENSG00000285990</th>\n",
       "      <th>ENSG00000285991</th>\n",
       "      <th>ENSG00000285992</th>\n",
       "      <th>ENSG00000285993</th>\n",
       "      <th>ENSG00000285994</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SRR1797218</td>\n",
       "      <td>Normal</td>\n",
       "      <td>6.423093</td>\n",
       "      <td>5.179930</td>\n",
       "      <td>4.879843</td>\n",
       "      <td>5.839890</td>\n",
       "      <td>6.078415</td>\n",
       "      <td>5.756283</td>\n",
       "      <td>7.812003</td>\n",
       "      <td>4.843385</td>\n",
       "      <td>...</td>\n",
       "      <td>3.708941</td>\n",
       "      <td>3.708941</td>\n",
       "      <td>3.708941</td>\n",
       "      <td>3.708941</td>\n",
       "      <td>3.708941</td>\n",
       "      <td>4.503814</td>\n",
       "      <td>4.234924</td>\n",
       "      <td>3.708941</td>\n",
       "      <td>3.708941</td>\n",
       "      <td>7.019053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SRR1797219</td>\n",
       "      <td>Normal</td>\n",
       "      <td>4.991914</td>\n",
       "      <td>3.708941</td>\n",
       "      <td>5.139865</td>\n",
       "      <td>6.831926</td>\n",
       "      <td>6.183066</td>\n",
       "      <td>7.655465</td>\n",
       "      <td>7.749852</td>\n",
       "      <td>5.723944</td>\n",
       "      <td>...</td>\n",
       "      <td>3.708941</td>\n",
       "      <td>3.708941</td>\n",
       "      <td>3.708941</td>\n",
       "      <td>3.708941</td>\n",
       "      <td>3.708941</td>\n",
       "      <td>3.708941</td>\n",
       "      <td>3.708941</td>\n",
       "      <td>3.708941</td>\n",
       "      <td>3.708941</td>\n",
       "      <td>6.746602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SRR1797220</td>\n",
       "      <td>Normal</td>\n",
       "      <td>5.378521</td>\n",
       "      <td>5.294450</td>\n",
       "      <td>4.884195</td>\n",
       "      <td>5.225706</td>\n",
       "      <td>4.682815</td>\n",
       "      <td>7.423949</td>\n",
       "      <td>8.258191</td>\n",
       "      <td>4.992560</td>\n",
       "      <td>...</td>\n",
       "      <td>3.708941</td>\n",
       "      <td>3.708941</td>\n",
       "      <td>4.439132</td>\n",
       "      <td>3.708941</td>\n",
       "      <td>3.708941</td>\n",
       "      <td>5.036719</td>\n",
       "      <td>3.708941</td>\n",
       "      <td>3.708941</td>\n",
       "      <td>3.708941</td>\n",
       "      <td>6.828835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SRR1797221</td>\n",
       "      <td>Normal</td>\n",
       "      <td>4.998041</td>\n",
       "      <td>6.188281</td>\n",
       "      <td>3.708941</td>\n",
       "      <td>3.708941</td>\n",
       "      <td>3.708941</td>\n",
       "      <td>7.466507</td>\n",
       "      <td>6.917176</td>\n",
       "      <td>3.708941</td>\n",
       "      <td>...</td>\n",
       "      <td>3.708941</td>\n",
       "      <td>3.708941</td>\n",
       "      <td>3.708941</td>\n",
       "      <td>3.708941</td>\n",
       "      <td>3.708941</td>\n",
       "      <td>3.708941</td>\n",
       "      <td>3.708941</td>\n",
       "      <td>3.708941</td>\n",
       "      <td>5.864157</td>\n",
       "      <td>3.708941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SRR1797222</td>\n",
       "      <td>Normal</td>\n",
       "      <td>5.273318</td>\n",
       "      <td>3.708941</td>\n",
       "      <td>4.950478</td>\n",
       "      <td>6.412278</td>\n",
       "      <td>5.956615</td>\n",
       "      <td>6.924628</td>\n",
       "      <td>7.095977</td>\n",
       "      <td>5.142353</td>\n",
       "      <td>...</td>\n",
       "      <td>3.708941</td>\n",
       "      <td>3.708941</td>\n",
       "      <td>3.708941</td>\n",
       "      <td>3.708941</td>\n",
       "      <td>3.708941</td>\n",
       "      <td>3.708941</td>\n",
       "      <td>4.661041</td>\n",
       "      <td>3.708941</td>\n",
       "      <td>4.788796</td>\n",
       "      <td>5.063567</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58737 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID    class  ENSG00000000003  ENSG00000000005  ENSG00000000419  \\\n",
       "0  SRR1797218   Normal         6.423093         5.179930         4.879843   \n",
       "1  SRR1797219   Normal         4.991914         3.708941         5.139865   \n",
       "2  SRR1797220   Normal         5.378521         5.294450         4.884195   \n",
       "3  SRR1797221   Normal         4.998041         6.188281         3.708941   \n",
       "4  SRR1797222   Normal         5.273318         3.708941         4.950478   \n",
       "\n",
       "   ENSG00000000457  ENSG00000000460  ENSG00000000938  ENSG00000000971  \\\n",
       "0         5.839890         6.078415         5.756283         7.812003   \n",
       "1         6.831926         6.183066         7.655465         7.749852   \n",
       "2         5.225706         4.682815         7.423949         8.258191   \n",
       "3         3.708941         3.708941         7.466507         6.917176   \n",
       "4         6.412278         5.956615         6.924628         7.095977   \n",
       "\n",
       "   ENSG00000001036  ...  ENSG00000285985  ENSG00000285986  ENSG00000285987  \\\n",
       "0         4.843385  ...         3.708941         3.708941         3.708941   \n",
       "1         5.723944  ...         3.708941         3.708941         3.708941   \n",
       "2         4.992560  ...         3.708941         3.708941         4.439132   \n",
       "3         3.708941  ...         3.708941         3.708941         3.708941   \n",
       "4         5.142353  ...         3.708941         3.708941         3.708941   \n",
       "\n",
       "   ENSG00000285988  ENSG00000285989  ENSG00000285990  ENSG00000285991  \\\n",
       "0         3.708941         3.708941         4.503814         4.234924   \n",
       "1         3.708941         3.708941         3.708941         3.708941   \n",
       "2         3.708941         3.708941         5.036719         3.708941   \n",
       "3         3.708941         3.708941         3.708941         3.708941   \n",
       "4         3.708941         3.708941         3.708941         4.661041   \n",
       "\n",
       "   ENSG00000285992  ENSG00000285993  ENSG00000285994  \n",
       "0         3.708941         3.708941         7.019053  \n",
       "1         3.708941         3.708941         6.746602  \n",
       "2         3.708941         3.708941         6.828835  \n",
       "3         3.708941         5.864157         3.708941  \n",
       "4         3.708941         4.788796         5.063567  \n",
       "\n",
       "[5 rows x 58737 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the data file \n",
    "lung_df2 = pd.read_csv(\"GSE60052.csv\")\n",
    "# display the first five rows\n",
    "lung_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>class</th>\n",
       "      <th>ENSG00000000003</th>\n",
       "      <th>ENSG00000000005</th>\n",
       "      <th>ENSG00000000419</th>\n",
       "      <th>ENSG00000000457</th>\n",
       "      <th>ENSG00000000460</th>\n",
       "      <th>ENSG00000000938</th>\n",
       "      <th>ENSG00000000971</th>\n",
       "      <th>ENSG00000001036</th>\n",
       "      <th>...</th>\n",
       "      <th>ENSG00000285985</th>\n",
       "      <th>ENSG00000285986</th>\n",
       "      <th>ENSG00000285987</th>\n",
       "      <th>ENSG00000285988</th>\n",
       "      <th>ENSG00000285989</th>\n",
       "      <th>ENSG00000285990</th>\n",
       "      <th>ENSG00000285991</th>\n",
       "      <th>ENSG00000285992</th>\n",
       "      <th>ENSG00000285993</th>\n",
       "      <th>ENSG00000285994</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GSM993606</td>\n",
       "      <td>Tumor</td>\n",
       "      <td>10.568931</td>\n",
       "      <td>3.114310</td>\n",
       "      <td>8.704112</td>\n",
       "      <td>9.130016</td>\n",
       "      <td>8.241592</td>\n",
       "      <td>8.387981</td>\n",
       "      <td>11.490738</td>\n",
       "      <td>10.444113</td>\n",
       "      <td>...</td>\n",
       "      <td>2.531043</td>\n",
       "      <td>2.531043</td>\n",
       "      <td>2.531043</td>\n",
       "      <td>2.531043</td>\n",
       "      <td>2.531043</td>\n",
       "      <td>2.531043</td>\n",
       "      <td>4.229406</td>\n",
       "      <td>2.531043</td>\n",
       "      <td>2.531043</td>\n",
       "      <td>3.475839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GSM993607</td>\n",
       "      <td>Tumor</td>\n",
       "      <td>8.888400</td>\n",
       "      <td>2.531043</td>\n",
       "      <td>8.821358</td>\n",
       "      <td>9.133383</td>\n",
       "      <td>7.566570</td>\n",
       "      <td>10.956587</td>\n",
       "      <td>11.556373</td>\n",
       "      <td>10.689391</td>\n",
       "      <td>...</td>\n",
       "      <td>2.531043</td>\n",
       "      <td>2.531043</td>\n",
       "      <td>2.531043</td>\n",
       "      <td>2.531043</td>\n",
       "      <td>2.531043</td>\n",
       "      <td>2.531043</td>\n",
       "      <td>4.122718</td>\n",
       "      <td>2.531043</td>\n",
       "      <td>3.121964</td>\n",
       "      <td>3.536063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GSM993608</td>\n",
       "      <td>Tumor</td>\n",
       "      <td>9.709469</td>\n",
       "      <td>2.531043</td>\n",
       "      <td>9.733217</td>\n",
       "      <td>9.022464</td>\n",
       "      <td>7.090320</td>\n",
       "      <td>9.638268</td>\n",
       "      <td>11.774856</td>\n",
       "      <td>10.406903</td>\n",
       "      <td>...</td>\n",
       "      <td>2.531043</td>\n",
       "      <td>2.531043</td>\n",
       "      <td>2.531043</td>\n",
       "      <td>2.531043</td>\n",
       "      <td>2.531043</td>\n",
       "      <td>2.531043</td>\n",
       "      <td>2.531043</td>\n",
       "      <td>2.531043</td>\n",
       "      <td>2.531043</td>\n",
       "      <td>3.784356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GSM993610</td>\n",
       "      <td>Tumor</td>\n",
       "      <td>12.259593</td>\n",
       "      <td>2.531043</td>\n",
       "      <td>10.030434</td>\n",
       "      <td>9.160498</td>\n",
       "      <td>8.252846</td>\n",
       "      <td>6.701692</td>\n",
       "      <td>9.804658</td>\n",
       "      <td>11.217979</td>\n",
       "      <td>...</td>\n",
       "      <td>2.531043</td>\n",
       "      <td>2.531043</td>\n",
       "      <td>2.531043</td>\n",
       "      <td>2.531043</td>\n",
       "      <td>2.531043</td>\n",
       "      <td>2.531043</td>\n",
       "      <td>2.531043</td>\n",
       "      <td>2.531043</td>\n",
       "      <td>2.531043</td>\n",
       "      <td>3.201240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GSM993611</td>\n",
       "      <td>Tumor</td>\n",
       "      <td>9.039147</td>\n",
       "      <td>2.531043</td>\n",
       "      <td>8.983013</td>\n",
       "      <td>8.665050</td>\n",
       "      <td>7.030950</td>\n",
       "      <td>9.629136</td>\n",
       "      <td>11.975530</td>\n",
       "      <td>10.607398</td>\n",
       "      <td>...</td>\n",
       "      <td>2.531043</td>\n",
       "      <td>2.531043</td>\n",
       "      <td>2.531043</td>\n",
       "      <td>2.531043</td>\n",
       "      <td>2.531043</td>\n",
       "      <td>2.531043</td>\n",
       "      <td>2.531043</td>\n",
       "      <td>2.531043</td>\n",
       "      <td>2.531043</td>\n",
       "      <td>3.649756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58737 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID   class  ENSG00000000003  ENSG00000000005  ENSG00000000419  \\\n",
       "0  GSM993606   Tumor        10.568931         3.114310         8.704112   \n",
       "1  GSM993607   Tumor         8.888400         2.531043         8.821358   \n",
       "2  GSM993608   Tumor         9.709469         2.531043         9.733217   \n",
       "3  GSM993610   Tumor        12.259593         2.531043        10.030434   \n",
       "4  GSM993611   Tumor         9.039147         2.531043         8.983013   \n",
       "\n",
       "   ENSG00000000457  ENSG00000000460  ENSG00000000938  ENSG00000000971  \\\n",
       "0         9.130016         8.241592         8.387981        11.490738   \n",
       "1         9.133383         7.566570        10.956587        11.556373   \n",
       "2         9.022464         7.090320         9.638268        11.774856   \n",
       "3         9.160498         8.252846         6.701692         9.804658   \n",
       "4         8.665050         7.030950         9.629136        11.975530   \n",
       "\n",
       "   ENSG00000001036  ...  ENSG00000285985  ENSG00000285986  ENSG00000285987  \\\n",
       "0        10.444113  ...         2.531043         2.531043         2.531043   \n",
       "1        10.689391  ...         2.531043         2.531043         2.531043   \n",
       "2        10.406903  ...         2.531043         2.531043         2.531043   \n",
       "3        11.217979  ...         2.531043         2.531043         2.531043   \n",
       "4        10.607398  ...         2.531043         2.531043         2.531043   \n",
       "\n",
       "   ENSG00000285988  ENSG00000285989  ENSG00000285990  ENSG00000285991  \\\n",
       "0         2.531043         2.531043         2.531043         4.229406   \n",
       "1         2.531043         2.531043         2.531043         4.122718   \n",
       "2         2.531043         2.531043         2.531043         2.531043   \n",
       "3         2.531043         2.531043         2.531043         2.531043   \n",
       "4         2.531043         2.531043         2.531043         2.531043   \n",
       "\n",
       "   ENSG00000285992  ENSG00000285993  ENSG00000285994  \n",
       "0         2.531043         2.531043         3.475839  \n",
       "1         2.531043         3.121964         3.536063  \n",
       "2         2.531043         2.531043         3.784356  \n",
       "3         2.531043         2.531043         3.201240  \n",
       "4         2.531043         2.531043         3.649756  \n",
       "\n",
       "[5 rows x 58737 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the data file \n",
    "lung_df3 = pd.read_csv(\"GSE40419.csv\")\n",
    "# display the first five rows\n",
    "lung_df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>class</th>\n",
       "      <th>ENSG00000000003</th>\n",
       "      <th>ENSG00000000005</th>\n",
       "      <th>ENSG00000000419</th>\n",
       "      <th>ENSG00000000457</th>\n",
       "      <th>ENSG00000000460</th>\n",
       "      <th>ENSG00000000938</th>\n",
       "      <th>ENSG00000000971</th>\n",
       "      <th>ENSG00000001036</th>\n",
       "      <th>...</th>\n",
       "      <th>ENSG00000285985</th>\n",
       "      <th>ENSG00000285986</th>\n",
       "      <th>ENSG00000285987</th>\n",
       "      <th>ENSG00000285988</th>\n",
       "      <th>ENSG00000285989</th>\n",
       "      <th>ENSG00000285990</th>\n",
       "      <th>ENSG00000285991</th>\n",
       "      <th>ENSG00000285992</th>\n",
       "      <th>ENSG00000285993</th>\n",
       "      <th>ENSG00000285994</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P1N</td>\n",
       "      <td>Normal</td>\n",
       "      <td>9.869563</td>\n",
       "      <td>3.359294</td>\n",
       "      <td>9.252274</td>\n",
       "      <td>8.919576</td>\n",
       "      <td>7.394545</td>\n",
       "      <td>13.664387</td>\n",
       "      <td>13.268303</td>\n",
       "      <td>10.681938</td>\n",
       "      <td>...</td>\n",
       "      <td>2.870308</td>\n",
       "      <td>2.870308</td>\n",
       "      <td>2.870308</td>\n",
       "      <td>2.870308</td>\n",
       "      <td>2.870308</td>\n",
       "      <td>2.870308</td>\n",
       "      <td>5.276223</td>\n",
       "      <td>2.870308</td>\n",
       "      <td>2.870308</td>\n",
       "      <td>5.796883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P1T</td>\n",
       "      <td>Tumor</td>\n",
       "      <td>11.957128</td>\n",
       "      <td>2.870308</td>\n",
       "      <td>9.673054</td>\n",
       "      <td>9.994453</td>\n",
       "      <td>8.393224</td>\n",
       "      <td>9.925747</td>\n",
       "      <td>14.117760</td>\n",
       "      <td>11.041954</td>\n",
       "      <td>...</td>\n",
       "      <td>2.870308</td>\n",
       "      <td>2.870308</td>\n",
       "      <td>2.870308</td>\n",
       "      <td>2.870308</td>\n",
       "      <td>2.870308</td>\n",
       "      <td>2.870308</td>\n",
       "      <td>4.549299</td>\n",
       "      <td>3.561798</td>\n",
       "      <td>2.870308</td>\n",
       "      <td>5.341960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P3N</td>\n",
       "      <td>Normal</td>\n",
       "      <td>9.573051</td>\n",
       "      <td>3.370413</td>\n",
       "      <td>9.177268</td>\n",
       "      <td>9.279816</td>\n",
       "      <td>7.376917</td>\n",
       "      <td>11.449583</td>\n",
       "      <td>13.214280</td>\n",
       "      <td>10.657062</td>\n",
       "      <td>...</td>\n",
       "      <td>2.870308</td>\n",
       "      <td>2.870308</td>\n",
       "      <td>2.870308</td>\n",
       "      <td>2.870308</td>\n",
       "      <td>2.870308</td>\n",
       "      <td>2.870308</td>\n",
       "      <td>5.505797</td>\n",
       "      <td>2.870308</td>\n",
       "      <td>3.369478</td>\n",
       "      <td>4.640682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P3T</td>\n",
       "      <td>Tumor</td>\n",
       "      <td>11.750409</td>\n",
       "      <td>2.870308</td>\n",
       "      <td>9.178781</td>\n",
       "      <td>10.407126</td>\n",
       "      <td>8.580091</td>\n",
       "      <td>9.525149</td>\n",
       "      <td>12.777749</td>\n",
       "      <td>11.110023</td>\n",
       "      <td>...</td>\n",
       "      <td>2.870308</td>\n",
       "      <td>2.870308</td>\n",
       "      <td>2.870308</td>\n",
       "      <td>3.698260</td>\n",
       "      <td>2.870308</td>\n",
       "      <td>2.870308</td>\n",
       "      <td>5.024206</td>\n",
       "      <td>2.870308</td>\n",
       "      <td>3.545341</td>\n",
       "      <td>4.818864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P4N</td>\n",
       "      <td>Normal</td>\n",
       "      <td>9.347072</td>\n",
       "      <td>3.703784</td>\n",
       "      <td>9.021748</td>\n",
       "      <td>8.872918</td>\n",
       "      <td>7.587812</td>\n",
       "      <td>12.715550</td>\n",
       "      <td>13.486744</td>\n",
       "      <td>10.544305</td>\n",
       "      <td>...</td>\n",
       "      <td>2.870308</td>\n",
       "      <td>2.870308</td>\n",
       "      <td>2.870308</td>\n",
       "      <td>2.870308</td>\n",
       "      <td>2.870308</td>\n",
       "      <td>2.870308</td>\n",
       "      <td>4.912281</td>\n",
       "      <td>3.375706</td>\n",
       "      <td>2.870308</td>\n",
       "      <td>4.254559</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58737 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID   class  ENSG00000000003  ENSG00000000005  ENSG00000000419  \\\n",
       "0  P1N  Normal         9.869563         3.359294         9.252274   \n",
       "1  P1T   Tumor        11.957128         2.870308         9.673054   \n",
       "2  P3N  Normal         9.573051         3.370413         9.177268   \n",
       "3  P3T   Tumor        11.750409         2.870308         9.178781   \n",
       "4  P4N  Normal         9.347072         3.703784         9.021748   \n",
       "\n",
       "   ENSG00000000457  ENSG00000000460  ENSG00000000938  ENSG00000000971  \\\n",
       "0         8.919576         7.394545        13.664387        13.268303   \n",
       "1         9.994453         8.393224         9.925747        14.117760   \n",
       "2         9.279816         7.376917        11.449583        13.214280   \n",
       "3        10.407126         8.580091         9.525149        12.777749   \n",
       "4         8.872918         7.587812        12.715550        13.486744   \n",
       "\n",
       "   ENSG00000001036  ...  ENSG00000285985  ENSG00000285986  ENSG00000285987  \\\n",
       "0        10.681938  ...         2.870308         2.870308         2.870308   \n",
       "1        11.041954  ...         2.870308         2.870308         2.870308   \n",
       "2        10.657062  ...         2.870308         2.870308         2.870308   \n",
       "3        11.110023  ...         2.870308         2.870308         2.870308   \n",
       "4        10.544305  ...         2.870308         2.870308         2.870308   \n",
       "\n",
       "   ENSG00000285988  ENSG00000285989  ENSG00000285990  ENSG00000285991  \\\n",
       "0         2.870308         2.870308         2.870308         5.276223   \n",
       "1         2.870308         2.870308         2.870308         4.549299   \n",
       "2         2.870308         2.870308         2.870308         5.505797   \n",
       "3         3.698260         2.870308         2.870308         5.024206   \n",
       "4         2.870308         2.870308         2.870308         4.912281   \n",
       "\n",
       "   ENSG00000285992  ENSG00000285993  ENSG00000285994  \n",
       "0         2.870308         2.870308         5.796883  \n",
       "1         3.561798         2.870308         5.341960  \n",
       "2         2.870308         3.369478         4.640682  \n",
       "3         2.870308         3.545341         4.818864  \n",
       "4         3.375706         2.870308         4.254559  \n",
       "\n",
       "[5 rows x 58737 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the data file \n",
    "lung_df4 = pd.read_csv(\"GSE37764.csv\")\n",
    "# display the first five rows\n",
    "lung_df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>class</th>\n",
       "      <th>ENSG00000000003</th>\n",
       "      <th>ENSG00000000005</th>\n",
       "      <th>ENSG00000000419</th>\n",
       "      <th>ENSG00000000457</th>\n",
       "      <th>ENSG00000000460</th>\n",
       "      <th>ENSG00000000938</th>\n",
       "      <th>ENSG00000000971</th>\n",
       "      <th>ENSG00000001036</th>\n",
       "      <th>...</th>\n",
       "      <th>ENSG00000285985</th>\n",
       "      <th>ENSG00000285986</th>\n",
       "      <th>ENSG00000285987</th>\n",
       "      <th>ENSG00000285988</th>\n",
       "      <th>ENSG00000285989</th>\n",
       "      <th>ENSG00000285990</th>\n",
       "      <th>ENSG00000285991</th>\n",
       "      <th>ENSG00000285992</th>\n",
       "      <th>ENSG00000285993</th>\n",
       "      <th>ENSG00000285994</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SRR4296063</td>\n",
       "      <td>Normal</td>\n",
       "      <td>10.728260</td>\n",
       "      <td>4.668142</td>\n",
       "      <td>10.278195</td>\n",
       "      <td>10.184036</td>\n",
       "      <td>8.215333</td>\n",
       "      <td>11.310861</td>\n",
       "      <td>13.178872</td>\n",
       "      <td>11.469473</td>\n",
       "      <td>...</td>\n",
       "      <td>2.329988</td>\n",
       "      <td>2.329988</td>\n",
       "      <td>2.329988</td>\n",
       "      <td>2.329988</td>\n",
       "      <td>2.329988</td>\n",
       "      <td>2.329988</td>\n",
       "      <td>4.877783</td>\n",
       "      <td>2.329988</td>\n",
       "      <td>2.916440</td>\n",
       "      <td>3.332160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SRR4296064</td>\n",
       "      <td>Tumor</td>\n",
       "      <td>11.332606</td>\n",
       "      <td>2.329988</td>\n",
       "      <td>10.127734</td>\n",
       "      <td>10.167900</td>\n",
       "      <td>8.174060</td>\n",
       "      <td>10.399611</td>\n",
       "      <td>13.208972</td>\n",
       "      <td>11.510862</td>\n",
       "      <td>...</td>\n",
       "      <td>2.329988</td>\n",
       "      <td>2.329988</td>\n",
       "      <td>2.931826</td>\n",
       "      <td>2.329988</td>\n",
       "      <td>2.329988</td>\n",
       "      <td>3.375017</td>\n",
       "      <td>4.644066</td>\n",
       "      <td>2.329988</td>\n",
       "      <td>2.329988</td>\n",
       "      <td>3.509185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SRR4296065</td>\n",
       "      <td>Normal</td>\n",
       "      <td>9.951182</td>\n",
       "      <td>4.264426</td>\n",
       "      <td>10.288874</td>\n",
       "      <td>10.093258</td>\n",
       "      <td>8.011385</td>\n",
       "      <td>11.814572</td>\n",
       "      <td>14.038661</td>\n",
       "      <td>11.651766</td>\n",
       "      <td>...</td>\n",
       "      <td>2.329988</td>\n",
       "      <td>2.329988</td>\n",
       "      <td>2.931948</td>\n",
       "      <td>2.329988</td>\n",
       "      <td>2.329988</td>\n",
       "      <td>2.329988</td>\n",
       "      <td>5.169625</td>\n",
       "      <td>2.932519</td>\n",
       "      <td>2.329988</td>\n",
       "      <td>3.640437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SRR4296066</td>\n",
       "      <td>Tumor</td>\n",
       "      <td>12.185680</td>\n",
       "      <td>2.798643</td>\n",
       "      <td>10.178582</td>\n",
       "      <td>10.401606</td>\n",
       "      <td>8.902321</td>\n",
       "      <td>10.294009</td>\n",
       "      <td>13.170466</td>\n",
       "      <td>11.546855</td>\n",
       "      <td>...</td>\n",
       "      <td>2.329988</td>\n",
       "      <td>2.329988</td>\n",
       "      <td>3.397771</td>\n",
       "      <td>2.329988</td>\n",
       "      <td>2.329988</td>\n",
       "      <td>2.874488</td>\n",
       "      <td>4.548259</td>\n",
       "      <td>2.329988</td>\n",
       "      <td>2.329988</td>\n",
       "      <td>3.720906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SRR4296067</td>\n",
       "      <td>Normal</td>\n",
       "      <td>9.875179</td>\n",
       "      <td>2.922071</td>\n",
       "      <td>10.444479</td>\n",
       "      <td>10.435843</td>\n",
       "      <td>8.692961</td>\n",
       "      <td>12.604934</td>\n",
       "      <td>13.538341</td>\n",
       "      <td>11.733252</td>\n",
       "      <td>...</td>\n",
       "      <td>2.329988</td>\n",
       "      <td>2.329988</td>\n",
       "      <td>2.329988</td>\n",
       "      <td>2.329988</td>\n",
       "      <td>2.329988</td>\n",
       "      <td>2.329988</td>\n",
       "      <td>4.055185</td>\n",
       "      <td>2.329988</td>\n",
       "      <td>3.015702</td>\n",
       "      <td>4.348411</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58737 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID    class  ENSG00000000003  ENSG00000000005  ENSG00000000419  \\\n",
       "0  SRR4296063   Normal        10.728260         4.668142        10.278195   \n",
       "1  SRR4296064    Tumor        11.332606         2.329988        10.127734   \n",
       "2  SRR4296065   Normal         9.951182         4.264426        10.288874   \n",
       "3  SRR4296066    Tumor        12.185680         2.798643        10.178582   \n",
       "4  SRR4296067   Normal         9.875179         2.922071        10.444479   \n",
       "\n",
       "   ENSG00000000457  ENSG00000000460  ENSG00000000938  ENSG00000000971  \\\n",
       "0        10.184036         8.215333        11.310861        13.178872   \n",
       "1        10.167900         8.174060        10.399611        13.208972   \n",
       "2        10.093258         8.011385        11.814572        14.038661   \n",
       "3        10.401606         8.902321        10.294009        13.170466   \n",
       "4        10.435843         8.692961        12.604934        13.538341   \n",
       "\n",
       "   ENSG00000001036  ...  ENSG00000285985  ENSG00000285986  ENSG00000285987  \\\n",
       "0        11.469473  ...         2.329988         2.329988         2.329988   \n",
       "1        11.510862  ...         2.329988         2.329988         2.931826   \n",
       "2        11.651766  ...         2.329988         2.329988         2.931948   \n",
       "3        11.546855  ...         2.329988         2.329988         3.397771   \n",
       "4        11.733252  ...         2.329988         2.329988         2.329988   \n",
       "\n",
       "   ENSG00000285988  ENSG00000285989  ENSG00000285990  ENSG00000285991  \\\n",
       "0         2.329988         2.329988         2.329988         4.877783   \n",
       "1         2.329988         2.329988         3.375017         4.644066   \n",
       "2         2.329988         2.329988         2.329988         5.169625   \n",
       "3         2.329988         2.329988         2.874488         4.548259   \n",
       "4         2.329988         2.329988         2.329988         4.055185   \n",
       "\n",
       "   ENSG00000285992  ENSG00000285993  ENSG00000285994  \n",
       "0         2.329988         2.916440         3.332160  \n",
       "1         2.329988         2.329988         3.509185  \n",
       "2         2.932519         2.329988         3.640437  \n",
       "3         2.329988         2.329988         3.720906  \n",
       "4         2.329988         3.015702         4.348411  \n",
       "\n",
       "[5 rows x 58737 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenate them into a single dataframe\n",
    "lung_df1_4 = pd.concat([lung_df1, lung_df2, lung_df3, lung_df4])\n",
    "\n",
    "# view the first five rows \n",
    "lung_df1_4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 313 entries, 0 to 11\n",
      "Columns: 58737 entries, ID to ENSG00000285994\n",
      "dtypes: float64(58735), object(2)\n",
      "memory usage: 140.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# display the data information \n",
    "lung_df1_4.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Select first 50 columns for analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting the first 50 columns for analysis instead of 50000+ columns is to reduce computational complexity while focusing on the most relevant features for initial exploration and modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>class</th>\n",
       "      <th>ENSG00000000003</th>\n",
       "      <th>ENSG00000000005</th>\n",
       "      <th>ENSG00000000419</th>\n",
       "      <th>ENSG00000000457</th>\n",
       "      <th>ENSG00000000460</th>\n",
       "      <th>ENSG00000000938</th>\n",
       "      <th>ENSG00000000971</th>\n",
       "      <th>ENSG00000001036</th>\n",
       "      <th>...</th>\n",
       "      <th>ENSG00000003400</th>\n",
       "      <th>ENSG00000003402</th>\n",
       "      <th>ENSG00000003436</th>\n",
       "      <th>ENSG00000003509</th>\n",
       "      <th>ENSG00000003756</th>\n",
       "      <th>ENSG00000003987</th>\n",
       "      <th>ENSG00000003989</th>\n",
       "      <th>ENSG00000004059</th>\n",
       "      <th>ENSG00000004139</th>\n",
       "      <th>ENSG00000004142</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SRR4296063</td>\n",
       "      <td>Normal</td>\n",
       "      <td>10.728260</td>\n",
       "      <td>4.668142</td>\n",
       "      <td>10.278195</td>\n",
       "      <td>10.184036</td>\n",
       "      <td>8.215333</td>\n",
       "      <td>11.310861</td>\n",
       "      <td>13.178872</td>\n",
       "      <td>11.469473</td>\n",
       "      <td>...</td>\n",
       "      <td>11.563274</td>\n",
       "      <td>14.031341</td>\n",
       "      <td>13.921061</td>\n",
       "      <td>9.047888</td>\n",
       "      <td>12.849967</td>\n",
       "      <td>7.093293</td>\n",
       "      <td>11.106861</td>\n",
       "      <td>12.031649</td>\n",
       "      <td>10.068417</td>\n",
       "      <td>11.539250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SRR4296064</td>\n",
       "      <td>Tumor</td>\n",
       "      <td>11.332606</td>\n",
       "      <td>2.329988</td>\n",
       "      <td>10.127734</td>\n",
       "      <td>10.167900</td>\n",
       "      <td>8.174060</td>\n",
       "      <td>10.399611</td>\n",
       "      <td>13.208972</td>\n",
       "      <td>11.510862</td>\n",
       "      <td>...</td>\n",
       "      <td>10.942225</td>\n",
       "      <td>13.624737</td>\n",
       "      <td>12.216945</td>\n",
       "      <td>9.030037</td>\n",
       "      <td>12.713656</td>\n",
       "      <td>7.271941</td>\n",
       "      <td>10.341599</td>\n",
       "      <td>12.258726</td>\n",
       "      <td>11.093741</td>\n",
       "      <td>12.326561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SRR4296065</td>\n",
       "      <td>Normal</td>\n",
       "      <td>9.951182</td>\n",
       "      <td>4.264426</td>\n",
       "      <td>10.288874</td>\n",
       "      <td>10.093258</td>\n",
       "      <td>8.011385</td>\n",
       "      <td>11.814572</td>\n",
       "      <td>14.038661</td>\n",
       "      <td>11.651766</td>\n",
       "      <td>...</td>\n",
       "      <td>11.264093</td>\n",
       "      <td>14.002874</td>\n",
       "      <td>13.448304</td>\n",
       "      <td>8.791654</td>\n",
       "      <td>12.640431</td>\n",
       "      <td>7.186462</td>\n",
       "      <td>11.662027</td>\n",
       "      <td>12.014045</td>\n",
       "      <td>10.590986</td>\n",
       "      <td>11.596168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SRR4296066</td>\n",
       "      <td>Tumor</td>\n",
       "      <td>12.185680</td>\n",
       "      <td>2.798643</td>\n",
       "      <td>10.178582</td>\n",
       "      <td>10.401606</td>\n",
       "      <td>8.902321</td>\n",
       "      <td>10.294009</td>\n",
       "      <td>13.170466</td>\n",
       "      <td>11.546855</td>\n",
       "      <td>...</td>\n",
       "      <td>11.789080</td>\n",
       "      <td>14.323343</td>\n",
       "      <td>14.607221</td>\n",
       "      <td>9.073890</td>\n",
       "      <td>12.484788</td>\n",
       "      <td>5.721430</td>\n",
       "      <td>9.344144</td>\n",
       "      <td>12.381636</td>\n",
       "      <td>9.843834</td>\n",
       "      <td>12.292631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SRR4296067</td>\n",
       "      <td>Normal</td>\n",
       "      <td>9.875179</td>\n",
       "      <td>2.922071</td>\n",
       "      <td>10.444479</td>\n",
       "      <td>10.435843</td>\n",
       "      <td>8.692961</td>\n",
       "      <td>12.604934</td>\n",
       "      <td>13.538341</td>\n",
       "      <td>11.733252</td>\n",
       "      <td>...</td>\n",
       "      <td>11.595322</td>\n",
       "      <td>14.816656</td>\n",
       "      <td>13.249358</td>\n",
       "      <td>9.212233</td>\n",
       "      <td>12.641647</td>\n",
       "      <td>6.880581</td>\n",
       "      <td>10.841791</td>\n",
       "      <td>11.996772</td>\n",
       "      <td>10.287463</td>\n",
       "      <td>11.712016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID    class  ENSG00000000003  ENSG00000000005  ENSG00000000419  \\\n",
       "0  SRR4296063   Normal        10.728260         4.668142        10.278195   \n",
       "1  SRR4296064    Tumor        11.332606         2.329988        10.127734   \n",
       "2  SRR4296065   Normal         9.951182         4.264426        10.288874   \n",
       "3  SRR4296066    Tumor        12.185680         2.798643        10.178582   \n",
       "4  SRR4296067   Normal         9.875179         2.922071        10.444479   \n",
       "\n",
       "   ENSG00000000457  ENSG00000000460  ENSG00000000938  ENSG00000000971  \\\n",
       "0        10.184036         8.215333        11.310861        13.178872   \n",
       "1        10.167900         8.174060        10.399611        13.208972   \n",
       "2        10.093258         8.011385        11.814572        14.038661   \n",
       "3        10.401606         8.902321        10.294009        13.170466   \n",
       "4        10.435843         8.692961        12.604934        13.538341   \n",
       "\n",
       "   ENSG00000001036  ...  ENSG00000003400  ENSG00000003402  ENSG00000003436  \\\n",
       "0        11.469473  ...        11.563274        14.031341        13.921061   \n",
       "1        11.510862  ...        10.942225        13.624737        12.216945   \n",
       "2        11.651766  ...        11.264093        14.002874        13.448304   \n",
       "3        11.546855  ...        11.789080        14.323343        14.607221   \n",
       "4        11.733252  ...        11.595322        14.816656        13.249358   \n",
       "\n",
       "   ENSG00000003509  ENSG00000003756  ENSG00000003987  ENSG00000003989  \\\n",
       "0         9.047888        12.849967         7.093293        11.106861   \n",
       "1         9.030037        12.713656         7.271941        10.341599   \n",
       "2         8.791654        12.640431         7.186462        11.662027   \n",
       "3         9.073890        12.484788         5.721430         9.344144   \n",
       "4         9.212233        12.641647         6.880581        10.841791   \n",
       "\n",
       "   ENSG00000004059  ENSG00000004139  ENSG00000004142  \n",
       "0        12.031649        10.068417        11.539250  \n",
       "1        12.258726        11.093741        12.326561  \n",
       "2        12.014045        10.590986        11.596168  \n",
       "3        12.381636         9.843834        12.292631  \n",
       "4        11.996772        10.287463        11.712016  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select the first ten columns in the dataframe\n",
    "lung_df1_4 = lung_df1_4.iloc[:, :50]\n",
    "# display the first five rows\n",
    "lung_df1_4.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Check for missing values**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking missing values is to ensure data completeness and integrity for accurate analysis and modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                 0\n",
       "class              0\n",
       "ENSG00000000003    0\n",
       "ENSG00000000005    0\n",
       "ENSG00000000419    0\n",
       "ENSG00000000457    0\n",
       "ENSG00000000460    0\n",
       "ENSG00000000938    0\n",
       "ENSG00000000971    0\n",
       "ENSG00000001036    0\n",
       "ENSG00000001084    0\n",
       "ENSG00000001167    0\n",
       "ENSG00000001460    0\n",
       "ENSG00000001461    0\n",
       "ENSG00000001497    0\n",
       "ENSG00000001561    0\n",
       "ENSG00000001617    0\n",
       "ENSG00000001626    0\n",
       "ENSG00000001629    0\n",
       "ENSG00000001630    0\n",
       "ENSG00000001631    0\n",
       "ENSG00000002016    0\n",
       "ENSG00000002079    0\n",
       "ENSG00000002330    0\n",
       "ENSG00000002549    0\n",
       "ENSG00000002586    0\n",
       "ENSG00000002587    0\n",
       "ENSG00000002726    0\n",
       "ENSG00000002745    0\n",
       "ENSG00000002746    0\n",
       "ENSG00000002822    0\n",
       "ENSG00000002834    0\n",
       "ENSG00000002919    0\n",
       "ENSG00000002933    0\n",
       "ENSG00000003056    0\n",
       "ENSG00000003096    0\n",
       "ENSG00000003137    0\n",
       "ENSG00000003147    0\n",
       "ENSG00000003249    0\n",
       "ENSG00000003393    0\n",
       "ENSG00000003400    0\n",
       "ENSG00000003402    0\n",
       "ENSG00000003436    0\n",
       "ENSG00000003509    0\n",
       "ENSG00000003756    0\n",
       "ENSG00000003987    0\n",
       "ENSG00000003989    0\n",
       "ENSG00000004059    0\n",
       "ENSG00000004139    0\n",
       "ENSG00000004142    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count the total number of missing values for each feature\n",
    "lung_df1_4.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count the total number of missing values in the data\n",
    "lung_df1_4.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Distribution of Samples Corresponding to Each Lung Cancer Types**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing the distribution corresponding to each lung cancer type is to understand the variability and characteristics of each type, aiding in the identification of potential patterns or differences that could inform diagnosis, prognosis, or treatment strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tumor</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Normal</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Normal</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tumor</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     index  class\n",
       "0    Tumor    191\n",
       "1   Normal    110\n",
       "2   Normal      6\n",
       "3    Tumor      6"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a dataframe of the class column and then calculated the number of rows corresponding to each class\n",
    "lung_df = lung_df1_4['class'].value_counts().reset_index()\n",
    "lung_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use barplot to visualize the class distribution of the lung cancer types \n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.barplot(x = \"class\", y = \"index\", data = lung_df)\n",
    "plt.xlabel(\"Number of Samples\")\n",
    "plt.ylabel(\"Class\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' Normal', ' Tumor', 'Normal', 'Tumor'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a closer look on different classes \n",
    "set(lung_df1_4['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace those unusual class with the correct ones \n",
    "lung_df1_4['class'] = lung_df1_4['class'].replace(' Normal', 'Normal')\n",
    "lung_df1_4['class'] = lung_df1_4['class'].replace(' Tumor', 'Tumor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tumor</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Normal</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index  class\n",
       "0   Tumor    197\n",
       "1  Normal    116"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a dataframe of the class column and then calculated the number of rows corresponding to each class\n",
    "lung_df_corrected = lung_df1_4['class'].value_counts().reset_index()\n",
    "lung_df_corrected.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use barplot to visualize the class distribution of the lung cancer types \n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.barplot(x = \"class\", y = \"index\", data = lung_df_corrected)\n",
    "plt.xlabel(\"Number of Samples\")\n",
    "plt.ylabel(\"Class\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Splitting**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting data into 80% training and 20% testing is to train machine learning models on a majority of the data while reserving a portion for independent evaluation, ensuring the model's generalizability and performance on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250, 48)\n",
      "(63, 48)\n",
      "(250,)\n",
      "(63,)\n"
     ]
    }
   ],
   "source": [
    "# split the data into 80% training and 20% testing \n",
    "X_train, X_test, y_train, y_test = train_test_split(lung_df1_4.drop(['ID', 'class'], axis = 1), \n",
    "                                                    lung_df1_4['class'], \n",
    "                                                    test_size = 0.20, \n",
    "                                                    shuffle = True, \n",
    "                                                    random_state = 42, \n",
    "                                                    stratify = lung_df1_4['class'])\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Resampling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using SMOTE-Tomek to resample the class labels is to address class imbalance by synthesizing new minority class instances while simultaneously removing potentially noisy or borderline instances, improving the model's ability to learn from imbalanced data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfEAAAF/CAYAAABZiPDVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAA0AUlEQVR4nO3deUAV9f7/8dcBBBFBJMnSIJckl9xQcUEtrS5aWe4Lhnm7plk3L1q54p7hnknXLMtr4Z5iV7N7y8wkK5dSQ03LrEzM3BAFZD3n8/vDn+erV/FowqHR5+MvZuacz7xnYHidz8znzNiMMUYAAMByPEq6AAAA8McQ4gAAWBQhDgCARRHiAABYFCEOAIBFEeIAAFgUIX6DS01NVa1atfTYY4/pscceU4cOHdS5c2e9//77zte8+uqrF01fzmuvvaZPPvnksssufP/dd9+ttLS0a6oxJSVFY8aMkSTt2rVLgwYNuqb3/xF2u10DBw5UVFSUFi5ceNGyhIQETZgwodhruJyjR49q+PDh6tChgx599FF169at0P1eEr788kvn31JkZKSaNWvmnP7www9LpCa73a4BAwboxIkTSkpKUqNGjfTYY4/p0Ucf1UMPPaQBAwbo2LFjLtvZu3evHnjgAXXq1EmpqalFXueFtZ2vr23btho6dKhyc3OLfH1FoW3bttq1a9d1H5e///67nn32WTkcjiKsDpLkVdIFoPiVLl1a//73v53Thw8fVt++feXr66uoqCj94x//cNnGli1bdNddd1122dW8/0p+/PFHHT16VJJUt25dzZ49+7rauxpHjx7Vpk2btHPnTnl6ehb7+q5GWlqaevbsqX/84x+Kj4+XzWbTvn379Ne//lW+vr6KjIws6RLVokUL599SQkKCTp065fwAVlLmz5+viIgIVahQQZLUuHFjvfHGG87l48aN0+zZs/XSSy9dsZ3169eradOmmjRpUrHV+r+15ebmqlevXlq1apV69uxZbOu9Xtd7XN52222qVauWFi9erMcff7wIKwMhfhOqXLmyBg0apLfffltRUVEaPny4atSoob/97W+aPXu21q1bp1KlSql8+fKKj4/XunXrtHv3bk2dOlWenp5av3690tPTdejQId133306efKk8/2SNGvWLO3atUsOh0OxsbFq06aNkpKS9NFHHzn/gZ2fPv8PNiMjQyNGjFDHjh01ceJEffDBB8rIyND48eO1b98+2Ww2tWrVSkOGDJGXl5fq1q2r/v3764svvtCxY8fUp08f9e3b95Jt/frrrzV16lRlZ2erVKlSio2NVXh4uPr166eCggJ17txZCQkJCg0Nvap9d/fdd+urr75SUFDQRdP79+/XK6+8opCQEO3fv195eXkaM2aMmjVrprS0NI0YMUK//vqrAgMDFRwcrBo1aui55567qO3FixcrPDxcHTt2dM6rWbOmEhIS5O/vL0lasWKFli1bpvz8fJ0+fVpPPfWUoqOjlZSUpHXr1snDw0MHDx5UqVKlNGXKFIWFhen48eMaO3asfvrpJ3l4eKhnz57q06ePMjIyNGnSJP3www/Kz89X8+bNNXToUHl5eemee+7R/fffr3379mn69OmqW7euy30TFxenoKAgDRkyRJK0evVqffTRR+rTp4+mTp2qihUr6tChQypdurQmT56s6tWrKy8vT9OnT9e2bdtkt9tVu3ZtxcXFqWzZslq8eLGWLl2qUqVKycfHRxMmTLjkg2R2drbeeecdrVmz5rI15efnKzMzUyEhIc55r7/+uj7++GM5HA5VrlxZY8eO1ZYtW7RkyRLZ7Xbl5ORoxowZ+uc//6m1a9fK09NTVatW1ejRoxUcHKyYmBiVK1dOP/30k3r16qWOHTsWuh9dSU9PV2ZmpsqVKyfp3IfLCRMm6MiRI8rPz9fDDz+sp59+WgUFBZo4caK2b9+uUqVK6Y477lB8fLz8/Pw0d+5cffLJJ8rNzVV2draGDRumBx98UAkJCfr111916NAhHTt2TPXq1VNkZKTef/99paam6sUXX9QjjzyihIQE7d+/XydOnNDJkydVs2ZNTZo0SWXLlnXWuWXLFudxOXz4cJUtW1bff/+9fv/9d1WrVk0zZ86Un5+fNm7cqOnTp8vDw0O1atXSl19+qcWLF+uOO+5Qt27d1LVrV3Xv3l3e3t4u9w2uksEN7dChQ6ZBgwaXzP/hhx9M/fr1jTHGDBs2zLz11lvmt99+M+Hh4SY3N9cYY8zbb79t1q1bZ4wx5vHHHzf/+c9/nK9/4oknnG2df78xxoSFhZk33njDGGPM999/byIiIszJkyfNypUrTf/+/Z3vuXD6wp83b95sHn74YWOMMUOHDjUTJ040DofD5ObmmieffNLZdlhYmElMTDTGGLNr1y5zzz33mJycnIu2MS0tzTRv3tzs3LnTuc0RERHm119/LXS/GGPM7Nmzzfjx4y+7LCwszJw8efKS6c2bN5tatWqZ7777zrnvevfubYwxZvDgwWbq1KnGGGOOHj1qIiMjzezZsy9pe8CAAWbhwoWXXa8xxmRmZpru3bubtLQ0Y4wxO3bscG7DypUrTaNGjcyRI0eMMcZMmDDBDB061BhjzLPPPmumTJlijDHmzJkz5uGHHza//PKLGT58uHn33XeNMcYUFBSYF154wbz55pvO7Vq1alWhtVxuP3333XcmMjLS5OfnG2OMiY6ONsnJyWbz5s2mZs2aZtu2bcYYYxYvXmw6depkjDEmISHBTJ482TgcDmOMMTNmzDBjx441BQUFpk6dOubo0aPGGGNWrVplli5dekkNn376qXn88ced0ytXrjTh4eHm0UcfNR06dDARERGmVatWJjU11dlObGyss8alS5eafv36XbI9K1asMD169DBZWVnOZU8++aQx5tyxMGLECOc6r7QfL3Rhbe3atTNNmzY1PXr0MEuWLHG+JiYmxqxfv94YY0xOTo6JiYkxa9euNdu2bTPt2rVz7qepU6eab775xqSmppqYmBiTnZ1tjDHmgw8+MI888oiz5jZt2pgzZ86Y7Oxs06RJExMfH2+MMWbdunXmL3/5i/N1rVu3NsePHzd2u90MGTLETJ482RhjTJs2bUxKSspFx+WwYcNMjx49TG5ursnLyzMdO3Y0K1asMGlpaSYiIsLs3bvXGGNMUlKSCQsLM4cOHXJuX+fOnc1XX311yb7BH0dP/CZls9lUunTpi+ZVrFhRNWvWVKdOndS6dWu1bt1azZs3v+z7GzVqVGjbvXr1kiSFhYWpevXq2rFjxx+qMTk5WUuWLJHNZpO3t7d69uypd955R/3795ck3X///ZKkOnXqKC8vT2fPnpWPj4/z/SkpKQoNDVX9+vUlSTVq1FB4eLi2bt2qpk2b/qGarqRSpUqqVauWJKl27dpatWqVJGnjxo3On2+99Va1a9fusu+32WwyV7gL8vle18aNG/XLL79o3759Onv2rHN5nTp1dNtttznXv27dOknnrmO/+OKLkiR/f3998MEHkqTPPvtMu3bt0ooVKyRJOTk5F62vcePG17T9tWrV0h133KHPPvtMVatW1bFjx9SyZUtt3bpVNWvWdLbXpUsXTZgwQadOndJnn32mjIwMffnll5LO9ZxvueUWeXp6ql27durZs6fuu+8+RUZGqkOHDpes86effrrkLMqFp6wdDofeffdd9evXTx9++KE2bNigXbt2qUuXLs7l2dnZl7SbnJyszp07q0yZMpKkPn36aO7cucrLy7tk37jaj5erzeFwaM6cOVqzZo3z7/js2bPatm2bTp8+rVdffdU5b9++fWrZsqU8PT3VrVs3tWzZUlFRUapXr54kacqUKVqzZo0OHjyob7/9VllZWc71tWjRwnkW59Zbb1WrVq0kSaGhoUpPT3e+rl27ds7LEV27dtXLL7+sYcOGFbodrVq1cvamw8LCdPr0aX399deqXr26atasKUnq1KnTJZcwQkND9fPPP6tZs2aFto1rQ4jfpHbt2qWwsLCL5nl4eGjhwoXatWuXvvrqK7388stq2rSp4uLiLnn/+X9ul+Ph8X/jJY0x8vLyuiSg8vPzXdb4v4NgHA6HCgoKnNPnA9tmsznXdaX3n3/NhW1cj/P/0M+78EPRhdvr5eV1UW0X7p8LNWjQQDt37rzkmuHSpUuVnZ2t9u3bq0ePHurevbsaNWqkdu3aacOGDVe1/vP7SJIOHTqk8uXLy+Fw6NVXX1X16tUlSWfOnLnodVf6HRemd+/eWrlypapUqaLu3bs72/vfcQfGGHl6esrhcGjkyJG69957JUlZWVnOQV7Tp0/XDz/8oC+//FLz5s3TihUr9Prrr1/UjoeHxxUHS3l4eKhHjx6Kj4/XyZMn5XA41K9fP0VHR0s69zs8ffr0Je+73N/ShX83F+4bV/uxsLr+/ve/a8eOHRo1apTefPNNORwOGWO0dOlS+fr6Sjo3TsLHx0d+fn7697//re3bt2vz5s2KjY1Vnz591KRJEz3zzDPq27evIiMj1aRJE40fP965nv89bV3YKf4Lfz8Oh6PQv9HzLve35unpecl++9927Hb7n2YMyo2C0ek3oZ9//llz5szRk08+edH8ffv26ZFHHlH16tU1YMAA9e3bV99//72kcwf51Ybf+V7nnj17dPDgQdWvX19BQUHav3+/cnNzVVBQcFH4FNZ2y5YttWjRIhljlJeXp+XLl6tFixZXvZ3169fXzz//rJSUFEnS/v37tW3bNkVERFx1G/8rKChIu3btkiRnT9eVe++919lLO3XqlD755JPL/pPv0aOHtm7dqtWrVzv/Ge7evVuzZ89WWFiYdu/eraCgID3zzDNq1aqVcx/a7fYrrr958+ZauXKlJCkjI0NPPPGEfvnlF7Vs2VILFixw7t+BAwdeMlL/WkVFRWnv3r36+OOPnb1d6dzf1r59+yRJy5YtU3h4uAICApy/47y8PDkcDo0ePVozZ85UWlqa7r33XgUGBqpv376KjY11/i1eqEqVKjp06NAVa1q3bp0qV66soKAgtWzZUitWrFBmZqakc9+sGDp06CXvadmypZKSkpxnOhITE9WkSZPLXsu9nv04duxYffXVV/rkk09UtmxZNWjQQP/6178knfsw0KtXL61fv14bNmxQ37591bBhQz333HPq2LGj9u3bp23btumee+7RX//6V0VERGj9+vUu/x4uZ/369crIyJDD4dDy5cvVpk2ba24jPDzceYZIkj766KNLPtCkpqaqWrVq19w2CkdP/CaQk5Ojxx57TNK5T8Y+Pj4aMmSI7rvvvoteV7NmTbVv315dunRRmTJlVLp0aWcvvE2bNpoyZcpV9aAPHTqkjh07ymazaebMmQoMDHT2Etq3b6/g4GA1bdrU+U+5YcOGmjVrlp599ln16dPH2U5cXJxeeukldejQQfn5+WrVqpWefvrpq97uoKAgvfrqq5o4caJycnJks9kUHx+vqlWruvwK0fLly50fRqRzA9iWLl2quLg4TZgwQQEBAWrRooWCg4Nd1jFixAjFxcWpQ4cOCgwMVKVKlS65lCFJgYGBSkxM1LRp0/TGG2/Iw8NDvr6+mjRpkiIjI5Wdna0VK1aoXbt28vX1Vb169RQUFKSDBw9ecf1jxozRuHHj1KFDBxljNGDAAN1zzz0aNWqUJk2a5Ny/LVq0UL9+/Vxuz5V4e3srKipKJ06ccA7+k6QKFSpo1qxZOnz4sIKCgjR16lRJ0jPPPKMpU6aoU6dOstvtqlWrlnPg1MCBA9W3b1+VLl1anp6elx1d3qJFC40aNUpnzpxRQECApHODGR977DHZbDYVFBQoMDBQ//znP+Xh4aFu3brp6NGjzrMEt99+uyZPnnxJu127dtWRI0fUrVs3ORwO3XnnnZo+ffplt/l69mNoaKieeuopxcfHq1WrVpo+fbomTpyoDh06KC8vT4888ogeffRR2e12JScn65FHHlGZMmVUrlw5TZw4UaVLl9bHH3+shx56SKVKlVLz5s11+vRp54eUq1WhQgU99dRTOnXqlJo0aXJNx9l5gYGBmjlzpoYNGyYPDw/dc8898vLycp5VOD9wLjw8/JrbxhW4+yI8cLNZuHCh2b59uzHGmNzcXNOlSxfz2WeflXBVxSMrK8t06tTJOZjQmIsHKxaH119//bIDyXB1rjSQ81pkZGSYKVOmmLNnzxpjjNm9e7eJjIx0DsabPXv2FQdu4o+hJw4Us7vuuksTJ06Uw+FQfn6+2rVr57wGfCP5/PPP9fzzz6tLly7OwYTu8OSTT2rgwIHq2LHjVZ0ZQfEoW7asSpUqpa5du8rLy0teXl6aNWuWbDabjhw5oj179uif//xnSZd5w7EZc4XhsAAA4E+LgW0AAFgUIQ4AgEUR4gAAWJTlBrY5HA7Z7VzGBwDcHEqVKvwGOZYLcbvdKD39rOsXAgBwAwgO9i90GafTAQCwKEIcAACLIsQBALAoQhwAAIsqthD/9ttvFRMTI0k6efKkBg4cqN69e6tnz5769ddfJZ17yETnzp3VvXv3i55qBQAAXCuW0enz5s3T6tWrnU+vmTZtmjp06KCHHnpImzdv1k8//SRfX18lJiZq5cqVys3NVXR0tCIjIy/7qD8AAHCpYumJh4aGKiEhwTm9fft2HT16VH379tWaNWsUERGhlJQUNWzYUN7e3vL391doaKjzObQAAMC1YumJR0VFXfS85sOHDysgIEALFizQa6+9pnnz5qlKlSry9/+/7775+fld1TNwPT1tCgwsUxxlAwBgKW652UtgYKDatm0rSWrbtq1eeeUV3XPPPcrKynK+Jisr66JQLww3ewEA3ExK/GYvjRo10saNGyVJ27Zt01133aV69erpm2++UW5urjIyMnTgwAGFhYW5oxwAAG4IbumJDxs2THFxcVq6dKnKli2rGTNmqFy5coqJiVF0dLSMMRo8eLB8fHzcUQ4AADcEmzHGUk8Tyc+3czodAHDTKPHT6QAAoOhZ7ilmxaV8WW95+XI6H9ZXkJ2rU5l5JV0GADcgxP8/L18fbar3SEmXAVy3likfSIQ4cFPgdDoAABZFiAMAYFGEOAAAFkWIAwBgUYQ4AAAWRYgDAGBRhDgAABZFiAMAYFGEOAAAFkWIAwBgUYQ4AAAWRYgDAGBRhDgAABZFiAMAYFGEOAAAFkWIAwBgUYQ4AAAWRYgDAGBRhDgAABZFiAMAYFGEOAAAFkWIAwBgUYQ4AAAWRYgDAGBRhDgAABZFiAMAYFGEOAAAFkWIAwBgUYQ4AAAWVWwh/u233yomJuaieWvWrFGPHj2c08uXL1fnzp3VvXt3bdiwobhKAQDghuRVHI3OmzdPq1evlq+vr3Ped999pxUrVsgYI0k6fvy4EhMTtXLlSuXm5io6OlqRkZHy9vYujpIAALjhFEtPPDQ0VAkJCc7pU6dOaebMmRo5cqRzXkpKiho2bChvb2/5+/srNDRU+/btK45yAAC4IRVLTzwqKkqpqamSJLvdrlGjRmnEiBHy8fFxviYzM1P+/v7OaT8/P2VmZrps29PTpsDAMkVfNHAD4RgBbg7FEuIX2rNnjw4ePKhx48YpNzdXP/74oyZNmqRmzZopKyvL+bqsrKyLQr0wdrtRevrZIq8zONj1ugGrKI5jBEDJuFI+FXuI16tXT2vXrpUkpaamasiQIRo1apSOHz+uWbNmKTc3V3l5eTpw4IDCwsKKuxwAAG4YxR7ihQkODlZMTIyio6NljNHgwYMvOt0OAACuzGbODxe3iPx8e7GdTt9U75Eibxdwt5YpH+j48YySLgNAEbnS6XRu9gIAgEUR4gAAWBQhDgCARRHiAABYFCEOAIBFEeIAAFgUIQ4AgEUR4gAAWBQhDgCARRHiAABYFCEOAIBFEeIAAFgUIQ4AgEUR4gAAWBQhDgCARRHiAABYFCEOAIBFEeIAAFgUIQ4AgEUR4gAAWBQhDgCARRHiAABYFCEOAIBFEeIAAFgUIQ4AgEUR4gAAWBQhDgCARRHiAABYFCEOAIBFEeIAAFgUIQ4AgEUVW4h/++23iomJkSTt3btX0dHRiomJ0d/+9jedOHFCkrR8+XJ17txZ3bt314YNG4qrFAAAbkhexdHovHnztHr1avn6+kqSJk2apNGjR6tWrVpaunSp5s2bp379+ikxMVErV65Ubm6uoqOjFRkZKW9v7+IoCQCAG06x9MRDQ0OVkJDgnJ45c6Zq1aolSbLb7fLx8VFKSooaNmwob29v+fv7KzQ0VPv27SuOcgAAuCEVS088KipKqampzulbb71VkrR9+3YtXLhQixYt0ueffy5/f3/na/z8/JSZmemybU9PmwIDyxR90cANhGMEuDkUS4hfzocffqjXX39db775poKCglS2bFllZWU5l2dlZV0U6oWx243S088WeX3Bwa7XDVhFcRwjAErGlfLJLaPT//3vf2vhwoVKTExUSEiIJKlevXr65ptvlJubq4yMDB04cEBhYWHuKAcAgBtCsffE7Xa7Jk2apNtvv13PPfecJKlJkyYaNGiQYmJiFB0dLWOMBg8eLB8fn+IuBwCAG4bNGGNKuohrkZ9vL7bT6ZvqPVLk7QLu1jLlAx0/nlHSZQAoIiV+Oh0AABQ9QhwAAIsixAEAsChCHAAAiyLEAQCwKEIcAACLIsQBALAoQhwAAIsixAEAsChCHAAAiyLEAQCwKEIcAACLIsQBALAoQhwAAIsixAEAsChCHAAAiyLEAQCwKEIcAACLIsQBALAoQhwAAIsixAEAsChCHAAAiyLEAQCwKEIcAACLIsQBALAoQhwAAIsixAEAsChCHAAAi3IZ4kePHtWPP/6on3/+WSNHjtTevXvdURcAAHDBZYg///zzOnHihF555RVFRkbq5ZdfdkddAADABZchbrPZ1KRJE505c0YPP/ywPDw4Aw8AwJ+By0QuKCjQtGnT1LhxY23evFn5+fnuqAsAALjgMsTj4+MVEhKi/v37Ky0tTVOmTLmqhr/99lvFxMRIkg4ePKhevXopOjpaY8eOlcPhkCS99tpr6tq1q3r27KmUlJTr2AwAAG4+LkP83XffVe/eveXt7a2HHnpICQkJLhudN2+e4uLilJubK+ncB4HY2FgtXrxYxhitX79ee/bs0datW/Xee+9p5syZGj9+/PVvDQAANxGvwhYsWrRIr7/+utLT0/Xxxx8751evXt1lo6GhoUpISNDQoUMlSXv27FFERIQkqXXr1vriiy9UtWpVtWzZUjabTZUqVZLdbldaWpqCgoKud5sAALgpFBrivXv3Vu/evTV37lw9/fTT19RoVFSUUlNTndPGGNlsNkmSn5+fMjIylJmZqcDAQOdrzs93FeKenjYFBpa5pnqAmw3HCHBzKDTEz3v88cf14YcfKi8vzzmvY8eO17SSC0e0Z2VlKSAgQGXLllVWVtZF8/39/V22Zbcbpaefvab1X43gYNfrBqyiOI4RACXjSvnk8pr4M888o08//VQHDhzQgQMH9NNPP11zAbVr19aWLVskScnJyWrcuLHCw8O1adMmORwO/fbbb3I4HJxKBwDgGrjsiRtjNH369OtaybBhwzR69GjNnDlT1apVU1RUlDw9PdW4cWP16NFDDodDY8aMua51AABws7EZY8yVXvDSSy+pQ4cOqlWrlnOet7d3sRdWmPx8e7GdTt9U75Eibxdwt5YpH+j48YySLgNAEbnS6XSXPfGtW7fq008/dU7bbDatX7++aCoDAAB/mMsQX716tSTp1KlTCgwMdI4yBwAAJctliG/btk3jx4+X3W5Xu3btVKlSJXXr1s0dtQEAgCtwOTp91qxZWrhwoSpUqKCnn35aS5YscUddAADABZch7uHh4TyN7uPjIz8/P3fUBQAAXHAZ4qGhoZoxY4bS09P15ptvqlKlSu6oCwAAuOAyxMePH69KlSqpUaNGKlOmjCZOnOiOugAAgAuFhviuXbskSZs3b1ZISIjuv/9+ValSRVu3bnVbcQAAoHCFjk7/6quvVLduXa1du/aSZS1btizWogAAgGuFhnj//v0lSeHh4Rd9pezdd98t/qoA3DTKlS8jby/Pki4DuG55BXadPuXehw8VGuIffPCBPv30U23ZskWbN2+WJDkcDv3www/q06eP2woEcGPz9vLUa1t/KekygOv294gqbl9noSHeqlUrBQcHKz09XT169JB07utmISEhbisOAAAUrtAQL1eunJo2baqmTZvq2LFjKigokDFGv/32mypWrOjOGgEAwGW4vO3qyJEjtXPnTmVnZys7O1uhoaFavny5O2oDAABX4PJ74vv27dPatWvVsmVLffjhh/Lx8XFHXQAAwAWXIV6+fHnZbDadPXtWQUFB7qgJAABcBZchXqdOHb399tu69dZbNXjwYOXk5LijLgAA4ILLa+JDhgxRZmamSpcureTkZNWrV88ddQEAABcKDfEDBw5o1qxZ8vPz0wsvvKCyZcuqbdu27qwNAABcQaGn08eNG6du3bopMjJS06ZNc2dNAADgKhTaE7fZbGrdurUkaeXKlW4rCAAAXB2XA9ukc7dbBQAAfy6F9sTT09O1adMmGWN0+vRpbdq0ybmMp5gBAFDyCg3xOnXqOB9DWrt27YseSUqIAwBQ8goN8fj4eHfWAQAArtFVXRMHAAB/PoWGeEZGhjvrAAAA16jQEO/fv78kaezYsW4rBgAAXL1Cr4l7eXmpS5cuOnjwoL7//ntJkjFGNptNS5cudVuBAADg8goN8QULFujo0aMaN26cxo0bJ2OMO+sCAAAuFBrinp6eqlSpkubMmaNly5bpxx9/VJUqVdSrVy931gcAAArhcnT6mDFj9OuvvyoyMlKHDx9WXFycO+oCAAAuuHwU6cGDB7Vo0SJJ0gMPPKCePXv+oRXl5+dr+PDhOnz4sDw8PDRx4kR5eXlp+PDhstlsqlGjhsaOHSsPD771BgDA1XCZmLm5ucrOzpYk5eTkyG63/6EVbdy4UQUFBVq6dKmeffZZzZo1S/Hx8YqNjdXixYtljNH69ev/UNsAANyMXPbE+/Tpo8cee0w1atTQjz/+qEGDBv2hFVWtWlV2u10Oh0OZmZny8vLSzp07FRERIUlq3bq1vvjiCz344IN/qH0AAG42LkP80UcfVevWrXXo0CHdcccdKl++/B9aUZkyZXT48GG1b99ep06d0ty5c7Vt2zbZbDZJkp+f31XdYMbT06bAwDJ/qAbgZsExApQMdx97LkNckgIDAxUYGHhdK1qwYIFatmyp559/XkeOHNETTzyh/Px85/KsrCwFBAS4bMduN0pPP3tdtVxOcLB/kbcJlJTiOEaKC8cebiTuzie3jSILCAiQv/+5QsqVK6eCggLVrl1bW7ZskSQlJyercePG7ioHAADLcxnib7/9dpGsqG/fvtqzZ4+io6P1xBNPaPDgwRozZowSEhLUo0cP5efnKyoqqkjWBQDAzcDl6fSNGzeqb9++8vT0vK4V+fn56dVXX71k/sKFC6+rXQAAblYuQ/zUqVNq1aqV7rjjDtlsNu6dDgDAn4TLEJ87d6476gAAANfIZYh7eXlp2rRpSktLU7t27XT33XercuXK7qgNAABcgcuBbaNHj1aXLl2Un5+vxo0ba9KkSe6oCwAAuOAyxHNyctS8eXPZbDZVq1ZNPj4+7qgLAAC44DLEfXx89Pnnn8vhcGjnzp3y9vZ2R10AAMAFlyE+ceJEJSUl6dSpU5o/f77GjRvnhrIAAIArLge23XbbbRowYIB++eUX1ahRQyEhIe6oCwAAuOAyxOfMmaPPP/9cdevW1YIFC9SuXTv17dvXDaUBAIAruao7ti1ZskQeHh4qKChQdHQ0IQ4AwJ+Ay2vit9xyi7KzsyVJ+fn5CgoKKvaiAACAa4X2xHv06CGbzaaTJ08qKipKd999tw4cOHDdjyQFAABFo9AQnzlzpjvrAAAA16jQED9/a9WUlBStXbtWubm5zmV8zQwAgJLncmDbsGHD9NRTTykgIMAd9QAAgKvkMsTvvPNOde7c2R21AACAa+AyxKOiojR48GBVr17dOe/vf/97sRYFAABccxniixYt0l/+8hdOpwMA8CfjMsQDAwPVv39/d9QCAACugcsQL1++vMaMGaPatWvLZrNJOvcdcgAAULKuamCbJJ04caLYiwEAAFfPZYgzMh0AgD8nlyE+ePBg2Ww2ORwOpaam6s4779SSJUvcURsAALgClyG+bNky589nzpzR6NGji7UgAABwdVw+xexC/v7+OnToUHHVAgAAroHLnvj5p5kZY5SWlqbmzZu7oy4AAOCCyxC/8GlmPj4+qlChQrEWBAAArk6hIf7+++8X+qaOHTsWQykAAOBaFBriBw4cuGjaGKOkpCSVLl2aEAcA4E+g0BB//vnnnT//+uuvGjZsmO677z6NHDnSLYUBAIAru6oHoLzzzjsaMWKE2rRp446aAADAVSg0xI8ePaoRI0aoXLlyeu+991SuXLnrXtkbb7yhTz/9VPn5+erVq5ciIiI0fPhw2Ww21ahRQ2PHjpWHxzV96w0AgJtWoSH+8MMPy9vbW82aNdOECRMuWjZjxoxrXtGWLVu0Y8cOLVmyRNnZ2Zo/f77i4+MVGxurpk2basyYMVq/fr0efPDBa98KAABuQoWG+Jw5c4p0RZs2bVJYWJieffZZZWZmaujQoVq+fLkiIiIkSa1bt9YXX3xBiAMAcJUKDfHz4VpUTp06pd9++01z585VamqqBg4cKGOM8/Gmfn5+ysjIcNmOp6dNgYFlirQ24EbDMQKUDHcfey4HthWVwMBAVatWTd7e3qpWrZp8fHz0+++/O5dnZWUpICDAZTt2u1F6+tkiry842L/I2wRKSnEcI8WFYw83Enfnk9tGkTVq1Eiff/65jDE6evSosrOz1bx5c23ZskWSlJycrMaNG7urHAAALM9tPfE2bdpo27Zt6tq1q4wxGjNmjO644w6NHj1aM2fOVLVq1RQVFeWucgAAsDy3hbgkDR069JJ5CxcudGcJAADcMPhSNgAAFkWIAwBgUYQ4AAAWRYgDAGBRhDgAABZFiAMAYFGEOAAAFkWIAwBgUYQ4AAAWRYgDAGBRhDgAABZFiAMAYFGEOAAAFkWIAwBgUYQ4AAAWRYgDAGBRhDgAABZFiAMAYFGEOAAAFkWIAwBgUYQ4AAAWRYgDAGBRhDgAABZFiAMAYFGEOAAAFkWIAwBgUYQ4AAAWRYgDAGBRhDgAABZFiAMAYFGEOAAAFkWIAwBgUW4P8ZMnT+ree+/VgQMHdPDgQfXq1UvR0dEaO3asHA6Hu8sBAMCy3Bri+fn5GjNmjEqXLi1Jio+PV2xsrBYvXixjjNavX+/OcgAAsDS3hviUKVPUs2dP3XrrrZKkPXv2KCIiQpLUunVrffnll+4sBwAAS/Ny14qSkpIUFBSkVq1a6c0335QkGWNks9kkSX5+fsrIyHDZjqenTYGBZYq1VsDqOEaAkuHuY89tIb5y5UrZbDZ99dVX2rt3r4YNG6a0tDTn8qysLAUEBLhsx243Sk8/W+T1BQf7F3mbQEkpjmOkuHDs4Ubi7nxyW4gvWrTI+XNMTIzGjRunadOmacuWLWratKmSk5PVrFkzd5UDAIDllehXzIYNG6aEhAT16NFD+fn5ioqKKslyAACwFLf1xC+UmJjo/HnhwoUlUQIAAJbHzV4AALAoQhwAAIsixAEAsChCHAAAiyLEAQCwKEIcAACLIsQBALAoQhwAAIsixAEAsChCHAAAiyLEAQCwKEIcAACLIsQBALAoQhwAAIsixAEAsChCHAAAiyLEAQCwKEIcAACLIsQBALAoQhwAAIsixAEAsChCHAAAiyLEAQCwKEIcAACLIsQBALAoQhwAAIsixAEAsChCHAAAiyLEAQCwKEIcAACLIsQBALAoL3etKD8/XyNHjtThw4eVl5engQMH6q677tLw4cNls9lUo0YNjR07Vh4efK4AAOBquC3EV69ercDAQE2bNk3p6enq2LGjatasqdjYWDVt2lRjxozR+vXr9eCDD7qrJAAALM1t3d527drpH//4hyTJGCNPT0/t2bNHERERkqTWrVvryy+/dFc5AABYntt64n5+fpKkzMxMDRo0SLGxsZoyZYpsNptzeUZGhst2PD1tCgwsU6y1AlbHMQKUDHcfe24LcUk6cuSInn32WUVHR6tDhw6aNm2ac1lWVpYCAgJctmG3G6Wnny3y2oKD/Yu8TaCkFMcxUlw49nAjcXc+ue10+okTJ/Tkk0/qxRdfVNeuXSVJtWvX1pYtWyRJycnJaty4sbvKAQDA8twW4nPnztWZM2c0Z84cxcTEKCYmRrGxsUpISFCPHj2Un5+vqKgod5UDAIDlue10elxcnOLi4i6Zv3DhQneVAADADYUvZQMAYFGEOAAAFkWIAwBgUYQ4AAAWRYgDAGBRhDgAABZFiAMAYFGEOAAAFkWIAwBgUYQ4AAAWRYgDAGBRhDgAABZFiAMAYFGEOAAAFkWIAwBgUYQ4AAAWRYgDAGBRhDgAABZFiAMAYFGEOAAAFkWIAwBgUYQ4AAAWRYgDAGBRhDgAABZFiAMAYFGEOAAAFkWIAwBgUYQ4AAAWRYgDAGBRhDgAABZFiAMAYFGEOAAAFuVV0gU4HA6NGzdO33//vby9vfXSSy/pzjvvLOmyAAD40yvxnvgnn3yivLw8LVu2TM8//7wmT55c0iUBAGAJJR7i33zzjVq1aiVJatCggXbv3l3CFQEAYA0lfjo9MzNTZcuWdU57enqqoKBAXl6XL61UKU8FB/sXSy0tUz4olnYBdyuuY6S4/D2iSkmXABQJdx97Jd4TL1u2rLKyspzTDoej0AAHAAD/p8RDPDw8XMnJyZKknTt3KiwsrIQrAgDAGmzGGFOSBZwfnf7DDz/IGKOXX35Z1atXL8mSAACwhBIPcQAA8MeU+Ol0AADwxxDiAABYFCGOazZ58mTFxMSoXbt2uu+++xQTE6NBgwaVdFnADW3Lli1q1KiRjhw54pw3ffp0JSUlFds6U1NT1b1792JrH9eP73Lhmg0fPlySlJSUpJ9++kkvvPBCCVcE3By8vb01YsQI/etf/5LNZivpcvAnQIijSAwfPlwPPfSQWrdureTkZH344YeaPHmyHnzwQTVs2FC//PKLmjdvroyMDKWkpKhq1aqaNm2aUlNTNXLkSNntdtlsNsXFxalmzZpq06aNqlWrpurVq2vkyJElvXnAn0KzZs3kcDi0aNEiPf7448758+fP19q1a+Xl5aXGjRvrxRdfVEJCgnbs2KGzZ89q0qRJGj58uG6//Xalpqbq4Ycf1v79+/Xdd9/pvvvu05AhQ7R161a99tprMsYoKytLM2bMUKlSpUpwa3E1CHEUq8OHD+udd95RcHCwIiIi9N5772n06NG6//77debMGU2dOlV9+vTRAw88oL1792rkyJFKSkrSkSNHlJSUpPLly5f0JgB/KuPGjVO3bt2ct6vOysrSf/7zHy1dulReXl567rnntGHDBklStWrVFBcXp9TUVB06dEjz589XTk6O7r//fiUnJ8vX11dt2rTRkCFDtH//fk2bNk0VK1bU3Llz9d///lcdOnQoyU3FVSDEUeQu/NZiYGCgKlWqJEkqU6aM7rrrLkmSv7+/cnNzdeDAATVp0kSSVKtWLf3++++SpPLlyxPgwGWUL19eI0eO1LBhwxQeHq7c3FzVr1/f2Wtu3Lix9u/fL0mqWrWq830hISHy9/eXt7e3KlSooMDAQElynpavWLGiJk2apDJlyujo0aMKDw9374bhD2FgG4qEt7e3jh8/Lkn67rvvnPNdXberXr26vv76a0nS3r17VaFCBUmShwd/mkBh2rZtq6pVq2rVqlXy8fFRSkqKCgoKZIzRtm3bnOF94XHk6lgcPXq0Xn75ZU2ePFm33nqruIWINdATR5Ho1q2bRo4cqTVr1qhKlSpX/b6hQ4dq9OjRmj9/vgoKCjRp0qTiKxK4gYwaNUqbN2+Wn5+f2rdvr169esnhcKhRo0Z64IEHtG/fvmtq79FHH1Xv3r3l6+urChUq6NixY8VUOYoSd2wDAMCiOGcJAIBFEeIAAFgUIQ4AgEUR4gAAWBQhDgCARfEVM6AEbdmyRUuXLtUrr7xSrOs5cuSIJk+erLS0NOXk5KhOnToaOXKkvL29i3W9/2vy5Mnas2ePjh8/rpycHIWEhKh8+fKaPXu2W+sAbhSEOHCDs9vteuaZZzRu3DjVr19fkvTSSy9p9uzZbn94DQ/PAYoWIQ78CbVt21b/+c9/5OPjo+nTp6tatWqqXLmy5s2bp1KlSik1NVUPPfSQBg4cqIMHD2r48OHy8vJS5cqVdfjwYSUmJjrb+uabb3Tbbbc5A1ySXnzxRTkcDknSjBkztHv3bqWnp6tmzZqKj49XQkKCUlNTdfLkSf32228aMWKEWrVqpQ0bNjgfklGnTh2NHz9eX3/9tV555RV5enoqJCREEyZM0Jo1a7Ry5Uo5HA4NGjRIzZs3L3RbMzIy1KlTJ3300Ufy9PTUtGnTVKdOHS1ZskRVq1bVzz//LGOMXnnlFQUHB2vGjBn6+uuv5XA41LdvX7Vv316LFi3S+++/Lw8PD9WtW1dxcXHF98sB/kS4Jg5YyG+//aaEhAQtW7ZMb731liRp6tSpevrpp5WYmHjZ+10fO3ZMISEhF83z8fGRr6+vMjMzFRAQoH/9619auXKldu7cqaNHj0o6dyvdt956S6NGjdKCBQtUUFCgiRMn6s0331RSUpJCQ0N15MgRjR49Wq+99poWLlyoihUratWqVZKkgIAALVmy5IoBLp27j36jRo20adMm2e12JScn64EHHpAkhYeHKzExUe3bt9cbb7yhjRs3KjU1VUuWLNG7776ruXPn6syZM0pKStLo0aO1bNkyVatWTQUFBde9rwEroCcO/MldeFPFsLAweXl5ycvLS6VLl5YkHThwQA0bNpQkNWrUSGvWrLno/ZUqVdLHH3980bxTp05px44datWqldLS0jRkyBCVKVNGZ8+eVX5+vqRzD6SRpNtuu015eXk6deqUAgICdMstt0iSnnrqKZ08eVLHjh1TbGysJCknJ0ctWrTQnXfeedHDN1zp1q2bEhMT5XA41KJFC+e1+mbNmkk6F+affvqpKlasqD179igmJkaSVFBQoMOHDys+Pl7z58/X1KlT1aBBA+77jZsGPXHgT8jb21vHjh2TMeaie2Bf7iEWYWFh2rFjhyTp22+/vWR5gwYNlJqaqpSUFEnnPhS89tpr+vrrr5WcnKwjR45o5syZGjJkiHJycpwB+L/ruuWWW3TmzBmlp6dLOndd/fDhw7rttts0Z84cJSYm6umnn3YG77U8xKZx48Y6dOiQVqxYoa5duzrn7969W5K0fft23XXXXapWrZqaNm2qxMREvfPOO2rfvr1CQkK0fPlyjR8/XgsXLtTevXud+wO40dETB0rYF198oc6dOzunZ8yYoX79+ql///6qXLmyAgICrvj+F154QSNHjtT8+fPl7+8vL6+LD2sPDw+9+uqrmjBhgrKzs3X27Fk1aNBAsbGxOn36tObMmaPevXvLZrMpJCSk0AdfeHh4aOzYsRowYIA8PDxUu3Zt1a1bV6NGjVL//v1ljJGfn5+mTp2qI0eOXPN+6NChg/773/+qRo0aznmrVq3SggUL5Ovrq6lTpyowMFBbt25VdHS0zp49qwceeEBly5bV3XffrejoaPn5+alixYoXXf8HbmQ8AAWwuNWrV6t+/fq688479d5772n79u2Kj48v6bKu2VtvvaXAwEBnTzwmJkbjxo1T9erVS7gy4M+LnjhgcbfffrsGDx4sX19feXh46OWXXy7pkq7Z8OHDdezYMc2dO7ekSwEshZ44AAAWxcA2AAAsihAHAMCiCHEAACyKEAcAwKIIcQAALIoQBwDAov4f9EdjRqQ+EioAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# distribution of lung cancer types before applying resampling technique\n",
    "plt.figure(figsize = (8, 6))\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.countplot(x = y_train, palette=['crimson', 'skyblue'])\n",
    "plt.title(\"Distribution of Lung Cancer Types (Before Resampling)\")\n",
    "plt.xlabel(\"Lung Cancer Types\")\n",
    "plt.ylabel(\"Number of Patients\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying resampling technique\n",
    "smote_tomek = SMOTETomek(random_state = 42)\n",
    "X_train_res, y_train_res = smote_tomek.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# distribution of lung cancer types after applying resampling technique\n",
    "plt.figure(figsize = (8, 6))\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.countplot(x = y_train_res, palette=['crimson', 'skyblue'])\n",
    "plt.title(\"Distribution of Lung Cancer Types (After Resampling)\")\n",
    "plt.xlabel(\"Lung Cancer Types\")\n",
    "plt.ylabel(\"Number of Patients\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Transformation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENSG00000000003</th>\n",
       "      <th>ENSG00000000005</th>\n",
       "      <th>ENSG00000000419</th>\n",
       "      <th>ENSG00000000457</th>\n",
       "      <th>ENSG00000000460</th>\n",
       "      <th>ENSG00000000938</th>\n",
       "      <th>ENSG00000000971</th>\n",
       "      <th>ENSG00000001036</th>\n",
       "      <th>ENSG00000001084</th>\n",
       "      <th>ENSG00000001167</th>\n",
       "      <th>...</th>\n",
       "      <th>ENSG00000003400</th>\n",
       "      <th>ENSG00000003402</th>\n",
       "      <th>ENSG00000003436</th>\n",
       "      <th>ENSG00000003509</th>\n",
       "      <th>ENSG00000003756</th>\n",
       "      <th>ENSG00000003987</th>\n",
       "      <th>ENSG00000003989</th>\n",
       "      <th>ENSG00000004059</th>\n",
       "      <th>ENSG00000004139</th>\n",
       "      <th>ENSG00000004142</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.234678</td>\n",
       "      <td>4.634395</td>\n",
       "      <td>0.086224</td>\n",
       "      <td>-0.043637</td>\n",
       "      <td>-0.412079</td>\n",
       "      <td>-0.087568</td>\n",
       "      <td>0.141758</td>\n",
       "      <td>0.291403</td>\n",
       "      <td>-0.062944</td>\n",
       "      <td>0.277055</td>\n",
       "      <td>...</td>\n",
       "      <td>0.203099</td>\n",
       "      <td>0.706053</td>\n",
       "      <td>0.797619</td>\n",
       "      <td>0.860695</td>\n",
       "      <td>0.412302</td>\n",
       "      <td>-2.120354</td>\n",
       "      <td>-0.785904</td>\n",
       "      <td>0.367341</td>\n",
       "      <td>-0.191329</td>\n",
       "      <td>0.659883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.481630</td>\n",
       "      <td>-1.088727</td>\n",
       "      <td>0.393885</td>\n",
       "      <td>0.081690</td>\n",
       "      <td>0.255043</td>\n",
       "      <td>0.044410</td>\n",
       "      <td>0.551511</td>\n",
       "      <td>0.174597</td>\n",
       "      <td>1.796380</td>\n",
       "      <td>0.401716</td>\n",
       "      <td>...</td>\n",
       "      <td>0.272284</td>\n",
       "      <td>0.510074</td>\n",
       "      <td>0.228360</td>\n",
       "      <td>0.324721</td>\n",
       "      <td>0.454481</td>\n",
       "      <td>-0.326132</td>\n",
       "      <td>0.317026</td>\n",
       "      <td>0.230402</td>\n",
       "      <td>-0.414452</td>\n",
       "      <td>0.233399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.899209</td>\n",
       "      <td>0.540451</td>\n",
       "      <td>-1.775802</td>\n",
       "      <td>-1.289537</td>\n",
       "      <td>-1.163083</td>\n",
       "      <td>-0.637282</td>\n",
       "      <td>-1.147808</td>\n",
       "      <td>-1.646437</td>\n",
       "      <td>-1.524145</td>\n",
       "      <td>-2.031053</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.352449</td>\n",
       "      <td>-0.565953</td>\n",
       "      <td>-0.358369</td>\n",
       "      <td>-2.224981</td>\n",
       "      <td>-1.198323</td>\n",
       "      <td>-1.116561</td>\n",
       "      <td>-0.963517</td>\n",
       "      <td>-1.779758</td>\n",
       "      <td>-2.283342</td>\n",
       "      <td>-1.354213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.770320</td>\n",
       "      <td>1.695261</td>\n",
       "      <td>-2.576997</td>\n",
       "      <td>-1.545523</td>\n",
       "      <td>-0.436382</td>\n",
       "      <td>-1.718143</td>\n",
       "      <td>-2.187674</td>\n",
       "      <td>-2.372824</td>\n",
       "      <td>-1.423067</td>\n",
       "      <td>-2.332330</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.705504</td>\n",
       "      <td>-1.774165</td>\n",
       "      <td>-2.418789</td>\n",
       "      <td>-1.660614</td>\n",
       "      <td>-2.287721</td>\n",
       "      <td>1.000678</td>\n",
       "      <td>-2.448145</td>\n",
       "      <td>-1.655062</td>\n",
       "      <td>0.441241</td>\n",
       "      <td>-1.292560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.030564</td>\n",
       "      <td>0.022250</td>\n",
       "      <td>0.283700</td>\n",
       "      <td>0.044262</td>\n",
       "      <td>-0.163719</td>\n",
       "      <td>0.387189</td>\n",
       "      <td>0.649831</td>\n",
       "      <td>0.242766</td>\n",
       "      <td>0.039920</td>\n",
       "      <td>0.018010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.413709</td>\n",
       "      <td>0.124715</td>\n",
       "      <td>0.566561</td>\n",
       "      <td>0.504549</td>\n",
       "      <td>0.358854</td>\n",
       "      <td>-0.412508</td>\n",
       "      <td>0.165960</td>\n",
       "      <td>0.155976</td>\n",
       "      <td>0.141204</td>\n",
       "      <td>0.136883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ENSG00000000003  ENSG00000000005  ENSG00000000419  ENSG00000000457  \\\n",
       "0         0.234678         4.634395         0.086224        -0.043637   \n",
       "1         0.481630        -1.088727         0.393885         0.081690   \n",
       "2        -1.899209         0.540451        -1.775802        -1.289537   \n",
       "3        -1.770320         1.695261        -2.576997        -1.545523   \n",
       "4         0.030564         0.022250         0.283700         0.044262   \n",
       "\n",
       "   ENSG00000000460  ENSG00000000938  ENSG00000000971  ENSG00000001036  \\\n",
       "0        -0.412079        -0.087568         0.141758         0.291403   \n",
       "1         0.255043         0.044410         0.551511         0.174597   \n",
       "2        -1.163083        -0.637282        -1.147808        -1.646437   \n",
       "3        -0.436382        -1.718143        -2.187674        -2.372824   \n",
       "4        -0.163719         0.387189         0.649831         0.242766   \n",
       "\n",
       "   ENSG00000001084  ENSG00000001167  ...  ENSG00000003400  ENSG00000003402  \\\n",
       "0        -0.062944         0.277055  ...         0.203099         0.706053   \n",
       "1         1.796380         0.401716  ...         0.272284         0.510074   \n",
       "2        -1.524145        -2.031053  ...        -1.352449        -0.565953   \n",
       "3        -1.423067        -2.332330  ...        -2.705504        -1.774165   \n",
       "4         0.039920         0.018010  ...         0.413709         0.124715   \n",
       "\n",
       "   ENSG00000003436  ENSG00000003509  ENSG00000003756  ENSG00000003987  \\\n",
       "0         0.797619         0.860695         0.412302        -2.120354   \n",
       "1         0.228360         0.324721         0.454481        -0.326132   \n",
       "2        -0.358369        -2.224981        -1.198323        -1.116561   \n",
       "3        -2.418789        -1.660614        -2.287721         1.000678   \n",
       "4         0.566561         0.504549         0.358854        -0.412508   \n",
       "\n",
       "   ENSG00000003989  ENSG00000004059  ENSG00000004139  ENSG00000004142  \n",
       "0        -0.785904         0.367341        -0.191329         0.659883  \n",
       "1         0.317026         0.230402        -0.414452         0.233399  \n",
       "2        -0.963517        -1.779758        -2.283342        -1.354213  \n",
       "3        -2.448145        -1.655062         0.441241        -1.292560  \n",
       "4         0.165960         0.155976         0.141204         0.136883  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract the feature names for numerical features \n",
    "num_feature_names = lung_df1_4.drop('ID', axis = 1).select_dtypes(include = ['float64', 'int64']).columns\n",
    "\n",
    "# standardize the numerical features using standard scaler\n",
    "standard_scaler = StandardScaler()\n",
    "X_train_res[num_feature_names] = standard_scaler.fit_transform(X_train_res[num_feature_names])\n",
    "X_test[num_feature_names] = standard_scaler.transform(X_test[num_feature_names])\n",
    "\n",
    "# display the transformed input features \n",
    "X_train_res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1,\n",
       "       0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1,\n",
       "       0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "       0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1,\n",
       "       0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0,\n",
       "       1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# standardize the categorical features using label encoder \n",
    "label_encoder = LabelEncoder()\n",
    "y_train_res = label_encoder.fit_transform(y_train_res)\n",
    "y_test = label_encoder.transform(y_test)\n",
    "\n",
    "# display the scaled class labels \n",
    "y_train_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Baseline Model Selection**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting a baseline model using **default parameters** and from **stratified k-fold cross-validation** as well as **hold-out validation**is to establish a robust initial benchmark for model performance, considering both default parameter settings and cross-validation to ensure a reliable comparison across different folds and to provide a solid foundation for subsequent model refinement and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_cross_validation(nSplits, model, X_train, y_train):\n",
    "    \"\"\"\n",
    "    Perform custom cross-validation using StratifiedKFold.\n",
    "    \n",
    "    Parameters:\n",
    "    - nSplits: Number of splits for cross-validation.\n",
    "    - model: Classifier model to be trained and evaluated.\n",
    "    - X_train: Training features.\n",
    "    - y_train: Training labels.\n",
    "    \n",
    "    Returns:\n",
    "    Tuple containing mean training and validation accuracy across folds.\n",
    "    \"\"\"\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits = nSplits, shuffle = True, random_state = 42)\n",
    "\n",
    "    train_acc_list = list()\n",
    "    val_acc_list = list()\n",
    "    \n",
    "    for train_index, val_index in cv.split(X_train, y_train):\n",
    "        X_train_cv, X_val_cv = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "        y_train_cv, y_val_cv = y_train[train_index], y_train[val_index]\n",
    "        \n",
    "        model.fit(X_train_cv, y_train_cv)\n",
    "        \n",
    "        pred_train = model.predict(X_train_cv)\n",
    "        pred_val = model.predict(X_val_cv)\n",
    "        \n",
    "        train_acc = accuracy_score(y_train_cv, pred_train)\n",
    "        train_acc_list.append(train_acc)\n",
    "        val_acc = accuracy_score(y_val_cv, pred_val)\n",
    "        val_acc_list.append(val_acc)\n",
    "    \n",
    "    mean_train_acc = np.mean(train_acc_list)\n",
    "    mean_val_acc = np.mean(val_acc_list)\n",
    "    \n",
    "    return (mean_train_acc, mean_val_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **(A) Decision Tree Classifier**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision Tree Classifier** is a popular machine learning algorithm used for both classification and regression tasks. It works by partitioning the feature space into regions, where each region corresponds to a simple decision rule based on features. Decision trees are easy to interpret and understand, making them useful for exploring relationships in data. They are capable of handling both numerical and categorical data and are robust to outliers and missing values. However, they are prone to overfitting, especially with complex trees, and may not generalize well to unseen data without proper regularization techniques or ensemble methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Stratified K-Fold Cross-Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.89810547875064)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a decision tree classifier with a specified random state and default hyperparameters \n",
    "dtc = DecisionTreeClassifier(random_state = 42)\n",
    "# perform custom cross-validation \n",
    "dtc_scorings = custom_cross_validation(5, dtc, X_train_res, y_train_res)\n",
    "# display the cross-validation scorings \n",
    "dtc_scorings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Hold-Out Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Training Set\n",
      "=========================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       157\n",
      "           1       1.00      1.00      1.00       157\n",
      "\n",
      "    accuracy                           1.00       314\n",
      "   macro avg       1.00      1.00      1.00       314\n",
      "weighted avg       1.00      1.00      1.00       314\n",
      "\n",
      "Classification Report for Testing Set\n",
      "=========================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.87      0.85        23\n",
      "           1       0.92      0.90      0.91        40\n",
      "\n",
      "    accuracy                           0.89        63\n",
      "   macro avg       0.88      0.88      0.88        63\n",
      "weighted avg       0.89      0.89      0.89        63\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fit the decision tree classifier to the training data \n",
    "dtc.fit(X_train_res, y_train_res)\n",
    "\n",
    "# predict labels for the training and testing data \n",
    "dtc_pred_train = dtc.predict(X_train_res)\n",
    "dtc_pred_test = dtc.predict(X_test)\n",
    "\n",
    "# display the classification report for the training and testing data\n",
    "print(\"Classification Report for Training Set\")\n",
    "print(\"=========================================================\")\n",
    "print(classification_report(y_train_res, dtc_pred_train))\n",
    "print(\"Classification Report for Testing Set\")\n",
    "print(\"=========================================================\")\n",
    "print(classification_report(y_test, dtc_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **(B) Random Forest Classifier**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest Classifier** is a powerful ensemble learning method based on decision trees. It operates by constructing multiple decision trees during training and outputs the class that is the mode of the classes (classification) or the mean prediction (regression) of the individual trees. Random forests mitigate overfitting by training each tree on a random subset of the training data and a random subset of the features. They are robust, handle high-dimensional data well, and generally provide high accuracy. Additionally, they can handle missing values and maintain interpretability through feature importance measures. However, they may not perform as well on very imbalanced datasets, and their training time can be longer compared to simpler models. Overall, random forests are a versatile and widely-used algorithm in machine learning for classification and regression tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Stratified K-Fold Cross-Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.977726574500768)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a random forest classifier with a specified random state and default hyperparameters \n",
    "rfc = RandomForestClassifier(random_state = 42)\n",
    "# perform custom cross-validation \n",
    "rfc_scorings = custom_cross_validation(5, rfc, X_train_res, y_train_res)\n",
    "# display the cross-validation scorings \n",
    "rfc_scorings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Hold-Out Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Training Set\n",
      "=========================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       157\n",
      "           1       1.00      1.00      1.00       157\n",
      "\n",
      "    accuracy                           1.00       314\n",
      "   macro avg       1.00      1.00      1.00       314\n",
      "weighted avg       1.00      1.00      1.00       314\n",
      "\n",
      "Classification Report for Testing Set\n",
      "=========================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.91      0.95        23\n",
      "           1       0.95      1.00      0.98        40\n",
      "\n",
      "    accuracy                           0.97        63\n",
      "   macro avg       0.98      0.96      0.97        63\n",
      "weighted avg       0.97      0.97      0.97        63\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fit the random forest classifier to the training data \n",
    "rfc.fit(X_train_res, y_train_res)\n",
    "\n",
    "# predict labels for the training and testing data \n",
    "rfc_pred_train = rfc.predict(X_train_res)\n",
    "rfc_pred_test = rfc.predict(X_test)\n",
    "\n",
    "# display the classification report for the training and testing data\n",
    "print(\"Classification Report for Training Set\")\n",
    "print(\"=========================================================\")\n",
    "print(classification_report(y_train_res, rfc_pred_train))\n",
    "print(\"Classification Report for Testing Set\")\n",
    "print(\"=========================================================\")\n",
    "print(classification_report(y_test, rfc_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **(C) Gradient Boosting Classifier**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gradient Boosting Classifier** is an ensemble learning method that builds a strong predictive model by combining multiple weak learners, typically decision trees, in a sequential manner. Unlike random forests, which train each tree independently, gradient boosting trains trees sequentially, with each tree attempting to correct the errors made by the previous ones. It works by fitting new models to the residual errors of the existing model, gradually improving the overall prediction accuracy. Gradient boosting is known for its high predictive accuracy and ability to handle complex relationships in the data. However, it can be sensitive to overfitting, especially if the number of trees is too large or if the learning rate is not properly tuned. Despite this, gradient boosting is widely used in practice for a variety of machine learning tasks, including classification and regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Stratified K-Fold Cross-Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.9554531490015361)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a gradient boosting classifier with a specified random state and default hyperparameters \n",
    "gbc = GradientBoostingClassifier(random_state = 42)\n",
    "# perform custom cross-validation \n",
    "gbc_scorings = custom_cross_validation(5, gbc, X_train_res, y_train_res)\n",
    "# display the cross-validation scorings \n",
    "gbc_scorings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Hold-Out Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Training Set\n",
      "=========================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       157\n",
      "           1       1.00      1.00      1.00       157\n",
      "\n",
      "    accuracy                           1.00       314\n",
      "   macro avg       1.00      1.00      1.00       314\n",
      "weighted avg       1.00      1.00      1.00       314\n",
      "\n",
      "Classification Report for Testing Set\n",
      "=========================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.87      0.87        23\n",
      "           1       0.93      0.93      0.93        40\n",
      "\n",
      "    accuracy                           0.90        63\n",
      "   macro avg       0.90      0.90      0.90        63\n",
      "weighted avg       0.90      0.90      0.90        63\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fit the gradient boosting classifier to the training data \n",
    "gbc.fit(X_train_res, y_train_res)\n",
    "\n",
    "# predict labels for the training and testing data \n",
    "gbc_pred_train = gbc.predict(X_train_res)\n",
    "gbc_pred_test = gbc.predict(X_test)\n",
    "\n",
    "# display the classification report for the training and testing data\n",
    "print(\"Classification Report for Training Set\")\n",
    "print(\"=========================================================\")\n",
    "print(classification_report(y_train_res, gbc_pred_train))\n",
    "print(\"Classification Report for Testing Set\")\n",
    "print(\"=========================================================\")\n",
    "print(classification_report(y_test, gbc_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **(D) Extra Trees Classifier**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extra Trees Classifier** is an ensemble learning method that belongs to the family of decision tree-based algorithms. Similar to Random Forests, it builds multiple decision trees during training. However, what sets Extra Trees apart is its additional randomness in the selection of feature splits and the construction of the trees. Unlike Random Forests, which select the optimal split based on a subset of features, Extra Trees randomly choose splits for each feature. This randomness helps to reduce variance and increase robustness against overfitting, often resulting in faster training times compared to Random Forests. Extra Trees are particularly useful when dealing with high-dimensional datasets or when computational resources are limited."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Stratified K-Fold Cross-Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.980952380952381)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a extra trees classifier with a specified random state and default hyperparameters \n",
    "etc = ExtraTreesClassifier(random_state = 42)\n",
    "# perform custom cross-validation \n",
    "etc_scorings = custom_cross_validation(5, etc, X_train_res, y_train_res)\n",
    "# display the cross-validation scorings \n",
    "etc_scorings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Hold-Out Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Training Set\n",
      "=========================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       157\n",
      "           1       1.00      1.00      1.00       157\n",
      "\n",
      "    accuracy                           1.00       314\n",
      "   macro avg       1.00      1.00      1.00       314\n",
      "weighted avg       1.00      1.00      1.00       314\n",
      "\n",
      "Classification Report for Testing Set\n",
      "=========================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92        23\n",
      "           1       0.97      0.93      0.95        40\n",
      "\n",
      "    accuracy                           0.94        63\n",
      "   macro avg       0.93      0.94      0.93        63\n",
      "weighted avg       0.94      0.94      0.94        63\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fit the extra trees classifier to the training data \n",
    "etc.fit(X_train_res, y_train_res)\n",
    "\n",
    "# predict labels for the training and testing data \n",
    "etc_pred_train = etc.predict(X_train_res)\n",
    "etc_pred_test = etc.predict(X_test)\n",
    "\n",
    "# display the classification report for the training and testing data\n",
    "print(\"Classification Report for Training Set\")\n",
    "print(\"=========================================================\")\n",
    "print(classification_report(y_train_res, etc_pred_train))\n",
    "print(\"Classification Report for Testing Set\")\n",
    "print(\"=========================================================\")\n",
    "print(classification_report(y_test, etc_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **(E) Adaboost Classifier**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AdaBoost Classifier** is an ensemble learning algorithm that builds a strong classifier by combining multiple weak classifiers sequentially. It works by assigning higher weights to misclassified data points in each iteration, forcing subsequent weak learners to focus more on the difficult-to-classify instances. Through this iterative process, AdaBoost creates a strong model capable of achieving high accuracy even with simple base classifiers. It is particularly effective in handling complex datasets and is less prone to overfitting compared to other ensemble methods. However, AdaBoost may be sensitive to noisy data and outliers. Overall, AdaBoost is a powerful algorithm widely used for classification tasks due to its ability to improve performance over time by continually adapting to the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Stratified K-Fold Cross-Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.9554019457245264)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a adaboost classifier with a specified random state and default hyperparameters \n",
    "abc = AdaBoostClassifier(random_state = 42)\n",
    "# perform custom cross-validation \n",
    "abc_scorings = custom_cross_validation(5, abc, X_train_res, y_train_res)\n",
    "# display the cross-validation scorings \n",
    "abc_scorings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Hold-Out Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Training Set\n",
      "=========================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       157\n",
      "           1       1.00      1.00      1.00       157\n",
      "\n",
      "    accuracy                           1.00       314\n",
      "   macro avg       1.00      1.00      1.00       314\n",
      "weighted avg       1.00      1.00      1.00       314\n",
      "\n",
      "Classification Report for Testing Set\n",
      "=========================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.96      0.90        23\n",
      "           1       0.97      0.90      0.94        40\n",
      "\n",
      "    accuracy                           0.92        63\n",
      "   macro avg       0.91      0.93      0.92        63\n",
      "weighted avg       0.93      0.92      0.92        63\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fit the adaboost classifier to the training data \n",
    "abc.fit(X_train_res, y_train_res)\n",
    "\n",
    "# predict labels for the training and testing data \n",
    "abc_pred_train = abc.predict(X_train_res)\n",
    "abc_pred_test = abc.predict(X_test)\n",
    "\n",
    "# display the classification report for the training and testing data\n",
    "print(\"Classification Report for Training Set\")\n",
    "print(\"=========================================================\")\n",
    "print(classification_report(y_train_res, abc_pred_train))\n",
    "print(\"Classification Report for Testing Set\")\n",
    "print(\"=========================================================\")\n",
    "print(classification_report(y_test, abc_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering both metrics, it seems that the Extra Trees Classifier or Random Forest Classifier has the highest accuracy on both the stratified k-fold validation and the hold-out test set. Therefore, we may want to choose the Extra Trees Classifier or Random Forest Classifier for further hyperparameter optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Hyperparameters Optimization - Random Forest Classifier**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparameter optimization** is crucial for Random Forest Classifier despite its high performance because it allows fine-tuning of parameters to further enhance its effectiveness. While Random Forests are robust and versatile, adjusting hyperparameters such as the number of trees, maximum depth of trees, and minimum samples per leaf can optimize its performance for specific datasets and tasks. Hyperparameter optimization ensures that the Random Forest Classifier is effectively tailored to the characteristics of the data, potentially improving accuracy, generalization, and computational efficiency. This process maximizes the algorithm's potential and ensures that it achieves the best possible performance across different scenarios, ultimately leading to more reliable and accurate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 10, max_depth = 6, min_samples_split = 2, min_samples_leaf = 6 Overall: (Train = 0.9857, Validation = 0.9491)\n",
      "n_estimators = 10, max_depth = 6, min_samples_split = 2, min_samples_leaf = 7 Overall: (Train = 0.9801, Validation = 0.9458)\n",
      "n_estimators = 10, max_depth = 6, min_samples_split = 2, min_samples_leaf = 8 Overall: (Train = 0.9841, Validation = 0.9459)\n",
      "n_estimators = 10, max_depth = 6, min_samples_split = 2, min_samples_leaf = 9 Overall: (Train = 0.9817, Validation = 0.9459)\n",
      "n_estimators = 10, max_depth = 6, min_samples_split = 2, min_samples_leaf = 10 Overall: (Train = 0.9737, Validation = 0.9554)\n",
      "n_estimators = 10, max_depth = 6, min_samples_split = 3, min_samples_leaf = 6 Overall: (Train = 0.9857, Validation = 0.9491)\n",
      "n_estimators = 10, max_depth = 6, min_samples_split = 3, min_samples_leaf = 7 Overall: (Train = 0.9801, Validation = 0.9458)\n",
      "n_estimators = 10, max_depth = 6, min_samples_split = 3, min_samples_leaf = 8 Overall: (Train = 0.9841, Validation = 0.9459)\n",
      "n_estimators = 10, max_depth = 6, min_samples_split = 3, min_samples_leaf = 9 Overall: (Train = 0.9817, Validation = 0.9459)\n",
      "n_estimators = 10, max_depth = 6, min_samples_split = 3, min_samples_leaf = 10 Overall: (Train = 0.9737, Validation = 0.9554)\n",
      "n_estimators = 10, max_depth = 6, min_samples_split = 4, min_samples_leaf = 6 Overall: (Train = 0.9857, Validation = 0.9491)\n",
      "n_estimators = 10, max_depth = 6, min_samples_split = 4, min_samples_leaf = 7 Overall: (Train = 0.9801, Validation = 0.9458)\n",
      "n_estimators = 10, max_depth = 6, min_samples_split = 4, min_samples_leaf = 8 Overall: (Train = 0.9841, Validation = 0.9459)\n",
      "n_estimators = 10, max_depth = 6, min_samples_split = 4, min_samples_leaf = 9 Overall: (Train = 0.9817, Validation = 0.9459)\n",
      "n_estimators = 10, max_depth = 6, min_samples_split = 4, min_samples_leaf = 10 Overall: (Train = 0.9737, Validation = 0.9554)\n",
      "n_estimators = 10, max_depth = 6, min_samples_split = 5, min_samples_leaf = 6 Overall: (Train = 0.9857, Validation = 0.9491)\n",
      "n_estimators = 10, max_depth = 6, min_samples_split = 5, min_samples_leaf = 7 Overall: (Train = 0.9801, Validation = 0.9458)\n",
      "n_estimators = 10, max_depth = 6, min_samples_split = 5, min_samples_leaf = 8 Overall: (Train = 0.9841, Validation = 0.9459)\n",
      "n_estimators = 10, max_depth = 6, min_samples_split = 5, min_samples_leaf = 9 Overall: (Train = 0.9817, Validation = 0.9459)\n",
      "n_estimators = 10, max_depth = 6, min_samples_split = 5, min_samples_leaf = 10 Overall: (Train = 0.9737, Validation = 0.9554)\n",
      "n_estimators = 10, max_depth = 7, min_samples_split = 2, min_samples_leaf = 6 Overall: (Train = 0.9857, Validation = 0.9491)\n",
      "n_estimators = 10, max_depth = 7, min_samples_split = 2, min_samples_leaf = 7 Overall: (Train = 0.9801, Validation = 0.9458)\n",
      "n_estimators = 10, max_depth = 7, min_samples_split = 2, min_samples_leaf = 8 Overall: (Train = 0.9841, Validation = 0.9459)\n",
      "n_estimators = 10, max_depth = 7, min_samples_split = 2, min_samples_leaf = 9 Overall: (Train = 0.9817, Validation = 0.9459)\n",
      "n_estimators = 10, max_depth = 7, min_samples_split = 2, min_samples_leaf = 10 Overall: (Train = 0.9737, Validation = 0.9554)\n",
      "n_estimators = 10, max_depth = 7, min_samples_split = 3, min_samples_leaf = 6 Overall: (Train = 0.9857, Validation = 0.9491)\n",
      "n_estimators = 10, max_depth = 7, min_samples_split = 3, min_samples_leaf = 7 Overall: (Train = 0.9801, Validation = 0.9458)\n",
      "n_estimators = 10, max_depth = 7, min_samples_split = 3, min_samples_leaf = 8 Overall: (Train = 0.9841, Validation = 0.9459)\n",
      "n_estimators = 10, max_depth = 7, min_samples_split = 3, min_samples_leaf = 9 Overall: (Train = 0.9817, Validation = 0.9459)\n",
      "n_estimators = 10, max_depth = 7, min_samples_split = 3, min_samples_leaf = 10 Overall: (Train = 0.9737, Validation = 0.9554)\n",
      "n_estimators = 10, max_depth = 7, min_samples_split = 4, min_samples_leaf = 6 Overall: (Train = 0.9857, Validation = 0.9491)\n",
      "n_estimators = 10, max_depth = 7, min_samples_split = 4, min_samples_leaf = 7 Overall: (Train = 0.9801, Validation = 0.9458)\n",
      "n_estimators = 10, max_depth = 7, min_samples_split = 4, min_samples_leaf = 8 Overall: (Train = 0.9841, Validation = 0.9459)\n",
      "n_estimators = 10, max_depth = 7, min_samples_split = 4, min_samples_leaf = 9 Overall: (Train = 0.9817, Validation = 0.9459)\n",
      "n_estimators = 10, max_depth = 7, min_samples_split = 4, min_samples_leaf = 10 Overall: (Train = 0.9737, Validation = 0.9554)\n",
      "n_estimators = 10, max_depth = 7, min_samples_split = 5, min_samples_leaf = 6 Overall: (Train = 0.9857, Validation = 0.9491)\n",
      "n_estimators = 10, max_depth = 7, min_samples_split = 5, min_samples_leaf = 7 Overall: (Train = 0.9801, Validation = 0.9458)\n",
      "n_estimators = 10, max_depth = 7, min_samples_split = 5, min_samples_leaf = 8 Overall: (Train = 0.9841, Validation = 0.9459)\n",
      "n_estimators = 10, max_depth = 7, min_samples_split = 5, min_samples_leaf = 9 Overall: (Train = 0.9817, Validation = 0.9459)\n",
      "n_estimators = 10, max_depth = 7, min_samples_split = 5, min_samples_leaf = 10 Overall: (Train = 0.9737, Validation = 0.9554)\n",
      "n_estimators = 10, max_depth = 8, min_samples_split = 2, min_samples_leaf = 6 Overall: (Train = 0.9857, Validation = 0.9491)\n",
      "n_estimators = 10, max_depth = 8, min_samples_split = 2, min_samples_leaf = 7 Overall: (Train = 0.9801, Validation = 0.9458)\n",
      "n_estimators = 10, max_depth = 8, min_samples_split = 2, min_samples_leaf = 8 Overall: (Train = 0.9841, Validation = 0.9459)\n",
      "n_estimators = 10, max_depth = 8, min_samples_split = 2, min_samples_leaf = 9 Overall: (Train = 0.9817, Validation = 0.9459)\n",
      "n_estimators = 10, max_depth = 8, min_samples_split = 2, min_samples_leaf = 10 Overall: (Train = 0.9737, Validation = 0.9554)\n",
      "n_estimators = 10, max_depth = 8, min_samples_split = 3, min_samples_leaf = 6 Overall: (Train = 0.9857, Validation = 0.9491)\n",
      "n_estimators = 10, max_depth = 8, min_samples_split = 3, min_samples_leaf = 7 Overall: (Train = 0.9801, Validation = 0.9458)\n",
      "n_estimators = 10, max_depth = 8, min_samples_split = 3, min_samples_leaf = 8 Overall: (Train = 0.9841, Validation = 0.9459)\n",
      "n_estimators = 10, max_depth = 8, min_samples_split = 3, min_samples_leaf = 9 Overall: (Train = 0.9817, Validation = 0.9459)\n",
      "n_estimators = 10, max_depth = 8, min_samples_split = 3, min_samples_leaf = 10 Overall: (Train = 0.9737, Validation = 0.9554)\n",
      "n_estimators = 10, max_depth = 8, min_samples_split = 4, min_samples_leaf = 6 Overall: (Train = 0.9857, Validation = 0.9491)\n",
      "n_estimators = 10, max_depth = 8, min_samples_split = 4, min_samples_leaf = 7 Overall: (Train = 0.9801, Validation = 0.9458)\n",
      "n_estimators = 10, max_depth = 8, min_samples_split = 4, min_samples_leaf = 8 Overall: (Train = 0.9841, Validation = 0.9459)\n",
      "n_estimators = 10, max_depth = 8, min_samples_split = 4, min_samples_leaf = 9 Overall: (Train = 0.9817, Validation = 0.9459)\n",
      "n_estimators = 10, max_depth = 8, min_samples_split = 4, min_samples_leaf = 10 Overall: (Train = 0.9737, Validation = 0.9554)\n",
      "n_estimators = 10, max_depth = 8, min_samples_split = 5, min_samples_leaf = 6 Overall: (Train = 0.9857, Validation = 0.9491)\n",
      "n_estimators = 10, max_depth = 8, min_samples_split = 5, min_samples_leaf = 7 Overall: (Train = 0.9801, Validation = 0.9458)\n",
      "n_estimators = 10, max_depth = 8, min_samples_split = 5, min_samples_leaf = 8 Overall: (Train = 0.9841, Validation = 0.9459)\n",
      "n_estimators = 10, max_depth = 8, min_samples_split = 5, min_samples_leaf = 9 Overall: (Train = 0.9817, Validation = 0.9459)\n",
      "n_estimators = 10, max_depth = 8, min_samples_split = 5, min_samples_leaf = 10 Overall: (Train = 0.9737, Validation = 0.9554)\n",
      "n_estimators = 10, max_depth = 9, min_samples_split = 2, min_samples_leaf = 6 Overall: (Train = 0.9857, Validation = 0.9491)\n",
      "n_estimators = 10, max_depth = 9, min_samples_split = 2, min_samples_leaf = 7 Overall: (Train = 0.9801, Validation = 0.9458)\n",
      "n_estimators = 10, max_depth = 9, min_samples_split = 2, min_samples_leaf = 8 Overall: (Train = 0.9841, Validation = 0.9459)\n",
      "n_estimators = 10, max_depth = 9, min_samples_split = 2, min_samples_leaf = 9 Overall: (Train = 0.9817, Validation = 0.9459)\n",
      "n_estimators = 10, max_depth = 9, min_samples_split = 2, min_samples_leaf = 10 Overall: (Train = 0.9737, Validation = 0.9554)\n",
      "n_estimators = 10, max_depth = 9, min_samples_split = 3, min_samples_leaf = 6 Overall: (Train = 0.9857, Validation = 0.9491)\n",
      "n_estimators = 10, max_depth = 9, min_samples_split = 3, min_samples_leaf = 7 Overall: (Train = 0.9801, Validation = 0.9458)\n",
      "n_estimators = 10, max_depth = 9, min_samples_split = 3, min_samples_leaf = 8 Overall: (Train = 0.9841, Validation = 0.9459)\n",
      "n_estimators = 10, max_depth = 9, min_samples_split = 3, min_samples_leaf = 9 Overall: (Train = 0.9817, Validation = 0.9459)\n",
      "n_estimators = 10, max_depth = 9, min_samples_split = 3, min_samples_leaf = 10 Overall: (Train = 0.9737, Validation = 0.9554)\n",
      "n_estimators = 10, max_depth = 9, min_samples_split = 4, min_samples_leaf = 6 Overall: (Train = 0.9857, Validation = 0.9491)\n",
      "n_estimators = 10, max_depth = 9, min_samples_split = 4, min_samples_leaf = 7 Overall: (Train = 0.9801, Validation = 0.9458)\n",
      "n_estimators = 10, max_depth = 9, min_samples_split = 4, min_samples_leaf = 8 Overall: (Train = 0.9841, Validation = 0.9459)\n",
      "n_estimators = 10, max_depth = 9, min_samples_split = 4, min_samples_leaf = 9 Overall: (Train = 0.9817, Validation = 0.9459)\n",
      "n_estimators = 10, max_depth = 9, min_samples_split = 4, min_samples_leaf = 10 Overall: (Train = 0.9737, Validation = 0.9554)\n",
      "n_estimators = 10, max_depth = 9, min_samples_split = 5, min_samples_leaf = 6 Overall: (Train = 0.9857, Validation = 0.9491)\n",
      "n_estimators = 10, max_depth = 9, min_samples_split = 5, min_samples_leaf = 7 Overall: (Train = 0.9801, Validation = 0.9458)\n",
      "n_estimators = 10, max_depth = 9, min_samples_split = 5, min_samples_leaf = 8 Overall: (Train = 0.9841, Validation = 0.9459)\n",
      "n_estimators = 10, max_depth = 9, min_samples_split = 5, min_samples_leaf = 9 Overall: (Train = 0.9817, Validation = 0.9459)\n",
      "n_estimators = 10, max_depth = 9, min_samples_split = 5, min_samples_leaf = 10 Overall: (Train = 0.9737, Validation = 0.9554)\n",
      "n_estimators = 10, max_depth = 10, min_samples_split = 2, min_samples_leaf = 6 Overall: (Train = 0.9857, Validation = 0.9491)\n",
      "n_estimators = 10, max_depth = 10, min_samples_split = 2, min_samples_leaf = 7 Overall: (Train = 0.9801, Validation = 0.9458)\n",
      "n_estimators = 10, max_depth = 10, min_samples_split = 2, min_samples_leaf = 8 Overall: (Train = 0.9841, Validation = 0.9459)\n",
      "n_estimators = 10, max_depth = 10, min_samples_split = 2, min_samples_leaf = 9 Overall: (Train = 0.9817, Validation = 0.9459)\n",
      "n_estimators = 10, max_depth = 10, min_samples_split = 2, min_samples_leaf = 10 Overall: (Train = 0.9737, Validation = 0.9554)\n",
      "n_estimators = 10, max_depth = 10, min_samples_split = 3, min_samples_leaf = 6 Overall: (Train = 0.9857, Validation = 0.9491)\n",
      "n_estimators = 10, max_depth = 10, min_samples_split = 3, min_samples_leaf = 7 Overall: (Train = 0.9801, Validation = 0.9458)\n",
      "n_estimators = 10, max_depth = 10, min_samples_split = 3, min_samples_leaf = 8 Overall: (Train = 0.9841, Validation = 0.9459)\n",
      "n_estimators = 10, max_depth = 10, min_samples_split = 3, min_samples_leaf = 9 Overall: (Train = 0.9817, Validation = 0.9459)\n",
      "n_estimators = 10, max_depth = 10, min_samples_split = 3, min_samples_leaf = 10 Overall: (Train = 0.9737, Validation = 0.9554)\n",
      "n_estimators = 10, max_depth = 10, min_samples_split = 4, min_samples_leaf = 6 Overall: (Train = 0.9857, Validation = 0.9491)\n",
      "n_estimators = 10, max_depth = 10, min_samples_split = 4, min_samples_leaf = 7 Overall: (Train = 0.9801, Validation = 0.9458)\n",
      "n_estimators = 10, max_depth = 10, min_samples_split = 4, min_samples_leaf = 8 Overall: (Train = 0.9841, Validation = 0.9459)\n",
      "n_estimators = 10, max_depth = 10, min_samples_split = 4, min_samples_leaf = 9 Overall: (Train = 0.9817, Validation = 0.9459)\n",
      "n_estimators = 10, max_depth = 10, min_samples_split = 4, min_samples_leaf = 10 Overall: (Train = 0.9737, Validation = 0.9554)\n",
      "n_estimators = 10, max_depth = 10, min_samples_split = 5, min_samples_leaf = 6 Overall: (Train = 0.9857, Validation = 0.9491)\n",
      "n_estimators = 10, max_depth = 10, min_samples_split = 5, min_samples_leaf = 7 Overall: (Train = 0.9801, Validation = 0.9458)\n",
      "n_estimators = 10, max_depth = 10, min_samples_split = 5, min_samples_leaf = 8 Overall: (Train = 0.9841, Validation = 0.9459)\n",
      "n_estimators = 10, max_depth = 10, min_samples_split = 5, min_samples_leaf = 9 Overall: (Train = 0.9817, Validation = 0.9459)\n",
      "n_estimators = 10, max_depth = 10, min_samples_split = 5, min_samples_leaf = 10 Overall: (Train = 0.9737, Validation = 0.9554)\n",
      "n_estimators = 20, max_depth = 6, min_samples_split = 2, min_samples_leaf = 6 Overall: (Train = 0.9944, Validation = 0.9618)\n",
      "n_estimators = 20, max_depth = 6, min_samples_split = 2, min_samples_leaf = 7 Overall: (Train = 0.9889, Validation = 0.9682)\n",
      "n_estimators = 20, max_depth = 6, min_samples_split = 2, min_samples_leaf = 8 Overall: (Train = 0.9873, Validation = 0.9713)\n",
      "n_estimators = 20, max_depth = 6, min_samples_split = 2, min_samples_leaf = 9 Overall: (Train = 0.9881, Validation = 0.9650)\n",
      "n_estimators = 20, max_depth = 6, min_samples_split = 2, min_samples_leaf = 10 Overall: (Train = 0.9801, Validation = 0.9586)\n",
      "n_estimators = 20, max_depth = 6, min_samples_split = 3, min_samples_leaf = 6 Overall: (Train = 0.9944, Validation = 0.9618)\n",
      "n_estimators = 20, max_depth = 6, min_samples_split = 3, min_samples_leaf = 7 Overall: (Train = 0.9889, Validation = 0.9682)\n",
      "n_estimators = 20, max_depth = 6, min_samples_split = 3, min_samples_leaf = 8 Overall: (Train = 0.9873, Validation = 0.9713)\n",
      "n_estimators = 20, max_depth = 6, min_samples_split = 3, min_samples_leaf = 9 Overall: (Train = 0.9881, Validation = 0.9650)\n",
      "n_estimators = 20, max_depth = 6, min_samples_split = 3, min_samples_leaf = 10 Overall: (Train = 0.9801, Validation = 0.9586)\n",
      "n_estimators = 20, max_depth = 6, min_samples_split = 4, min_samples_leaf = 6 Overall: (Train = 0.9944, Validation = 0.9618)\n",
      "n_estimators = 20, max_depth = 6, min_samples_split = 4, min_samples_leaf = 7 Overall: (Train = 0.9889, Validation = 0.9682)\n",
      "n_estimators = 20, max_depth = 6, min_samples_split = 4, min_samples_leaf = 8 Overall: (Train = 0.9873, Validation = 0.9713)\n",
      "n_estimators = 20, max_depth = 6, min_samples_split = 4, min_samples_leaf = 9 Overall: (Train = 0.9881, Validation = 0.9650)\n",
      "n_estimators = 20, max_depth = 6, min_samples_split = 4, min_samples_leaf = 10 Overall: (Train = 0.9801, Validation = 0.9586)\n",
      "n_estimators = 20, max_depth = 6, min_samples_split = 5, min_samples_leaf = 6 Overall: (Train = 0.9944, Validation = 0.9618)\n",
      "n_estimators = 20, max_depth = 6, min_samples_split = 5, min_samples_leaf = 7 Overall: (Train = 0.9889, Validation = 0.9682)\n",
      "n_estimators = 20, max_depth = 6, min_samples_split = 5, min_samples_leaf = 8 Overall: (Train = 0.9873, Validation = 0.9713)\n",
      "n_estimators = 20, max_depth = 6, min_samples_split = 5, min_samples_leaf = 9 Overall: (Train = 0.9881, Validation = 0.9650)\n",
      "n_estimators = 20, max_depth = 6, min_samples_split = 5, min_samples_leaf = 10 Overall: (Train = 0.9801, Validation = 0.9586)\n",
      "n_estimators = 20, max_depth = 7, min_samples_split = 2, min_samples_leaf = 6 Overall: (Train = 0.9944, Validation = 0.9618)\n",
      "n_estimators = 20, max_depth = 7, min_samples_split = 2, min_samples_leaf = 7 Overall: (Train = 0.9889, Validation = 0.9682)\n",
      "n_estimators = 20, max_depth = 7, min_samples_split = 2, min_samples_leaf = 8 Overall: (Train = 0.9873, Validation = 0.9713)\n",
      "n_estimators = 20, max_depth = 7, min_samples_split = 2, min_samples_leaf = 9 Overall: (Train = 0.9881, Validation = 0.9650)\n",
      "n_estimators = 20, max_depth = 7, min_samples_split = 2, min_samples_leaf = 10 Overall: (Train = 0.9801, Validation = 0.9586)\n",
      "n_estimators = 20, max_depth = 7, min_samples_split = 3, min_samples_leaf = 6 Overall: (Train = 0.9944, Validation = 0.9618)\n",
      "n_estimators = 20, max_depth = 7, min_samples_split = 3, min_samples_leaf = 7 Overall: (Train = 0.9889, Validation = 0.9682)\n",
      "n_estimators = 20, max_depth = 7, min_samples_split = 3, min_samples_leaf = 8 Overall: (Train = 0.9873, Validation = 0.9713)\n",
      "n_estimators = 20, max_depth = 7, min_samples_split = 3, min_samples_leaf = 9 Overall: (Train = 0.9881, Validation = 0.9650)\n",
      "n_estimators = 20, max_depth = 7, min_samples_split = 3, min_samples_leaf = 10 Overall: (Train = 0.9801, Validation = 0.9586)\n",
      "n_estimators = 20, max_depth = 7, min_samples_split = 4, min_samples_leaf = 6 Overall: (Train = 0.9944, Validation = 0.9618)\n",
      "n_estimators = 20, max_depth = 7, min_samples_split = 4, min_samples_leaf = 7 Overall: (Train = 0.9889, Validation = 0.9682)\n",
      "n_estimators = 20, max_depth = 7, min_samples_split = 4, min_samples_leaf = 8 Overall: (Train = 0.9873, Validation = 0.9713)\n",
      "n_estimators = 20, max_depth = 7, min_samples_split = 4, min_samples_leaf = 9 Overall: (Train = 0.9881, Validation = 0.9650)\n",
      "n_estimators = 20, max_depth = 7, min_samples_split = 4, min_samples_leaf = 10 Overall: (Train = 0.9801, Validation = 0.9586)\n",
      "n_estimators = 20, max_depth = 7, min_samples_split = 5, min_samples_leaf = 6 Overall: (Train = 0.9944, Validation = 0.9618)\n",
      "n_estimators = 20, max_depth = 7, min_samples_split = 5, min_samples_leaf = 7 Overall: (Train = 0.9889, Validation = 0.9682)\n",
      "n_estimators = 20, max_depth = 7, min_samples_split = 5, min_samples_leaf = 8 Overall: (Train = 0.9873, Validation = 0.9713)\n",
      "n_estimators = 20, max_depth = 7, min_samples_split = 5, min_samples_leaf = 9 Overall: (Train = 0.9881, Validation = 0.9650)\n",
      "n_estimators = 20, max_depth = 7, min_samples_split = 5, min_samples_leaf = 10 Overall: (Train = 0.9801, Validation = 0.9586)\n",
      "n_estimators = 20, max_depth = 8, min_samples_split = 2, min_samples_leaf = 6 Overall: (Train = 0.9944, Validation = 0.9618)\n",
      "n_estimators = 20, max_depth = 8, min_samples_split = 2, min_samples_leaf = 7 Overall: (Train = 0.9889, Validation = 0.9682)\n",
      "n_estimators = 20, max_depth = 8, min_samples_split = 2, min_samples_leaf = 8 Overall: (Train = 0.9873, Validation = 0.9713)\n",
      "n_estimators = 20, max_depth = 8, min_samples_split = 2, min_samples_leaf = 9 Overall: (Train = 0.9881, Validation = 0.9650)\n",
      "n_estimators = 20, max_depth = 8, min_samples_split = 2, min_samples_leaf = 10 Overall: (Train = 0.9801, Validation = 0.9586)\n",
      "n_estimators = 20, max_depth = 8, min_samples_split = 3, min_samples_leaf = 6 Overall: (Train = 0.9944, Validation = 0.9618)\n",
      "n_estimators = 20, max_depth = 8, min_samples_split = 3, min_samples_leaf = 7 Overall: (Train = 0.9889, Validation = 0.9682)\n",
      "n_estimators = 20, max_depth = 8, min_samples_split = 3, min_samples_leaf = 8 Overall: (Train = 0.9873, Validation = 0.9713)\n",
      "n_estimators = 20, max_depth = 8, min_samples_split = 3, min_samples_leaf = 9 Overall: (Train = 0.9881, Validation = 0.9650)\n",
      "n_estimators = 20, max_depth = 8, min_samples_split = 3, min_samples_leaf = 10 Overall: (Train = 0.9801, Validation = 0.9586)\n",
      "n_estimators = 20, max_depth = 8, min_samples_split = 4, min_samples_leaf = 6 Overall: (Train = 0.9944, Validation = 0.9618)\n",
      "n_estimators = 20, max_depth = 8, min_samples_split = 4, min_samples_leaf = 7 Overall: (Train = 0.9889, Validation = 0.9682)\n",
      "n_estimators = 20, max_depth = 8, min_samples_split = 4, min_samples_leaf = 8 Overall: (Train = 0.9873, Validation = 0.9713)\n",
      "n_estimators = 20, max_depth = 8, min_samples_split = 4, min_samples_leaf = 9 Overall: (Train = 0.9881, Validation = 0.9650)\n",
      "n_estimators = 20, max_depth = 8, min_samples_split = 4, min_samples_leaf = 10 Overall: (Train = 0.9801, Validation = 0.9586)\n",
      "n_estimators = 20, max_depth = 8, min_samples_split = 5, min_samples_leaf = 6 Overall: (Train = 0.9944, Validation = 0.9618)\n",
      "n_estimators = 20, max_depth = 8, min_samples_split = 5, min_samples_leaf = 7 Overall: (Train = 0.9889, Validation = 0.9682)\n",
      "n_estimators = 20, max_depth = 8, min_samples_split = 5, min_samples_leaf = 8 Overall: (Train = 0.9873, Validation = 0.9713)\n",
      "n_estimators = 20, max_depth = 8, min_samples_split = 5, min_samples_leaf = 9 Overall: (Train = 0.9881, Validation = 0.9650)\n",
      "n_estimators = 20, max_depth = 8, min_samples_split = 5, min_samples_leaf = 10 Overall: (Train = 0.9801, Validation = 0.9586)\n",
      "n_estimators = 20, max_depth = 9, min_samples_split = 2, min_samples_leaf = 6 Overall: (Train = 0.9944, Validation = 0.9618)\n",
      "n_estimators = 20, max_depth = 9, min_samples_split = 2, min_samples_leaf = 7 Overall: (Train = 0.9889, Validation = 0.9682)\n",
      "n_estimators = 20, max_depth = 9, min_samples_split = 2, min_samples_leaf = 8 Overall: (Train = 0.9873, Validation = 0.9713)\n",
      "n_estimators = 20, max_depth = 9, min_samples_split = 2, min_samples_leaf = 9 Overall: (Train = 0.9881, Validation = 0.9650)\n",
      "n_estimators = 20, max_depth = 9, min_samples_split = 2, min_samples_leaf = 10 Overall: (Train = 0.9801, Validation = 0.9586)\n",
      "n_estimators = 20, max_depth = 9, min_samples_split = 3, min_samples_leaf = 6 Overall: (Train = 0.9944, Validation = 0.9618)\n",
      "n_estimators = 20, max_depth = 9, min_samples_split = 3, min_samples_leaf = 7 Overall: (Train = 0.9889, Validation = 0.9682)\n",
      "n_estimators = 20, max_depth = 9, min_samples_split = 3, min_samples_leaf = 8 Overall: (Train = 0.9873, Validation = 0.9713)\n",
      "n_estimators = 20, max_depth = 9, min_samples_split = 3, min_samples_leaf = 9 Overall: (Train = 0.9881, Validation = 0.9650)\n",
      "n_estimators = 20, max_depth = 9, min_samples_split = 3, min_samples_leaf = 10 Overall: (Train = 0.9801, Validation = 0.9586)\n",
      "n_estimators = 20, max_depth = 9, min_samples_split = 4, min_samples_leaf = 6 Overall: (Train = 0.9944, Validation = 0.9618)\n",
      "n_estimators = 20, max_depth = 9, min_samples_split = 4, min_samples_leaf = 7 Overall: (Train = 0.9889, Validation = 0.9682)\n",
      "n_estimators = 20, max_depth = 9, min_samples_split = 4, min_samples_leaf = 8 Overall: (Train = 0.9873, Validation = 0.9713)\n",
      "n_estimators = 20, max_depth = 9, min_samples_split = 4, min_samples_leaf = 9 Overall: (Train = 0.9881, Validation = 0.9650)\n",
      "n_estimators = 20, max_depth = 9, min_samples_split = 4, min_samples_leaf = 10 Overall: (Train = 0.9801, Validation = 0.9586)\n",
      "n_estimators = 20, max_depth = 9, min_samples_split = 5, min_samples_leaf = 6 Overall: (Train = 0.9944, Validation = 0.9618)\n",
      "n_estimators = 20, max_depth = 9, min_samples_split = 5, min_samples_leaf = 7 Overall: (Train = 0.9889, Validation = 0.9682)\n",
      "n_estimators = 20, max_depth = 9, min_samples_split = 5, min_samples_leaf = 8 Overall: (Train = 0.9873, Validation = 0.9713)\n",
      "n_estimators = 20, max_depth = 9, min_samples_split = 5, min_samples_leaf = 9 Overall: (Train = 0.9881, Validation = 0.9650)\n",
      "n_estimators = 20, max_depth = 9, min_samples_split = 5, min_samples_leaf = 10 Overall: (Train = 0.9801, Validation = 0.9586)\n",
      "n_estimators = 20, max_depth = 10, min_samples_split = 2, min_samples_leaf = 6 Overall: (Train = 0.9944, Validation = 0.9618)\n",
      "n_estimators = 20, max_depth = 10, min_samples_split = 2, min_samples_leaf = 7 Overall: (Train = 0.9889, Validation = 0.9682)\n",
      "n_estimators = 20, max_depth = 10, min_samples_split = 2, min_samples_leaf = 8 Overall: (Train = 0.9873, Validation = 0.9713)\n",
      "n_estimators = 20, max_depth = 10, min_samples_split = 2, min_samples_leaf = 9 Overall: (Train = 0.9881, Validation = 0.9650)\n",
      "n_estimators = 20, max_depth = 10, min_samples_split = 2, min_samples_leaf = 10 Overall: (Train = 0.9801, Validation = 0.9586)\n",
      "n_estimators = 20, max_depth = 10, min_samples_split = 3, min_samples_leaf = 6 Overall: (Train = 0.9944, Validation = 0.9618)\n",
      "n_estimators = 20, max_depth = 10, min_samples_split = 3, min_samples_leaf = 7 Overall: (Train = 0.9889, Validation = 0.9682)\n",
      "n_estimators = 20, max_depth = 10, min_samples_split = 3, min_samples_leaf = 8 Overall: (Train = 0.9873, Validation = 0.9713)\n",
      "n_estimators = 20, max_depth = 10, min_samples_split = 3, min_samples_leaf = 9 Overall: (Train = 0.9881, Validation = 0.9650)\n",
      "n_estimators = 20, max_depth = 10, min_samples_split = 3, min_samples_leaf = 10 Overall: (Train = 0.9801, Validation = 0.9586)\n",
      "n_estimators = 20, max_depth = 10, min_samples_split = 4, min_samples_leaf = 6 Overall: (Train = 0.9944, Validation = 0.9618)\n",
      "n_estimators = 20, max_depth = 10, min_samples_split = 4, min_samples_leaf = 7 Overall: (Train = 0.9889, Validation = 0.9682)\n",
      "n_estimators = 20, max_depth = 10, min_samples_split = 4, min_samples_leaf = 8 Overall: (Train = 0.9873, Validation = 0.9713)\n",
      "n_estimators = 20, max_depth = 10, min_samples_split = 4, min_samples_leaf = 9 Overall: (Train = 0.9881, Validation = 0.9650)\n",
      "n_estimators = 20, max_depth = 10, min_samples_split = 4, min_samples_leaf = 10 Overall: (Train = 0.9801, Validation = 0.9586)\n",
      "n_estimators = 20, max_depth = 10, min_samples_split = 5, min_samples_leaf = 6 Overall: (Train = 0.9944, Validation = 0.9618)\n",
      "n_estimators = 20, max_depth = 10, min_samples_split = 5, min_samples_leaf = 7 Overall: (Train = 0.9889, Validation = 0.9682)\n",
      "n_estimators = 20, max_depth = 10, min_samples_split = 5, min_samples_leaf = 8 Overall: (Train = 0.9873, Validation = 0.9713)\n",
      "n_estimators = 20, max_depth = 10, min_samples_split = 5, min_samples_leaf = 9 Overall: (Train = 0.9881, Validation = 0.9650)\n",
      "n_estimators = 20, max_depth = 10, min_samples_split = 5, min_samples_leaf = 10 Overall: (Train = 0.9801, Validation = 0.9586)\n",
      "n_estimators = 30, max_depth = 6, min_samples_split = 2, min_samples_leaf = 6 Overall: (Train = 0.9912, Validation = 0.9746)\n",
      "n_estimators = 30, max_depth = 6, min_samples_split = 2, min_samples_leaf = 7 Overall: (Train = 0.9904, Validation = 0.9746)\n",
      "n_estimators = 30, max_depth = 6, min_samples_split = 2, min_samples_leaf = 8 Overall: (Train = 0.9889, Validation = 0.9714)\n",
      "n_estimators = 30, max_depth = 6, min_samples_split = 2, min_samples_leaf = 9 Overall: (Train = 0.9849, Validation = 0.9650)\n",
      "n_estimators = 30, max_depth = 6, min_samples_split = 2, min_samples_leaf = 10 Overall: (Train = 0.9817, Validation = 0.9523)\n",
      "n_estimators = 30, max_depth = 6, min_samples_split = 3, min_samples_leaf = 6 Overall: (Train = 0.9912, Validation = 0.9746)\n",
      "n_estimators = 30, max_depth = 6, min_samples_split = 3, min_samples_leaf = 7 Overall: (Train = 0.9904, Validation = 0.9746)\n",
      "n_estimators = 30, max_depth = 6, min_samples_split = 3, min_samples_leaf = 8 Overall: (Train = 0.9889, Validation = 0.9714)\n",
      "n_estimators = 30, max_depth = 6, min_samples_split = 3, min_samples_leaf = 9 Overall: (Train = 0.9849, Validation = 0.9650)\n",
      "n_estimators = 30, max_depth = 6, min_samples_split = 3, min_samples_leaf = 10 Overall: (Train = 0.9817, Validation = 0.9523)\n",
      "n_estimators = 30, max_depth = 6, min_samples_split = 4, min_samples_leaf = 6 Overall: (Train = 0.9912, Validation = 0.9746)\n",
      "n_estimators = 30, max_depth = 6, min_samples_split = 4, min_samples_leaf = 7 Overall: (Train = 0.9904, Validation = 0.9746)\n",
      "n_estimators = 30, max_depth = 6, min_samples_split = 4, min_samples_leaf = 8 Overall: (Train = 0.9889, Validation = 0.9714)\n",
      "n_estimators = 30, max_depth = 6, min_samples_split = 4, min_samples_leaf = 9 Overall: (Train = 0.9849, Validation = 0.9650)\n",
      "n_estimators = 30, max_depth = 6, min_samples_split = 4, min_samples_leaf = 10 Overall: (Train = 0.9817, Validation = 0.9523)\n",
      "n_estimators = 30, max_depth = 6, min_samples_split = 5, min_samples_leaf = 6 Overall: (Train = 0.9912, Validation = 0.9746)\n",
      "n_estimators = 30, max_depth = 6, min_samples_split = 5, min_samples_leaf = 7 Overall: (Train = 0.9904, Validation = 0.9746)\n",
      "n_estimators = 30, max_depth = 6, min_samples_split = 5, min_samples_leaf = 8 Overall: (Train = 0.9889, Validation = 0.9714)\n",
      "n_estimators = 30, max_depth = 6, min_samples_split = 5, min_samples_leaf = 9 Overall: (Train = 0.9849, Validation = 0.9650)\n",
      "n_estimators = 30, max_depth = 6, min_samples_split = 5, min_samples_leaf = 10 Overall: (Train = 0.9817, Validation = 0.9523)\n",
      "n_estimators = 30, max_depth = 7, min_samples_split = 2, min_samples_leaf = 6 Overall: (Train = 0.9912, Validation = 0.9746)\n",
      "n_estimators = 30, max_depth = 7, min_samples_split = 2, min_samples_leaf = 7 Overall: (Train = 0.9904, Validation = 0.9746)\n",
      "n_estimators = 30, max_depth = 7, min_samples_split = 2, min_samples_leaf = 8 Overall: (Train = 0.9889, Validation = 0.9714)\n",
      "n_estimators = 30, max_depth = 7, min_samples_split = 2, min_samples_leaf = 9 Overall: (Train = 0.9849, Validation = 0.9650)\n",
      "n_estimators = 30, max_depth = 7, min_samples_split = 2, min_samples_leaf = 10 Overall: (Train = 0.9817, Validation = 0.9523)\n",
      "n_estimators = 30, max_depth = 7, min_samples_split = 3, min_samples_leaf = 6 Overall: (Train = 0.9912, Validation = 0.9746)\n",
      "n_estimators = 30, max_depth = 7, min_samples_split = 3, min_samples_leaf = 7 Overall: (Train = 0.9904, Validation = 0.9746)\n",
      "n_estimators = 30, max_depth = 7, min_samples_split = 3, min_samples_leaf = 8 Overall: (Train = 0.9889, Validation = 0.9714)\n",
      "n_estimators = 30, max_depth = 7, min_samples_split = 3, min_samples_leaf = 9 Overall: (Train = 0.9849, Validation = 0.9650)\n",
      "n_estimators = 30, max_depth = 7, min_samples_split = 3, min_samples_leaf = 10 Overall: (Train = 0.9817, Validation = 0.9523)\n",
      "n_estimators = 30, max_depth = 7, min_samples_split = 4, min_samples_leaf = 6 Overall: (Train = 0.9912, Validation = 0.9746)\n",
      "n_estimators = 30, max_depth = 7, min_samples_split = 4, min_samples_leaf = 7 Overall: (Train = 0.9904, Validation = 0.9746)\n",
      "n_estimators = 30, max_depth = 7, min_samples_split = 4, min_samples_leaf = 8 Overall: (Train = 0.9889, Validation = 0.9714)\n",
      "n_estimators = 30, max_depth = 7, min_samples_split = 4, min_samples_leaf = 9 Overall: (Train = 0.9849, Validation = 0.9650)\n",
      "n_estimators = 30, max_depth = 7, min_samples_split = 4, min_samples_leaf = 10 Overall: (Train = 0.9817, Validation = 0.9523)\n",
      "n_estimators = 30, max_depth = 7, min_samples_split = 5, min_samples_leaf = 6 Overall: (Train = 0.9912, Validation = 0.9746)\n",
      "n_estimators = 30, max_depth = 7, min_samples_split = 5, min_samples_leaf = 7 Overall: (Train = 0.9904, Validation = 0.9746)\n",
      "n_estimators = 30, max_depth = 7, min_samples_split = 5, min_samples_leaf = 8 Overall: (Train = 0.9889, Validation = 0.9714)\n",
      "n_estimators = 30, max_depth = 7, min_samples_split = 5, min_samples_leaf = 9 Overall: (Train = 0.9849, Validation = 0.9650)\n",
      "n_estimators = 30, max_depth = 7, min_samples_split = 5, min_samples_leaf = 10 Overall: (Train = 0.9817, Validation = 0.9523)\n",
      "n_estimators = 30, max_depth = 8, min_samples_split = 2, min_samples_leaf = 6 Overall: (Train = 0.9912, Validation = 0.9746)\n",
      "n_estimators = 30, max_depth = 8, min_samples_split = 2, min_samples_leaf = 7 Overall: (Train = 0.9904, Validation = 0.9746)\n",
      "n_estimators = 30, max_depth = 8, min_samples_split = 2, min_samples_leaf = 8 Overall: (Train = 0.9889, Validation = 0.9714)\n",
      "n_estimators = 30, max_depth = 8, min_samples_split = 2, min_samples_leaf = 9 Overall: (Train = 0.9849, Validation = 0.9650)\n",
      "n_estimators = 30, max_depth = 8, min_samples_split = 2, min_samples_leaf = 10 Overall: (Train = 0.9817, Validation = 0.9523)\n",
      "n_estimators = 30, max_depth = 8, min_samples_split = 3, min_samples_leaf = 6 Overall: (Train = 0.9912, Validation = 0.9746)\n",
      "n_estimators = 30, max_depth = 8, min_samples_split = 3, min_samples_leaf = 7 Overall: (Train = 0.9904, Validation = 0.9746)\n",
      "n_estimators = 30, max_depth = 8, min_samples_split = 3, min_samples_leaf = 8 Overall: (Train = 0.9889, Validation = 0.9714)\n",
      "n_estimators = 30, max_depth = 8, min_samples_split = 3, min_samples_leaf = 9 Overall: (Train = 0.9849, Validation = 0.9650)\n",
      "n_estimators = 30, max_depth = 8, min_samples_split = 3, min_samples_leaf = 10 Overall: (Train = 0.9817, Validation = 0.9523)\n",
      "n_estimators = 30, max_depth = 8, min_samples_split = 4, min_samples_leaf = 6 Overall: (Train = 0.9912, Validation = 0.9746)\n",
      "n_estimators = 30, max_depth = 8, min_samples_split = 4, min_samples_leaf = 7 Overall: (Train = 0.9904, Validation = 0.9746)\n",
      "n_estimators = 30, max_depth = 8, min_samples_split = 4, min_samples_leaf = 8 Overall: (Train = 0.9889, Validation = 0.9714)\n",
      "n_estimators = 30, max_depth = 8, min_samples_split = 4, min_samples_leaf = 9 Overall: (Train = 0.9849, Validation = 0.9650)\n",
      "n_estimators = 30, max_depth = 8, min_samples_split = 4, min_samples_leaf = 10 Overall: (Train = 0.9817, Validation = 0.9523)\n",
      "n_estimators = 30, max_depth = 8, min_samples_split = 5, min_samples_leaf = 6 Overall: (Train = 0.9912, Validation = 0.9746)\n",
      "n_estimators = 30, max_depth = 8, min_samples_split = 5, min_samples_leaf = 7 Overall: (Train = 0.9904, Validation = 0.9746)\n",
      "n_estimators = 30, max_depth = 8, min_samples_split = 5, min_samples_leaf = 8 Overall: (Train = 0.9889, Validation = 0.9714)\n",
      "n_estimators = 30, max_depth = 8, min_samples_split = 5, min_samples_leaf = 9 Overall: (Train = 0.9849, Validation = 0.9650)\n",
      "n_estimators = 30, max_depth = 8, min_samples_split = 5, min_samples_leaf = 10 Overall: (Train = 0.9817, Validation = 0.9523)\n",
      "n_estimators = 30, max_depth = 9, min_samples_split = 2, min_samples_leaf = 6 Overall: (Train = 0.9912, Validation = 0.9746)\n",
      "n_estimators = 30, max_depth = 9, min_samples_split = 2, min_samples_leaf = 7 Overall: (Train = 0.9904, Validation = 0.9746)\n",
      "n_estimators = 30, max_depth = 9, min_samples_split = 2, min_samples_leaf = 8 Overall: (Train = 0.9889, Validation = 0.9714)\n",
      "n_estimators = 30, max_depth = 9, min_samples_split = 2, min_samples_leaf = 9 Overall: (Train = 0.9849, Validation = 0.9650)\n",
      "n_estimators = 30, max_depth = 9, min_samples_split = 2, min_samples_leaf = 10 Overall: (Train = 0.9817, Validation = 0.9523)\n",
      "n_estimators = 30, max_depth = 9, min_samples_split = 3, min_samples_leaf = 6 Overall: (Train = 0.9912, Validation = 0.9746)\n",
      "n_estimators = 30, max_depth = 9, min_samples_split = 3, min_samples_leaf = 7 Overall: (Train = 0.9904, Validation = 0.9746)\n",
      "n_estimators = 30, max_depth = 9, min_samples_split = 3, min_samples_leaf = 8 Overall: (Train = 0.9889, Validation = 0.9714)\n",
      "n_estimators = 30, max_depth = 9, min_samples_split = 3, min_samples_leaf = 9 Overall: (Train = 0.9849, Validation = 0.9650)\n",
      "n_estimators = 30, max_depth = 9, min_samples_split = 3, min_samples_leaf = 10 Overall: (Train = 0.9817, Validation = 0.9523)\n",
      "n_estimators = 30, max_depth = 9, min_samples_split = 4, min_samples_leaf = 6 Overall: (Train = 0.9912, Validation = 0.9746)\n",
      "n_estimators = 30, max_depth = 9, min_samples_split = 4, min_samples_leaf = 7 Overall: (Train = 0.9904, Validation = 0.9746)\n",
      "n_estimators = 30, max_depth = 9, min_samples_split = 4, min_samples_leaf = 8 Overall: (Train = 0.9889, Validation = 0.9714)\n",
      "n_estimators = 30, max_depth = 9, min_samples_split = 4, min_samples_leaf = 9 Overall: (Train = 0.9849, Validation = 0.9650)\n",
      "n_estimators = 30, max_depth = 9, min_samples_split = 4, min_samples_leaf = 10 Overall: (Train = 0.9817, Validation = 0.9523)\n",
      "n_estimators = 30, max_depth = 9, min_samples_split = 5, min_samples_leaf = 6 Overall: (Train = 0.9912, Validation = 0.9746)\n",
      "n_estimators = 30, max_depth = 9, min_samples_split = 5, min_samples_leaf = 7 Overall: (Train = 0.9904, Validation = 0.9746)\n",
      "n_estimators = 30, max_depth = 9, min_samples_split = 5, min_samples_leaf = 8 Overall: (Train = 0.9889, Validation = 0.9714)\n",
      "n_estimators = 30, max_depth = 9, min_samples_split = 5, min_samples_leaf = 9 Overall: (Train = 0.9849, Validation = 0.9650)\n",
      "n_estimators = 30, max_depth = 9, min_samples_split = 5, min_samples_leaf = 10 Overall: (Train = 0.9817, Validation = 0.9523)\n",
      "n_estimators = 30, max_depth = 10, min_samples_split = 2, min_samples_leaf = 6 Overall: (Train = 0.9912, Validation = 0.9746)\n",
      "n_estimators = 30, max_depth = 10, min_samples_split = 2, min_samples_leaf = 7 Overall: (Train = 0.9904, Validation = 0.9746)\n",
      "n_estimators = 30, max_depth = 10, min_samples_split = 2, min_samples_leaf = 8 Overall: (Train = 0.9889, Validation = 0.9714)\n",
      "n_estimators = 30, max_depth = 10, min_samples_split = 2, min_samples_leaf = 9 Overall: (Train = 0.9849, Validation = 0.9650)\n",
      "n_estimators = 30, max_depth = 10, min_samples_split = 2, min_samples_leaf = 10 Overall: (Train = 0.9817, Validation = 0.9523)\n",
      "n_estimators = 30, max_depth = 10, min_samples_split = 3, min_samples_leaf = 6 Overall: (Train = 0.9912, Validation = 0.9746)\n",
      "n_estimators = 30, max_depth = 10, min_samples_split = 3, min_samples_leaf = 7 Overall: (Train = 0.9904, Validation = 0.9746)\n",
      "n_estimators = 30, max_depth = 10, min_samples_split = 3, min_samples_leaf = 8 Overall: (Train = 0.9889, Validation = 0.9714)\n",
      "n_estimators = 30, max_depth = 10, min_samples_split = 3, min_samples_leaf = 9 Overall: (Train = 0.9849, Validation = 0.9650)\n",
      "n_estimators = 30, max_depth = 10, min_samples_split = 3, min_samples_leaf = 10 Overall: (Train = 0.9817, Validation = 0.9523)\n",
      "n_estimators = 30, max_depth = 10, min_samples_split = 4, min_samples_leaf = 6 Overall: (Train = 0.9912, Validation = 0.9746)\n",
      "n_estimators = 30, max_depth = 10, min_samples_split = 4, min_samples_leaf = 7 Overall: (Train = 0.9904, Validation = 0.9746)\n",
      "n_estimators = 30, max_depth = 10, min_samples_split = 4, min_samples_leaf = 8 Overall: (Train = 0.9889, Validation = 0.9714)\n",
      "n_estimators = 30, max_depth = 10, min_samples_split = 4, min_samples_leaf = 9 Overall: (Train = 0.9849, Validation = 0.9650)\n",
      "n_estimators = 30, max_depth = 10, min_samples_split = 4, min_samples_leaf = 10 Overall: (Train = 0.9817, Validation = 0.9523)\n",
      "n_estimators = 30, max_depth = 10, min_samples_split = 5, min_samples_leaf = 6 Overall: (Train = 0.9912, Validation = 0.9746)\n",
      "n_estimators = 30, max_depth = 10, min_samples_split = 5, min_samples_leaf = 7 Overall: (Train = 0.9904, Validation = 0.9746)\n",
      "n_estimators = 30, max_depth = 10, min_samples_split = 5, min_samples_leaf = 8 Overall: (Train = 0.9889, Validation = 0.9714)\n",
      "n_estimators = 30, max_depth = 10, min_samples_split = 5, min_samples_leaf = 9 Overall: (Train = 0.9849, Validation = 0.9650)\n",
      "n_estimators = 30, max_depth = 10, min_samples_split = 5, min_samples_leaf = 10 Overall: (Train = 0.9817, Validation = 0.9523)\n",
      "n_estimators = 40, max_depth = 6, min_samples_split = 2, min_samples_leaf = 6 Overall: (Train = 0.9897, Validation = 0.9650)\n",
      "n_estimators = 40, max_depth = 6, min_samples_split = 2, min_samples_leaf = 7 Overall: (Train = 0.9865, Validation = 0.9650)\n",
      "n_estimators = 40, max_depth = 6, min_samples_split = 2, min_samples_leaf = 8 Overall: (Train = 0.9857, Validation = 0.9618)\n",
      "n_estimators = 40, max_depth = 6, min_samples_split = 2, min_samples_leaf = 9 Overall: (Train = 0.9825, Validation = 0.9555)\n",
      "n_estimators = 40, max_depth = 6, min_samples_split = 2, min_samples_leaf = 10 Overall: (Train = 0.9761, Validation = 0.9586)\n",
      "n_estimators = 40, max_depth = 6, min_samples_split = 3, min_samples_leaf = 6 Overall: (Train = 0.9897, Validation = 0.9650)\n",
      "n_estimators = 40, max_depth = 6, min_samples_split = 3, min_samples_leaf = 7 Overall: (Train = 0.9865, Validation = 0.9650)\n",
      "n_estimators = 40, max_depth = 6, min_samples_split = 3, min_samples_leaf = 8 Overall: (Train = 0.9857, Validation = 0.9618)\n",
      "n_estimators = 40, max_depth = 6, min_samples_split = 3, min_samples_leaf = 9 Overall: (Train = 0.9825, Validation = 0.9555)\n",
      "n_estimators = 40, max_depth = 6, min_samples_split = 3, min_samples_leaf = 10 Overall: (Train = 0.9761, Validation = 0.9586)\n",
      "n_estimators = 40, max_depth = 6, min_samples_split = 4, min_samples_leaf = 6 Overall: (Train = 0.9897, Validation = 0.9650)\n",
      "n_estimators = 40, max_depth = 6, min_samples_split = 4, min_samples_leaf = 7 Overall: (Train = 0.9865, Validation = 0.9650)\n",
      "n_estimators = 40, max_depth = 6, min_samples_split = 4, min_samples_leaf = 8 Overall: (Train = 0.9857, Validation = 0.9618)\n",
      "n_estimators = 40, max_depth = 6, min_samples_split = 4, min_samples_leaf = 9 Overall: (Train = 0.9825, Validation = 0.9555)\n",
      "n_estimators = 40, max_depth = 6, min_samples_split = 4, min_samples_leaf = 10 Overall: (Train = 0.9761, Validation = 0.9586)\n",
      "n_estimators = 40, max_depth = 6, min_samples_split = 5, min_samples_leaf = 6 Overall: (Train = 0.9897, Validation = 0.9650)\n",
      "n_estimators = 40, max_depth = 6, min_samples_split = 5, min_samples_leaf = 7 Overall: (Train = 0.9865, Validation = 0.9650)\n",
      "n_estimators = 40, max_depth = 6, min_samples_split = 5, min_samples_leaf = 8 Overall: (Train = 0.9857, Validation = 0.9618)\n",
      "n_estimators = 40, max_depth = 6, min_samples_split = 5, min_samples_leaf = 9 Overall: (Train = 0.9825, Validation = 0.9555)\n",
      "n_estimators = 40, max_depth = 6, min_samples_split = 5, min_samples_leaf = 10 Overall: (Train = 0.9761, Validation = 0.9586)\n",
      "n_estimators = 40, max_depth = 7, min_samples_split = 2, min_samples_leaf = 6 Overall: (Train = 0.9897, Validation = 0.9650)\n",
      "n_estimators = 40, max_depth = 7, min_samples_split = 2, min_samples_leaf = 7 Overall: (Train = 0.9873, Validation = 0.9650)\n",
      "n_estimators = 40, max_depth = 7, min_samples_split = 2, min_samples_leaf = 8 Overall: (Train = 0.9857, Validation = 0.9618)\n",
      "n_estimators = 40, max_depth = 7, min_samples_split = 2, min_samples_leaf = 9 Overall: (Train = 0.9825, Validation = 0.9555)\n",
      "n_estimators = 40, max_depth = 7, min_samples_split = 2, min_samples_leaf = 10 Overall: (Train = 0.9761, Validation = 0.9586)\n",
      "n_estimators = 40, max_depth = 7, min_samples_split = 3, min_samples_leaf = 6 Overall: (Train = 0.9897, Validation = 0.9650)\n",
      "n_estimators = 40, max_depth = 7, min_samples_split = 3, min_samples_leaf = 7 Overall: (Train = 0.9873, Validation = 0.9650)\n",
      "n_estimators = 40, max_depth = 7, min_samples_split = 3, min_samples_leaf = 8 Overall: (Train = 0.9857, Validation = 0.9618)\n",
      "n_estimators = 40, max_depth = 7, min_samples_split = 3, min_samples_leaf = 9 Overall: (Train = 0.9825, Validation = 0.9555)\n",
      "n_estimators = 40, max_depth = 7, min_samples_split = 3, min_samples_leaf = 10 Overall: (Train = 0.9761, Validation = 0.9586)\n",
      "n_estimators = 40, max_depth = 7, min_samples_split = 4, min_samples_leaf = 6 Overall: (Train = 0.9897, Validation = 0.9650)\n",
      "n_estimators = 40, max_depth = 7, min_samples_split = 4, min_samples_leaf = 7 Overall: (Train = 0.9873, Validation = 0.9650)\n",
      "n_estimators = 40, max_depth = 7, min_samples_split = 4, min_samples_leaf = 8 Overall: (Train = 0.9857, Validation = 0.9618)\n",
      "n_estimators = 40, max_depth = 7, min_samples_split = 4, min_samples_leaf = 9 Overall: (Train = 0.9825, Validation = 0.9555)\n",
      "n_estimators = 40, max_depth = 7, min_samples_split = 4, min_samples_leaf = 10 Overall: (Train = 0.9761, Validation = 0.9586)\n",
      "n_estimators = 40, max_depth = 7, min_samples_split = 5, min_samples_leaf = 6 Overall: (Train = 0.9897, Validation = 0.9650)\n",
      "n_estimators = 40, max_depth = 7, min_samples_split = 5, min_samples_leaf = 7 Overall: (Train = 0.9873, Validation = 0.9650)\n",
      "n_estimators = 40, max_depth = 7, min_samples_split = 5, min_samples_leaf = 8 Overall: (Train = 0.9857, Validation = 0.9618)\n",
      "n_estimators = 40, max_depth = 7, min_samples_split = 5, min_samples_leaf = 9 Overall: (Train = 0.9825, Validation = 0.9555)\n",
      "n_estimators = 40, max_depth = 7, min_samples_split = 5, min_samples_leaf = 10 Overall: (Train = 0.9761, Validation = 0.9586)\n",
      "n_estimators = 40, max_depth = 8, min_samples_split = 2, min_samples_leaf = 6 Overall: (Train = 0.9897, Validation = 0.9650)\n",
      "n_estimators = 40, max_depth = 8, min_samples_split = 2, min_samples_leaf = 7 Overall: (Train = 0.9873, Validation = 0.9650)\n",
      "n_estimators = 40, max_depth = 8, min_samples_split = 2, min_samples_leaf = 8 Overall: (Train = 0.9857, Validation = 0.9618)\n",
      "n_estimators = 40, max_depth = 8, min_samples_split = 2, min_samples_leaf = 9 Overall: (Train = 0.9825, Validation = 0.9555)\n",
      "n_estimators = 40, max_depth = 8, min_samples_split = 2, min_samples_leaf = 10 Overall: (Train = 0.9761, Validation = 0.9586)\n",
      "n_estimators = 40, max_depth = 8, min_samples_split = 3, min_samples_leaf = 6 Overall: (Train = 0.9897, Validation = 0.9650)\n",
      "n_estimators = 40, max_depth = 8, min_samples_split = 3, min_samples_leaf = 7 Overall: (Train = 0.9873, Validation = 0.9650)\n",
      "n_estimators = 40, max_depth = 8, min_samples_split = 3, min_samples_leaf = 8 Overall: (Train = 0.9857, Validation = 0.9618)\n",
      "n_estimators = 40, max_depth = 8, min_samples_split = 3, min_samples_leaf = 9 Overall: (Train = 0.9825, Validation = 0.9555)\n",
      "n_estimators = 40, max_depth = 8, min_samples_split = 3, min_samples_leaf = 10 Overall: (Train = 0.9761, Validation = 0.9586)\n",
      "n_estimators = 40, max_depth = 8, min_samples_split = 4, min_samples_leaf = 6 Overall: (Train = 0.9897, Validation = 0.9650)\n",
      "n_estimators = 40, max_depth = 8, min_samples_split = 4, min_samples_leaf = 7 Overall: (Train = 0.9873, Validation = 0.9650)\n",
      "n_estimators = 40, max_depth = 8, min_samples_split = 4, min_samples_leaf = 8 Overall: (Train = 0.9857, Validation = 0.9618)\n",
      "n_estimators = 40, max_depth = 8, min_samples_split = 4, min_samples_leaf = 9 Overall: (Train = 0.9825, Validation = 0.9555)\n",
      "n_estimators = 40, max_depth = 8, min_samples_split = 4, min_samples_leaf = 10 Overall: (Train = 0.9761, Validation = 0.9586)\n",
      "n_estimators = 40, max_depth = 8, min_samples_split = 5, min_samples_leaf = 6 Overall: (Train = 0.9897, Validation = 0.9650)\n",
      "n_estimators = 40, max_depth = 8, min_samples_split = 5, min_samples_leaf = 7 Overall: (Train = 0.9873, Validation = 0.9650)\n",
      "n_estimators = 40, max_depth = 8, min_samples_split = 5, min_samples_leaf = 8 Overall: (Train = 0.9857, Validation = 0.9618)\n",
      "n_estimators = 40, max_depth = 8, min_samples_split = 5, min_samples_leaf = 9 Overall: (Train = 0.9825, Validation = 0.9555)\n",
      "n_estimators = 40, max_depth = 8, min_samples_split = 5, min_samples_leaf = 10 Overall: (Train = 0.9761, Validation = 0.9586)\n",
      "n_estimators = 40, max_depth = 9, min_samples_split = 2, min_samples_leaf = 6 Overall: (Train = 0.9897, Validation = 0.9650)\n",
      "n_estimators = 40, max_depth = 9, min_samples_split = 2, min_samples_leaf = 7 Overall: (Train = 0.9873, Validation = 0.9650)\n",
      "n_estimators = 40, max_depth = 9, min_samples_split = 2, min_samples_leaf = 8 Overall: (Train = 0.9857, Validation = 0.9618)\n",
      "n_estimators = 40, max_depth = 9, min_samples_split = 2, min_samples_leaf = 9 Overall: (Train = 0.9825, Validation = 0.9555)\n",
      "n_estimators = 40, max_depth = 9, min_samples_split = 2, min_samples_leaf = 10 Overall: (Train = 0.9761, Validation = 0.9586)\n",
      "n_estimators = 40, max_depth = 9, min_samples_split = 3, min_samples_leaf = 6 Overall: (Train = 0.9897, Validation = 0.9650)\n",
      "n_estimators = 40, max_depth = 9, min_samples_split = 3, min_samples_leaf = 7 Overall: (Train = 0.9873, Validation = 0.9650)\n",
      "n_estimators = 40, max_depth = 9, min_samples_split = 3, min_samples_leaf = 8 Overall: (Train = 0.9857, Validation = 0.9618)\n",
      "n_estimators = 40, max_depth = 9, min_samples_split = 3, min_samples_leaf = 9 Overall: (Train = 0.9825, Validation = 0.9555)\n",
      "n_estimators = 40, max_depth = 9, min_samples_split = 3, min_samples_leaf = 10 Overall: (Train = 0.9761, Validation = 0.9586)\n",
      "n_estimators = 40, max_depth = 9, min_samples_split = 4, min_samples_leaf = 6 Overall: (Train = 0.9897, Validation = 0.9650)\n",
      "n_estimators = 40, max_depth = 9, min_samples_split = 4, min_samples_leaf = 7 Overall: (Train = 0.9873, Validation = 0.9650)\n",
      "n_estimators = 40, max_depth = 9, min_samples_split = 4, min_samples_leaf = 8 Overall: (Train = 0.9857, Validation = 0.9618)\n",
      "n_estimators = 40, max_depth = 9, min_samples_split = 4, min_samples_leaf = 9 Overall: (Train = 0.9825, Validation = 0.9555)\n",
      "n_estimators = 40, max_depth = 9, min_samples_split = 4, min_samples_leaf = 10 Overall: (Train = 0.9761, Validation = 0.9586)\n",
      "n_estimators = 40, max_depth = 9, min_samples_split = 5, min_samples_leaf = 6 Overall: (Train = 0.9897, Validation = 0.9650)\n",
      "n_estimators = 40, max_depth = 9, min_samples_split = 5, min_samples_leaf = 7 Overall: (Train = 0.9873, Validation = 0.9650)\n",
      "n_estimators = 40, max_depth = 9, min_samples_split = 5, min_samples_leaf = 8 Overall: (Train = 0.9857, Validation = 0.9618)\n",
      "n_estimators = 40, max_depth = 9, min_samples_split = 5, min_samples_leaf = 9 Overall: (Train = 0.9825, Validation = 0.9555)\n",
      "n_estimators = 40, max_depth = 9, min_samples_split = 5, min_samples_leaf = 10 Overall: (Train = 0.9761, Validation = 0.9586)\n",
      "n_estimators = 40, max_depth = 10, min_samples_split = 2, min_samples_leaf = 6 Overall: (Train = 0.9897, Validation = 0.9650)\n",
      "n_estimators = 40, max_depth = 10, min_samples_split = 2, min_samples_leaf = 7 Overall: (Train = 0.9873, Validation = 0.9650)\n",
      "n_estimators = 40, max_depth = 10, min_samples_split = 2, min_samples_leaf = 8 Overall: (Train = 0.9857, Validation = 0.9618)\n",
      "n_estimators = 40, max_depth = 10, min_samples_split = 2, min_samples_leaf = 9 Overall: (Train = 0.9825, Validation = 0.9555)\n",
      "n_estimators = 40, max_depth = 10, min_samples_split = 2, min_samples_leaf = 10 Overall: (Train = 0.9761, Validation = 0.9586)\n",
      "n_estimators = 40, max_depth = 10, min_samples_split = 3, min_samples_leaf = 6 Overall: (Train = 0.9897, Validation = 0.9650)\n",
      "n_estimators = 40, max_depth = 10, min_samples_split = 3, min_samples_leaf = 7 Overall: (Train = 0.9873, Validation = 0.9650)\n",
      "n_estimators = 40, max_depth = 10, min_samples_split = 3, min_samples_leaf = 8 Overall: (Train = 0.9857, Validation = 0.9618)\n",
      "n_estimators = 40, max_depth = 10, min_samples_split = 3, min_samples_leaf = 9 Overall: (Train = 0.9825, Validation = 0.9555)\n",
      "n_estimators = 40, max_depth = 10, min_samples_split = 3, min_samples_leaf = 10 Overall: (Train = 0.9761, Validation = 0.9586)\n",
      "n_estimators = 40, max_depth = 10, min_samples_split = 4, min_samples_leaf = 6 Overall: (Train = 0.9897, Validation = 0.9650)\n",
      "n_estimators = 40, max_depth = 10, min_samples_split = 4, min_samples_leaf = 7 Overall: (Train = 0.9873, Validation = 0.9650)\n",
      "n_estimators = 40, max_depth = 10, min_samples_split = 4, min_samples_leaf = 8 Overall: (Train = 0.9857, Validation = 0.9618)\n",
      "n_estimators = 40, max_depth = 10, min_samples_split = 4, min_samples_leaf = 9 Overall: (Train = 0.9825, Validation = 0.9555)\n",
      "n_estimators = 40, max_depth = 10, min_samples_split = 4, min_samples_leaf = 10 Overall: (Train = 0.9761, Validation = 0.9586)\n",
      "n_estimators = 40, max_depth = 10, min_samples_split = 5, min_samples_leaf = 6 Overall: (Train = 0.9897, Validation = 0.9650)\n",
      "n_estimators = 40, max_depth = 10, min_samples_split = 5, min_samples_leaf = 7 Overall: (Train = 0.9873, Validation = 0.9650)\n",
      "n_estimators = 40, max_depth = 10, min_samples_split = 5, min_samples_leaf = 8 Overall: (Train = 0.9857, Validation = 0.9618)\n",
      "n_estimators = 40, max_depth = 10, min_samples_split = 5, min_samples_leaf = 9 Overall: (Train = 0.9825, Validation = 0.9555)\n",
      "n_estimators = 40, max_depth = 10, min_samples_split = 5, min_samples_leaf = 10 Overall: (Train = 0.9761, Validation = 0.9586)\n",
      "n_estimators = 50, max_depth = 6, min_samples_split = 2, min_samples_leaf = 6 Overall: (Train = 0.9920, Validation = 0.9713)\n",
      "n_estimators = 50, max_depth = 6, min_samples_split = 2, min_samples_leaf = 7 Overall: (Train = 0.9904, Validation = 0.9618)\n",
      "n_estimators = 50, max_depth = 6, min_samples_split = 2, min_samples_leaf = 8 Overall: (Train = 0.9849, Validation = 0.9618)\n",
      "n_estimators = 50, max_depth = 6, min_samples_split = 2, min_samples_leaf = 9 Overall: (Train = 0.9817, Validation = 0.9554)\n",
      "n_estimators = 50, max_depth = 6, min_samples_split = 2, min_samples_leaf = 10 Overall: (Train = 0.9769, Validation = 0.9554)\n",
      "n_estimators = 50, max_depth = 6, min_samples_split = 3, min_samples_leaf = 6 Overall: (Train = 0.9920, Validation = 0.9713)\n",
      "n_estimators = 50, max_depth = 6, min_samples_split = 3, min_samples_leaf = 7 Overall: (Train = 0.9904, Validation = 0.9618)\n",
      "n_estimators = 50, max_depth = 6, min_samples_split = 3, min_samples_leaf = 8 Overall: (Train = 0.9849, Validation = 0.9618)\n",
      "n_estimators = 50, max_depth = 6, min_samples_split = 3, min_samples_leaf = 9 Overall: (Train = 0.9817, Validation = 0.9554)\n",
      "n_estimators = 50, max_depth = 6, min_samples_split = 3, min_samples_leaf = 10 Overall: (Train = 0.9769, Validation = 0.9554)\n",
      "n_estimators = 50, max_depth = 6, min_samples_split = 4, min_samples_leaf = 6 Overall: (Train = 0.9920, Validation = 0.9713)\n",
      "n_estimators = 50, max_depth = 6, min_samples_split = 4, min_samples_leaf = 7 Overall: (Train = 0.9904, Validation = 0.9618)\n",
      "n_estimators = 50, max_depth = 6, min_samples_split = 4, min_samples_leaf = 8 Overall: (Train = 0.9849, Validation = 0.9618)\n",
      "n_estimators = 50, max_depth = 6, min_samples_split = 4, min_samples_leaf = 9 Overall: (Train = 0.9817, Validation = 0.9554)\n",
      "n_estimators = 50, max_depth = 6, min_samples_split = 4, min_samples_leaf = 10 Overall: (Train = 0.9769, Validation = 0.9554)\n",
      "n_estimators = 50, max_depth = 6, min_samples_split = 5, min_samples_leaf = 6 Overall: (Train = 0.9920, Validation = 0.9713)\n",
      "n_estimators = 50, max_depth = 6, min_samples_split = 5, min_samples_leaf = 7 Overall: (Train = 0.9904, Validation = 0.9618)\n",
      "n_estimators = 50, max_depth = 6, min_samples_split = 5, min_samples_leaf = 8 Overall: (Train = 0.9849, Validation = 0.9618)\n",
      "n_estimators = 50, max_depth = 6, min_samples_split = 5, min_samples_leaf = 9 Overall: (Train = 0.9817, Validation = 0.9554)\n",
      "n_estimators = 50, max_depth = 6, min_samples_split = 5, min_samples_leaf = 10 Overall: (Train = 0.9769, Validation = 0.9554)\n",
      "n_estimators = 50, max_depth = 7, min_samples_split = 2, min_samples_leaf = 6 Overall: (Train = 0.9920, Validation = 0.9682)\n",
      "n_estimators = 50, max_depth = 7, min_samples_split = 2, min_samples_leaf = 7 Overall: (Train = 0.9904, Validation = 0.9618)\n",
      "n_estimators = 50, max_depth = 7, min_samples_split = 2, min_samples_leaf = 8 Overall: (Train = 0.9849, Validation = 0.9618)\n",
      "n_estimators = 50, max_depth = 7, min_samples_split = 2, min_samples_leaf = 9 Overall: (Train = 0.9817, Validation = 0.9554)\n",
      "n_estimators = 50, max_depth = 7, min_samples_split = 2, min_samples_leaf = 10 Overall: (Train = 0.9777, Validation = 0.9554)\n",
      "n_estimators = 50, max_depth = 7, min_samples_split = 3, min_samples_leaf = 6 Overall: (Train = 0.9920, Validation = 0.9682)\n",
      "n_estimators = 50, max_depth = 7, min_samples_split = 3, min_samples_leaf = 7 Overall: (Train = 0.9904, Validation = 0.9618)\n",
      "n_estimators = 50, max_depth = 7, min_samples_split = 3, min_samples_leaf = 8 Overall: (Train = 0.9849, Validation = 0.9618)\n",
      "n_estimators = 50, max_depth = 7, min_samples_split = 3, min_samples_leaf = 9 Overall: (Train = 0.9817, Validation = 0.9554)\n",
      "n_estimators = 50, max_depth = 7, min_samples_split = 3, min_samples_leaf = 10 Overall: (Train = 0.9777, Validation = 0.9554)\n",
      "n_estimators = 50, max_depth = 7, min_samples_split = 4, min_samples_leaf = 6 Overall: (Train = 0.9920, Validation = 0.9682)\n",
      "n_estimators = 50, max_depth = 7, min_samples_split = 4, min_samples_leaf = 7 Overall: (Train = 0.9904, Validation = 0.9618)\n",
      "n_estimators = 50, max_depth = 7, min_samples_split = 4, min_samples_leaf = 8 Overall: (Train = 0.9849, Validation = 0.9618)\n",
      "n_estimators = 50, max_depth = 7, min_samples_split = 4, min_samples_leaf = 9 Overall: (Train = 0.9817, Validation = 0.9554)\n",
      "n_estimators = 50, max_depth = 7, min_samples_split = 4, min_samples_leaf = 10 Overall: (Train = 0.9777, Validation = 0.9554)\n",
      "n_estimators = 50, max_depth = 7, min_samples_split = 5, min_samples_leaf = 6 Overall: (Train = 0.9920, Validation = 0.9682)\n",
      "n_estimators = 50, max_depth = 7, min_samples_split = 5, min_samples_leaf = 7 Overall: (Train = 0.9904, Validation = 0.9618)\n",
      "n_estimators = 50, max_depth = 7, min_samples_split = 5, min_samples_leaf = 8 Overall: (Train = 0.9849, Validation = 0.9618)\n",
      "n_estimators = 50, max_depth = 7, min_samples_split = 5, min_samples_leaf = 9 Overall: (Train = 0.9817, Validation = 0.9554)\n",
      "n_estimators = 50, max_depth = 7, min_samples_split = 5, min_samples_leaf = 10 Overall: (Train = 0.9777, Validation = 0.9554)\n",
      "n_estimators = 50, max_depth = 8, min_samples_split = 2, min_samples_leaf = 6 Overall: (Train = 0.9920, Validation = 0.9682)\n",
      "n_estimators = 50, max_depth = 8, min_samples_split = 2, min_samples_leaf = 7 Overall: (Train = 0.9904, Validation = 0.9618)\n",
      "n_estimators = 50, max_depth = 8, min_samples_split = 2, min_samples_leaf = 8 Overall: (Train = 0.9849, Validation = 0.9618)\n",
      "n_estimators = 50, max_depth = 8, min_samples_split = 2, min_samples_leaf = 9 Overall: (Train = 0.9817, Validation = 0.9554)\n",
      "n_estimators = 50, max_depth = 8, min_samples_split = 2, min_samples_leaf = 10 Overall: (Train = 0.9777, Validation = 0.9554)\n",
      "n_estimators = 50, max_depth = 8, min_samples_split = 3, min_samples_leaf = 6 Overall: (Train = 0.9920, Validation = 0.9682)\n",
      "n_estimators = 50, max_depth = 8, min_samples_split = 3, min_samples_leaf = 7 Overall: (Train = 0.9904, Validation = 0.9618)\n",
      "n_estimators = 50, max_depth = 8, min_samples_split = 3, min_samples_leaf = 8 Overall: (Train = 0.9849, Validation = 0.9618)\n",
      "n_estimators = 50, max_depth = 8, min_samples_split = 3, min_samples_leaf = 9 Overall: (Train = 0.9817, Validation = 0.9554)\n",
      "n_estimators = 50, max_depth = 8, min_samples_split = 3, min_samples_leaf = 10 Overall: (Train = 0.9777, Validation = 0.9554)\n",
      "n_estimators = 50, max_depth = 8, min_samples_split = 4, min_samples_leaf = 6 Overall: (Train = 0.9920, Validation = 0.9682)\n",
      "n_estimators = 50, max_depth = 8, min_samples_split = 4, min_samples_leaf = 7 Overall: (Train = 0.9904, Validation = 0.9618)\n",
      "n_estimators = 50, max_depth = 8, min_samples_split = 4, min_samples_leaf = 8 Overall: (Train = 0.9849, Validation = 0.9618)\n",
      "n_estimators = 50, max_depth = 8, min_samples_split = 4, min_samples_leaf = 9 Overall: (Train = 0.9817, Validation = 0.9554)\n",
      "n_estimators = 50, max_depth = 8, min_samples_split = 4, min_samples_leaf = 10 Overall: (Train = 0.9777, Validation = 0.9554)\n",
      "n_estimators = 50, max_depth = 8, min_samples_split = 5, min_samples_leaf = 6 Overall: (Train = 0.9920, Validation = 0.9682)\n",
      "n_estimators = 50, max_depth = 8, min_samples_split = 5, min_samples_leaf = 7 Overall: (Train = 0.9904, Validation = 0.9618)\n",
      "n_estimators = 50, max_depth = 8, min_samples_split = 5, min_samples_leaf = 8 Overall: (Train = 0.9849, Validation = 0.9618)\n",
      "n_estimators = 50, max_depth = 8, min_samples_split = 5, min_samples_leaf = 9 Overall: (Train = 0.9817, Validation = 0.9554)\n",
      "n_estimators = 50, max_depth = 8, min_samples_split = 5, min_samples_leaf = 10 Overall: (Train = 0.9777, Validation = 0.9554)\n",
      "n_estimators = 50, max_depth = 9, min_samples_split = 2, min_samples_leaf = 6 Overall: (Train = 0.9920, Validation = 0.9682)\n",
      "n_estimators = 50, max_depth = 9, min_samples_split = 2, min_samples_leaf = 7 Overall: (Train = 0.9904, Validation = 0.9618)\n",
      "n_estimators = 50, max_depth = 9, min_samples_split = 2, min_samples_leaf = 8 Overall: (Train = 0.9849, Validation = 0.9618)\n",
      "n_estimators = 50, max_depth = 9, min_samples_split = 2, min_samples_leaf = 9 Overall: (Train = 0.9817, Validation = 0.9554)\n",
      "n_estimators = 50, max_depth = 9, min_samples_split = 2, min_samples_leaf = 10 Overall: (Train = 0.9777, Validation = 0.9554)\n",
      "n_estimators = 50, max_depth = 9, min_samples_split = 3, min_samples_leaf = 6 Overall: (Train = 0.9920, Validation = 0.9682)\n",
      "n_estimators = 50, max_depth = 9, min_samples_split = 3, min_samples_leaf = 7 Overall: (Train = 0.9904, Validation = 0.9618)\n",
      "n_estimators = 50, max_depth = 9, min_samples_split = 3, min_samples_leaf = 8 Overall: (Train = 0.9849, Validation = 0.9618)\n",
      "n_estimators = 50, max_depth = 9, min_samples_split = 3, min_samples_leaf = 9 Overall: (Train = 0.9817, Validation = 0.9554)\n",
      "n_estimators = 50, max_depth = 9, min_samples_split = 3, min_samples_leaf = 10 Overall: (Train = 0.9777, Validation = 0.9554)\n",
      "n_estimators = 50, max_depth = 9, min_samples_split = 4, min_samples_leaf = 6 Overall: (Train = 0.9920, Validation = 0.9682)\n",
      "n_estimators = 50, max_depth = 9, min_samples_split = 4, min_samples_leaf = 7 Overall: (Train = 0.9904, Validation = 0.9618)\n",
      "n_estimators = 50, max_depth = 9, min_samples_split = 4, min_samples_leaf = 8 Overall: (Train = 0.9849, Validation = 0.9618)\n",
      "n_estimators = 50, max_depth = 9, min_samples_split = 4, min_samples_leaf = 9 Overall: (Train = 0.9817, Validation = 0.9554)\n",
      "n_estimators = 50, max_depth = 9, min_samples_split = 4, min_samples_leaf = 10 Overall: (Train = 0.9777, Validation = 0.9554)\n",
      "n_estimators = 50, max_depth = 9, min_samples_split = 5, min_samples_leaf = 6 Overall: (Train = 0.9920, Validation = 0.9682)\n",
      "n_estimators = 50, max_depth = 9, min_samples_split = 5, min_samples_leaf = 7 Overall: (Train = 0.9904, Validation = 0.9618)\n",
      "n_estimators = 50, max_depth = 9, min_samples_split = 5, min_samples_leaf = 8 Overall: (Train = 0.9849, Validation = 0.9618)\n",
      "n_estimators = 50, max_depth = 9, min_samples_split = 5, min_samples_leaf = 9 Overall: (Train = 0.9817, Validation = 0.9554)\n",
      "n_estimators = 50, max_depth = 9, min_samples_split = 5, min_samples_leaf = 10 Overall: (Train = 0.9777, Validation = 0.9554)\n",
      "n_estimators = 50, max_depth = 10, min_samples_split = 2, min_samples_leaf = 6 Overall: (Train = 0.9920, Validation = 0.9682)\n",
      "n_estimators = 50, max_depth = 10, min_samples_split = 2, min_samples_leaf = 7 Overall: (Train = 0.9904, Validation = 0.9618)\n",
      "n_estimators = 50, max_depth = 10, min_samples_split = 2, min_samples_leaf = 8 Overall: (Train = 0.9849, Validation = 0.9618)\n",
      "n_estimators = 50, max_depth = 10, min_samples_split = 2, min_samples_leaf = 9 Overall: (Train = 0.9817, Validation = 0.9554)\n",
      "n_estimators = 50, max_depth = 10, min_samples_split = 2, min_samples_leaf = 10 Overall: (Train = 0.9777, Validation = 0.9554)\n",
      "n_estimators = 50, max_depth = 10, min_samples_split = 3, min_samples_leaf = 6 Overall: (Train = 0.9920, Validation = 0.9682)\n",
      "n_estimators = 50, max_depth = 10, min_samples_split = 3, min_samples_leaf = 7 Overall: (Train = 0.9904, Validation = 0.9618)\n",
      "n_estimators = 50, max_depth = 10, min_samples_split = 3, min_samples_leaf = 8 Overall: (Train = 0.9849, Validation = 0.9618)\n",
      "n_estimators = 50, max_depth = 10, min_samples_split = 3, min_samples_leaf = 9 Overall: (Train = 0.9817, Validation = 0.9554)\n",
      "n_estimators = 50, max_depth = 10, min_samples_split = 3, min_samples_leaf = 10 Overall: (Train = 0.9777, Validation = 0.9554)\n",
      "n_estimators = 50, max_depth = 10, min_samples_split = 4, min_samples_leaf = 6 Overall: (Train = 0.9920, Validation = 0.9682)\n",
      "n_estimators = 50, max_depth = 10, min_samples_split = 4, min_samples_leaf = 7 Overall: (Train = 0.9904, Validation = 0.9618)\n",
      "n_estimators = 50, max_depth = 10, min_samples_split = 4, min_samples_leaf = 8 Overall: (Train = 0.9849, Validation = 0.9618)\n",
      "n_estimators = 50, max_depth = 10, min_samples_split = 4, min_samples_leaf = 9 Overall: (Train = 0.9817, Validation = 0.9554)\n",
      "n_estimators = 50, max_depth = 10, min_samples_split = 4, min_samples_leaf = 10 Overall: (Train = 0.9777, Validation = 0.9554)\n",
      "n_estimators = 50, max_depth = 10, min_samples_split = 5, min_samples_leaf = 6 Overall: (Train = 0.9920, Validation = 0.9682)\n",
      "n_estimators = 50, max_depth = 10, min_samples_split = 5, min_samples_leaf = 7 Overall: (Train = 0.9904, Validation = 0.9618)\n",
      "n_estimators = 50, max_depth = 10, min_samples_split = 5, min_samples_leaf = 8 Overall: (Train = 0.9849, Validation = 0.9618)\n",
      "n_estimators = 50, max_depth = 10, min_samples_split = 5, min_samples_leaf = 9 Overall: (Train = 0.9817, Validation = 0.9554)\n",
      "n_estimators = 50, max_depth = 10, min_samples_split = 5, min_samples_leaf = 10 Overall: (Train = 0.9777, Validation = 0.9554)\n"
     ]
    }
   ],
   "source": [
    "# initialize the best validation score to zero\n",
    "best_score = 0 \n",
    "\n",
    "# iterate through various hyperparameters \n",
    "for n_estimators in np.arange(10, 60, 10):\n",
    "    for max_depth in [6, 7, 8, 9, 10]:\n",
    "        for min_samples_split in [2, 3, 4, 5]:\n",
    "            for min_samples_leaf in [6, 7, 8, 9, 10]:\n",
    "                \n",
    "                # create a random forest classifier with current hyperparameters\n",
    "                rfc_gs = RandomForestClassifier(n_estimators = n_estimators, \n",
    "                                                max_depth = max_depth, \n",
    "                                                min_samples_split = min_samples_split,\n",
    "                                                min_samples_leaf = min_samples_leaf,\n",
    "                                                random_state = 42)\n",
    "                \n",
    "                # perform custom cross validation to evaluate the classifier\n",
    "                rfc_cv_scores_gs = custom_cross_validation(5, rfc_gs, X_train_res, y_train_res)\n",
    "                \n",
    "                # display the performance hyperparameters with metrics\n",
    "                print(\"n_estimators = {}, max_depth = {}, min_samples_split = {}, min_samples_leaf = {} Overall: (Train = {:.4f}, Validation = {:.4f})\".format(n_estimators, max_depth, min_samples_split, min_samples_leaf, rfc_cv_scores_gs[0], rfc_cv_scores_gs[1]))\n",
    "                \n",
    "                # update the best score for best hyperparameters\n",
    "                if rfc_cv_scores_gs[1] > best_score:\n",
    "                    best_score = rfc_cv_scores_gs[1]\n",
    "                    best_hyperparameters = {'n_estimators': n_estimators, \n",
    "                                            'max_depth': max_depth,\n",
    "                                            'min_samples_split': min_samples_split,\n",
    "                                            'min_samples_leaf': min_samples_leaf}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best hyperparameters for Random Forest Classifier: {'n_estimators': 30, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 7}\n",
      "The best overall score for Random Forest Classifier: 0.9746\n"
     ]
    }
   ],
   "source": [
    "# display the best hyperparameters and best overall score\n",
    "print(\"The best hyperparameters for Random Forest Classifier: {}\".format(best_hyperparameters))\n",
    "print(\"The best overall score for Random Forest Classifier: {:.4f}\".format(best_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Model Training and Evaluation on Optimized Hyperparameters**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model training and evaluation on a hyperparameter-optimized Random Forest Classifier ensure maximized performance by fine-tuning parameters for optimal accuracy and generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=6, min_samples_leaf=7, n_estimators=30,\n",
       "                       random_state=42)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a random forest classifier with optimized hyperparameters\n",
    "rfc_opt = RandomForestClassifier(n_estimators = 30, \n",
    "                                 max_depth = 6, \n",
    "                                 min_samples_split = 2, \n",
    "                                 min_samples_leaf = 7, \n",
    "                                 random_state = 42)\n",
    "# fitting the classifier to the training data\n",
    "rfc_opt.fit(X_train_res, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making predictions on the training set and testing set\n",
    "rfc_opt_pred_train = rfc_opt.predict(X_train_res)\n",
    "rfc_opt_pred_test = rfc_opt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Training Set\n",
      "=========================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       157\n",
      "           1       0.99      0.99      0.99       157\n",
      "\n",
      "    accuracy                           0.99       314\n",
      "   macro avg       0.99      0.99      0.99       314\n",
      "weighted avg       0.99      0.99      0.99       314\n",
      "\n",
      "Classification Report for Testing Set\n",
      "=========================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91        23\n",
      "           1       0.95      0.95      0.95        40\n",
      "\n",
      "    accuracy                           0.94        63\n",
      "   macro avg       0.93      0.93      0.93        63\n",
      "weighted avg       0.94      0.94      0.94        63\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# display the classification report for the training set and testing set\n",
    "print(\"Classification Report for Training Set\")\n",
    "print(\"=========================================================\")\n",
    "print(classification_report(y_train_res, rfc_opt_pred_train))\n",
    "print(\"Classification Report for Testing Set\")\n",
    "print(\"=========================================================\")\n",
    "print(classification_report(y_test, rfc_opt_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classification report for the optimized Random Forest Classifier reveals strong performance on both the training and testing sets. With precision, recall, and F1-score all consistently high across both classes, the model demonstrates robustness in correctly identifying instances of both classes. The weighted average F1-score of 0.99 for the training set indicates excellent overall performance, while the testing set's weighted average F1-score of 0.94 suggests generalization to unseen data, though slightly lower than the training set. These results signify effective hyperparameter optimization, resulting in a well-generalized model with high accuracy and balanced performance across classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# calculate the ROC curves and AUC scores \n",
    "fpr_train, tpr_train, thresholds_train = roc_curve(y_train_res, rfc_opt_pred_train)\n",
    "fpr_test, tpr_test, thresholds_test = roc_curve(y_test, rfc_opt_pred_test)\n",
    "# calculate the auc scores \n",
    "auc_train = roc_auc_score(y_train_res, rfc_opt_pred_train)\n",
    "auc_test = roc_auc_score(y_test, rfc_opt_pred_test)\n",
    "\n",
    "# create ROC curves \n",
    "plt.figure(figsize = (10, 6))\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.lineplot(x = fpr_train, y = tpr_train, label = \"Training Set (AUC: {:.4f})\".format(auc_train))\n",
    "sns.lineplot(x = fpr_test, y = tpr_test, label = \"Testing Set (AUC: {:.4f})\".format(auc_test))\n",
    "plt.plot([0, 1], [0, 1], 'k--', label = \"No Discrimination\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A high AUC of 0.9936 for the training set indicates excellent discrimination ability, suggesting that the model can effectively differentiate between positive and negative instances in the training data. However, the AUC of 0.9315 for the testing set, while still relatively high, is slightly lower than that of the training set. This discrepancy suggests that while the model performs well on unseen data, there may be some degree of overfitting to the training data. Nonetheless, the testing set's AUC value still indicates strong discriminatory power and suggests that the model's performance generalizes well to new data, albeit with a slight drop in performance compared to the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABAUAAAFgCAYAAADD+MA6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABIKklEQVR4nO3dd3hUZeL28XtCSAgJoWyUFSkmgAKyKIgBpQgKCyKRIhCKEcVVdBEMKCQEAgjSDGBBAcG1LMUEEBUV3R+LKGJB14YUV6SH3iGB9PP+wcustCSc5GSeyXw/e811Me2cZ8bVc3PPc57jsizLEgAAAAAA8Dl+nh4AAAAAAADwDEoBAAAAAAB8FKUAAAAAAAA+ilIAAAAAAAAfRSkAAAAAAICPohQAAAAAAMBHUQrAUbm5uXrjjTfUvXt3denSRZ06dVJSUpKysrKKtM3HH39cHTp00IIFC674/b/88ouGDBlie/8XuvPOO3XzzTcrPT39vMffffdd3XDDDfrkk0/yff+pU6f0wAMPXPb5Ll266OTJk4Uez7Jly9SmTRs9/PDDhX7PH3311Vfq0qWLunTpohYtWqh58+bu+ytWrCj0dt5++23NnTs339cU9z+LgwcPKjY2VlFRUYqKilLPnj3173//u1DvHTBggI4ePVpsYwEA2EN28N3scM4fj8mPPPKIfv/9d1vjupR58+apS5cuuvfee9W5c2dNnTq1UP/fWrJkiRYuXFhs4wCMYgEOGj16tDV48GDr5MmTlmVZVnp6uvX4449bTz/9tO1t7tmzx2rYsKGVk5NTXMMskrZt21pt2rSx3n333fMej4mJsW6//Xbr448/zvf9u3fvtm6++eZiG09MTIz13nvvFcu2XnrpJeuZZ54plm2VhEceecR644033Pe3bNliNW3a1Pr9998LfO/1119vHTlyxMHRAQAKg+xAdnDqmLxixQqrV69e1pkzZyzLsqyMjAzr0UcftaZPn17ge+Pi4qzXXnut2McEmICZAnDM7t279cEHH2jSpEmqUKGCJKl8+fJ65pln1L59e0lnm+6nn35anTt3VlRUlJ577jnl5ORIkv7yl79o5syZ6t27t+688069+eabSktL09/+9jfl5OSoe/fu2rVrl2644YbzfuE9dz89PV1DhgxRly5d1K1bN40ePVp5eXlat26dOnfubGv/l3Pvvfdq+fLl7vt79uzR6dOnFRER4X5s6dKl6tmzp7p27aq2bdtq0aJFkqSRI0cqIyNDXbp0UW5urho2bKgnn3xSHTp00C+//OL+PC+//LKio6OVm5urQ4cOqWXLlvrmm2/OG8ekSZP0yy+/6MUXX9Sbb76Z7+e7cD+FkZqaqjvuuEMDBgxQhw4ddPDgQc2ZM0c9evRQVFSU2rVrp5UrV0qSZs6cqfHjx0s6+4vIzJkz1bdvX7Vt21bPPfecJJ33zyI+Pl7PPvusYmJi1L59ew0cOND9C8rnn3+uqKgodenSRfHx8WrdurVSU1MvGt+hQ4eUkZGhvLw8SVKdOnU0e/ZshYaGSpK2bt2qAQMGuH99Wrp0qfufgST1799f+/btK9R3AQAofmSH0pcdLnfsvdx3feEx+c4779Qvv/yidevWqXfv3ho+fLi6du2qTp06uT/L0aNHNXDgQN19993q06ePhgwZopkzZ140lkOHDik3N1cZGRmSpMDAQCUmJqpdu3aSpKysLE2aNEndunXTvffeq/j4eKWlpWnlypX69NNP9eabbzJbAKWTp1sJlF6ffPKJdd999+X7mhEjRlgTJkyw8vLyrMzMTGvAgAHWq6++alnW2ZZ4/vz5lmVZ1i+//GI1bNjQysjIuKgdv7BNPnf/3XfftQYMGGBZlmXl5ORYo0aNsnbs2GF988031j333GN7/xdq27at9f3331vNmze3Dhw4YFmWZb3yyivW/Pnzrfvvv9/6+OOPrbS0NKtXr17W0aNHLcuyrB9//NH9GS71ef74y8G5z5OTk2P169fPevXVV63+/ftbs2fPvuR3em6fhfl8F/5CcaEL2/7du3db119/vfXdd99ZlmVZqampVkxMjLtx//DDD63OnTtf9N62bdtaU6ZMsSzLsvbv32/95S9/sXbt2nXeP4u4uDgrOjrayszMtLKysqyuXbtaS5cutY4ePWpFRkZamzdvtizLspYtW2Zdf/311u7duy8a71dffWW1aNHCioyMtB577DFr3rx51v79+y3Lsqzs7GyrU6dO1oYNGyzLsqyTJ09ad999t/Xjjz+e9z0DADyH7FC6skN+x97LfdcX/vNp27attX79euubb76x6tevb23atMmyLMv6xz/+YfXr18+yLMsaOnSo9dxzz1mWZVkHDhywWrRoYb300ksXje3kyZPWQw89ZN14441Wr169rMmTJ1vffvut+/mZM2daU6ZMsfLy8izLsqzp06dbY8eOtSyLmQIo3ZgpAMf4+fm5f7G9nDVr1uj++++Xy+VSQECAevfurTVr1rifv+uuuyRJN954o7KysnT69OlC7/+WW27R77//rpiYGM2dO1f9+/dXrVq1HNl/2bJl1bFjR3344YeSpBUrVrh/UZCk4OBgzZkzR59//rleeOEFzZkzJ9/P0rRp04seK1OmjJKSkjRv3jy5XC4NHDiwwO+goM93qf0UxN/fXzfffLMk6dprr9XUqVP1wQcfaNq0aUpOTr7o/Mhzzn2XVatW1Z/+9CedOHHiote0atVKAQEBKlu2rK6//nqdOHFC//nPf1S7dm3Vq1dPktStWzeFhIRcch+33XabPvvsM73yyiu66aabtHr1anXs2FHr16/Xjh07tGvXLiUkJKhLly66//77lZGRoU2bNl3xdwAAcAbZoXRlh/yOvYX5ri9UrVo11a9fX5LUoEEDd5b4/PPPFR0dLUm6+uqr1bFjx0u+v0KFCnr99df18ccfq0ePHjpy5IgeffRRJSUlSZI+++wzffrpp+ratau6dOmif//739q6dWuhPy/grSgF4JhGjRpp27ZtSktLO+/xAwcO6NFHHz1vmvc5eXl57ilq0tlpXZLkcrkkSZZl5bvPPy4UU6NGDa1cuVKPPvqo0tLS9NBDD120cE9x7r9r165avny5fvjhB0VERKhSpUru5/bv36+uXbtqz549uuWWWxQbG5vv5yhfvvwlH9+7d68CAwO1c+fOQi0gVNDnu9x+8hMQECB/f39J0saNG9W7d2+lpaWpRYsW+tvf/nbZ9537LqWz3+elvsty5cpd9JoyZcpc9Fo/v4v/03XkyBGNGzdOLpdLTZs21WOPPaaFCxeqU6dOeu+995Sbm6vQ0FC9//777tvixYt13333XfF3AABwBtmhkvu50pAd8jv2Fua7vtClcoJ09geLP37Pl8oJ0tlFBn/44QfVqFFDPXv2dBcm507LyMvLU0JCgnusS5Ys0Ysvvljozwt4K0oBOKZq1aqKiopSQkKC++CelpamcePGqVKlSipXrpxatmyphQsXyrIsZWVlafHixbr99tuvaD9VqlRxn9d27nx2SVq0aJFGjhypli1bavjw4WrZsqW2bNly3nuLY//n3HTTTcrIyNDzzz+vbt26nffchg0bVKVKFf39739Xq1attHr1aklnD5b+/v7Kzc0tMLScPHlSw4cP19SpU9W5c2eNGjWqwDEV5+e7lO+++04NGzbUQw89pMjISK1atUq5ubnFtn1JatKkiXbs2KFff/1VkvSvf/1LJ0+edIetcypWrKivvvpK//znP93f5ZkzZ7Rv3z41aNBA4eHhCgwM1Pvvvy9J2rdvnzp37qwNGzZIOvtryh9DDwCg5JEd/qc0ZIf8jr35fddXeky+44473GsVHDt2TP/+978vygmSlJGRoenTp+v48ePux7Zv364GDRqc99mzsrKUl5enxMREzZgxw9aYAG9CKQBHjR07VnXq1FHv3r3VpUsX9ezZU3Xq1NGzzz4rSRo9erSOHj3qvoRceHi4HnvssSvax+jRozV+/Hh169ZNmzZt0lVXXSXpbPuem5urTp06qXv37kpLS7vo8j3Fsf8/6tKli7Zv365WrVqd93iLFi1UtWpVdezYUV27dtW+fftUpUoV7dy5U1dddZUaNGigu+++W8eOHcv3c7Zp00YtWrTQE088oV27dhW42E1xf74Lde7cWceOHXN/x+XLl9eJEycu+oWnKCpVqqQZM2YoLi5O3bp109q1a+Xv76+goKDzXufv769//OMf+vHHH3XXXXepc+fO6tWrl1q2bKkePXooICBAs2bN0tKlSxUVFaUBAwboySef1C233CJJat++vfr27avffvut2MYOALhyZIezSkN2yO/Ym993faXH5JEjR2rbtm2KiorSkCFDVK1atfNmFZzz97//Xbfddpt69+6tu+++Wx06dNA333yjF154wf38tddeq27duqlTp06yLEvx8fGSpNatW2v+/Pl69dVXbX0XgMlcVkEVIwB4UFpammbNmqXBgwcrKChIGzdu1MCBA/XFF19c8lcAAADgWxYuXKgGDRqocePGysrKUt++fTV48GDdcccdnh4a4BX8PT0AAMhPSEiIypYtqx49esjf31/+/v564YUXKAQAAICks5cgnjBhgvLy8pSdna2OHTtSCABXgJkCAAAAAAD4KNYUAAAAAADAR1EKAAAAAADgo4xbUyD78DZPDwEwXlC1VgW/CPBxOVl7HN9HUY5ZZcMiinEkvmlT7Xs8PQTAeI12/+TpIQDG8/XMwEwBAAAAAAB8lHEzBQAA8Bp5uZ4eAQAA8AYGZwZKAQAA7LLyPD0CAADgDQzODJQCAADYlWfuAR4AABjE4MxAKQAAgE2Wwa0/AAAwh8mZgVIAAAC7DG79AQCAQQzODJQCAADYZXDrDwAADGJwZuCShAAAAAAA+ChmCgAAYJfBlxcCAAAGMTgzUAoAAGCXwVMBAQCAQQzODJQCAADYZfCiQQAAwCAGZwZKAQAAbDL58kIAAMAcJmcGSgEAAOwyuPUHAAAGMTgzUAoAAGCXwa0/AAAwiMGZgVIAAAC7DF5JGAAAGMTgzODn6QEAAAAAAADPYKYAAAB2GTwVEAAAGMTgzEApAACAXQYvGgQAAAxicGagFAAAwC6DW38AAGAQgzMDpQAAAHYZ3PoDAACDGJwZKAUAALDJssxdSRgAAJjD5MxAKQAAgF0GTwUEAAAGcSgz5ObmavTo0dq+fbtcLpeeeeYZ5eTkaODAgbruuuskSX369FGnTp0uuw1KAQAAAAAAvNDq1aslScnJyVq3bp2ef/553XnnnXrooYc0YMCAQm2DUgAAALsMPj8QAAAYxKHM0K5dO7Vp00aStHfvXoWGhmrDhg3avn27Vq1apVq1aikhIUEhISGX3QalAAAAdnH6AAAAKIwiZIaUlBSlpKS470dHRys6Otp939/fX3FxcVq5cqVeeuklHThwQD179lTDhg01e/ZsvfLKK4qLi7vs9ikFAACwK8/cRYMAAIBBipAZLiwBLmXq1Kl6+umn1atXLyUnJ6tq1aqSpPbt22vChAn5vtfP9sgAAPB1Vp79GwAA8B0OZYb33ntPr776qiQpKChILpdLTzzxhNavXy9J+vrrr3XjjTfmuw1mCgAAYJfDawr8/PPPmjZtmubPn+9+7IMPPtCCBQvc0wgXL16s5ORk+fv76/HHH1fbtm0dHRMAALDBoczw17/+VSNHjlS/fv2Uk5OjhIQEXXPNNZowYYLKli2rsLCwAmcKUAoAAGCXg7/4z5s3T8uXL1dQUJD7sU2bNmnp0qWyLEuSdOjQIc2fP1/vvPOOMjMz1bdvX7Vo0UIBAQGOjQsAANjgUGYoX768XnzxxYseT05OLvQ2OH0AAAC78vLs3wpQs2ZNzZw5033/2LFjmjFjhhISEtyPrV+/Xo0bN1ZAQIAqVKigmjVr6tdff3XkowIAgCJwMDMUFTMFAADwgIJWEu7QoYNSU1MlSbm5uRo1apRGjhypwMBA92vS0tJUoUIF9/3g4GClpaWVwOgBAEBpQSkAAIBdRWjvC7OS8DkbN27Uzp07NW7cOGVmZur333/XxIkT1bx5c6Wnp7tfl56efl5JAAAADFECv/jbRSkAAIBNllUylyRs1KiRPvroI0lSamqqhg0bplGjRunQoUN64YUXlJmZqaysLG3dulXXX399iYwJAAAUXkllBjsoBQAAsMvDrf9VV12lmJgY9e3bV5ZlaejQoeedXgAAAAxh8EwBl3VuCWNDZB/e5ukhAMYLqtbK00MAjJeTtcfxfZxZ/Zrt9wa1/VsxjsQ3bap9j6eHABiv0e6fPD0EwHi+nhmYKQAAgF0Gt/4AAMAgBmcGSgEAAOxy6JrDAACglDE4M/h5egAAAAAAAMAzmCkAAIBdBk8FBAAABjE4M1AKAABgl8FTAQEAgEEMzgyUAgAA2GVw6w8AAAxicGagFAAAwC6DD/AAAMAgBmcGSgEAAOwyeCogAAAwiMGZgVIAAAC7DG79AQCAQQzODJQCAADYZXDrDwAADGJwZvDz9AAAAAAAAIBnMFMAAAC7DJ4KCAAADGJwZqAUAADALoOnAgIAAIMYnBkoBQAAsMvg1h8AABjE4MxAKQAAgF0GH+ABAIBBDM4MlAIAANhlWZ4eAQAA8AYGZwZKAQAA7DK49QcAAAYxODNwSUIAAAAAAHwUMwUAALDL4NYfAAAYxODMQCkAAIBdBl9eCAAAGMTgzEApAACAXQa3/gAAwCAGZwZKAQAA7DJ4JWEAAGAQgzMDpQAAAHYZ3PoDAACDGJwZKAUAALDL4AM8AAAwiMGZgVIAAAC7DF40CAAAGMTgzFDspUB0dLRcLtd5j1mWJZfLpeTk5OLeHQAA8FJkBgAAPK/YS4EZM2YU9yYBADCSlWfuokHegMwAAPAVJmeGYi8Frr32WknSzp079cknnyg7O1uSdPDgQY0fP764dwcAgOcYfH6gNyAzAAB8hkOZITc3V6NHj9b27dvlcrn0zDPPKDAwUPHx8XK5XKpbt67Gjh0rPz+/y27j8s8U0VNPPSVJ+uGHH5Samqrjx487tSsAADzDyrN/gxuZAQBQ6jmUGVavXi1JSk5OVmxsrJ5//nlNnjxZsbGxWrRokSzL0qpVq/LdhmOlQPny5TVw4EBVrVpVU6ZM0eHDh53aFQAAnpFn2b/BjcwAACj1HMoM7dq104QJEyRJe/fuVWhoqDZu3KjIyEhJUuvWrfXVV1/luw3HSgGXy6VDhw4pPT1dp0+f1unTp53aFQAAnpGXZ/9WCD///LNiYmIkSZs3b1bfvn0VExOjhx9+2P0X58WLF6t79+7q1auX+9cCb0NmAACUekXIDCkpKerevbv7lpKSct6m/f39FRcXpwkTJigqKsq9aK8kBQcH69SpU/kOzbFLEj7xxBNauXKlunTponbt2qlLly5O7QoAAM9wcE2BefPmafny5QoKCpIkTZw4UYmJiapfv76Sk5M1b948/e1vf9P8+fP1zjvvKDMzU3379lWLFi0UEBDg2LicQGYAAJR6RcgM0dHRio6Ozvc1U6dO1dNPP61evXopMzPT/Xh6erpCQ0Pzfa9jpcCtt96qW2+9VZJ01113ObUbAABKpZo1a2rmzJkaMWKEpLMr9V999dWSzi4qFBgYqPXr16tx48YKCAhQQECAatasqV9//VWNGjXy5NCvGJkBAAB73nvvPR04cEADBw5UUFCQXC6XGjZsqHXr1qlZs2Zas2aNmjdvnu82HCsFnn/+eS1duvS86w+vXbvWqd0BAFDyLPtrA6SkpJw3/e/CXwE6dOig1NRU9/1zhcAPP/ygBQsWaOHChfriiy9UoUIF92uCg4OVlpZme0yeQmYAAJR6RcgM+fnrX/+qkSNHql+/fsrJyVFCQoJq166txMREzZgxQxEREerQoUO+23CsFPjss8+0evVqr5vCCABAoTk8FfBCK1as0OzZszV37lxVqVJFISEhSk9Pdz+fnp5+XkngLcgMAIBSz6FTDsuXL68XX3zxoscXLFhQ6G04ttBggwYNzjuXAZ6zfuOvevCJERc9/svm/+qBx59WzONPaeioZ5WZmXXF2/5s7TeKfniI+j06VEuXfyxJOpWWrkEjxurBQcPV79Gh+mnD5iJ/BsBkkbc21qqVSzw9DHhCCV594P3339eCBQs0f/581ahRQ5LUqFEjff/998rMzNSpU6e0detWXX/99cX9KR1HZvBS/mVUbdpTui55qsKXzVDIXc3cT1Ud9Ygq97nbg4MDzOLv768333hJn326TF9/+aE6d27v6SGhpBl8xSLHZgrUrVtXLVu2VFhYmHv1w4Kuj4ji9/rCJfrgk08VVC7wvMcty9K4KS/p+YmjVLN6NS1d/on27j+o8FrVC73t7JwcTX1prpJfe1Hlg8rp/seeUpuWzZW87EM1v+VmxUR30/adqRoxboqWvPFycX80wAhPP/W4+vW7T6fTz3h6KPCEAq4dXFxyc3M1ceJEXXPNNRo8eLCks+fhDxkyRDExMerbt68sy9LQoUMVGBhYwNbMQ2bwThW7tFXu8ZPa8fR0+VUMUe0PZ2rbj5t17bSnFHDdtTqyLbXgjQA+ol/f7jpy5JgefGiIKleupO+/+z99+OFKTw8LJamEMoMdjpUCK1as0KpVqwpc6RDOqlHtGr0wabRGjk867/Edu/aoUsUK+mfKu/p92w61vj1S4bWqKzsnR+OTZmrX7r3Ks/I0+JH+imzyvwWr7ojqq88/WCRJ2rZjt2pWr6aKoWenqjZpdKO+/2mDHojupoCAspLOBlmmg6I027ptp3r2ekRvvfGSp4cCT3C4va9evboWL14sSfr2228v+ZpevXqpV69ejo7DaWQG73Ty47U69cmXks5eVtLKyZNf+SAdenGRQu64xcOjA8yy9J0P9c6yjySd/fclJyfHwyNCiSuBX/ztcqwUqFatmoKCgvgLoYe1b9tSe/YduOjxYydO6KdfNith2N9Vs3o1DRo+VjfWq6vtu1JVuWKoJowcquMnTqr/34fr/YWv6rGnEpWRmakTJ0/pwSdGqGrYnxTd7R6FBAe7txlcPkin0tIVWiFEknT4yFHFj39OcU8OLLHPC5S0d99doVpXMMMGpYvl4CUJfQmZwTtZpzNkSfILDlL1VxJ0cMY/lZ16QNmpBygFgAukp5+WJIWEBGtx8lyNGfech0eEkmZyZnCsFNi/f7/at2/vPu/R5XIpOTnZqd3hClWqGKqa1aup9nU1JUktmzXVxl+3aM++A/rh541av+m/ks7+0n/s+AnNmT5B0tmZAm++fPY/Yv/9fbtOnz7t3mb66TMKrXC2JPht63YNHzNFTz/xN93a2LsujQUAhWZw6+9NyAzey/+aMNWYPVrHFnykkx987unhAEarXr2ali55TXPmvKXk5Pc8PRyUNIMzg2OlwOTJk1WuXDmnNo8iqlHtzzp95ox2pe5VzerV9P3PG9Q9qoMCAgJU9aowPdq/tzIyMzX3rWT36QEXiriuhnam7tWJk6dUPqicvv95gx7se5+2bt+pp0ZPUtL4kapXN6KEPxkAwNuQGbxTmT9VUq03n9X+Z2Yr/aufPT0cwGhXXx2mj1cs0pNPjtanq7nkKsziWCkwevRovf32205tHjZ99H+rdfrMGfXs0knjR8ZqxLipsixLN/+lge64PVJZWVkaO/UlPThouNLST6t3987y8/vfRSrOrScgSWX9/TVi8CN6dOgoWZalbvf8VVWvCtOz015RZlaWprw4R5JUIThYM6eOLfHPCgCOM3jRIG9CZvBOYX/vpTIVQxQ2qLfCBvWWJO0aMFaWjasZAaVdfNxgVa5UUaMSntSohCclSfdExSgjI8PDI0OJMTgzuCzLcmQew8MPP6zatWsrPDzc/ZfKwlyPOfvwNieGA5QqQdVaeXoIgPFysvY4vo/08f1svzd4zMJiHIl3s5sZNtW+x+mhAV6v0e6fPD0EwHi+nhkcmynQuHFjSdKRI0ec2gUAAJ5l8KJB3oTMAAAo9QzODI6VAk888YQ+++wzbdmyReHh4WrXrp1TuwIAwDMMXjTIm5AZAAClnsGZwa/gl9gzffp0LVu2TGXLltV7772nqVOnOrUrAAA8w8qzf4MbmQEAUOoZnBkcmynw3XffuS8n1L9/f/Xq1cupXQEA4BkGt/7ehMwAACj1DM4Mjs0UyMnJUd7/P2/Csiy5XC6ndgUAALwYmQEAAM9xbKbAPffcoz59+uimm27S+vXr1alTJ6d2BQCAR1gGLxrkTcgMAIDSzuTMUOylwHvvvSdJqly5sqKiopSZmanOnTsrJCSkuHcFAIBnGTwV0BuQGQAAPsPgzFDspcDWrVvPu29ZlpYtW6Zy5cqpa9euxb07AAA8x+ADvDcgMwAAfIbBmaHYS4GnnnrK/eddu3YpLi5Obdq0UUJCQnHvCgAAz+IqAkVCZgAA+AyDM4NjawosXLhQb731lkaOHKm2bds6tRsAADzH4Nbfm5AZAAClnsGZodhLgQMHDmjkyJGqWLGilixZoooVKxb3LgAAMIJl8AHeG5AZAAC+wuTMUOylwD333KOAgAA1b95c48ePP++56dOnF/fuAADwHIMP8N6AzAAA8BkGZ4ZiLwVmzZpV3JsEAAClEJkBAADPK/ZSIDIysrg3CQCAmQy+5rA3IDMAAHyGwZnBsYUGAQAo9QyeCggAAAxicGagFAAAwC6DD/AAAMAgBmcGSgEAAGyyLHMP8AAAwBwmZwZKAQAA7DK49QcAAAYxODNQCgAAYJfBB3gAAGAQgzODn6cHAAAAAAAAPIOZAgAA2GQZ3PoDAABzmJwZKAUAALDL4AM8AAAwiMGZgVIAAAC78jw9AAAA4BUMzgyUAgAA2GTyVEAAAGAOkzMDpQAAAHYZfIAHAAAGMTgzUAoAAGCXw1MBf/75Z02bNk3z58/Xzp07FR8fL5fLpbp162rs2LHy8/PTyy+/rM8++0z+/v5KSEhQo0aNnB0UAAC4cg5lhuzsbCUkJGjPnj3KysrS448/rmuuuUYDBw7UddddJ0nq06ePOnXqdNltUAoAAGCTk1MB582bp+XLlysoKEiSNHnyZMXGxqpZs2YaM2aMVq1apWrVqunbb7/VkiVLtG/fPg0ePFjvvPOOY2MCAAD2OJUZli9frkqVKikpKUnHjx9X165dNWjQID300EMaMGBAobbh58jIAABAkdSsWVMzZ85039+4caMiIyMlSa1bt9ZXX32l77//Xi1btpTL5VK1atWUm5uro0ePemrIAACghHXs2FFPPvmkJMmyLJUpU0YbNmzQZ599pn79+ikhIUFpaWn5boOZAgAA2FWEqYApKSlKSUlx34+OjlZ0dLT7focOHZSamuq+b1mWXC6XJCk4OFinTp1SWlqaKlWq5H7NucerVKlif2AAAKD4OZQZgoODJUlpaWkaMmSIYmNjlZWVpZ49e6phw4aaPXu2XnnlFcXFxV12+5QCAADYVJSpgBeWAAXx8/vf5L709HSFhoYqJCRE6enp5z1eoUIF22MCAADOcDIz7Nu3T4MGDVLfvn0VFRWlkydPKjQ0VJLUvn17TZgwId/tc/oAAAB25RXhdoUaNGigdevWSZLWrFmjpk2bqkmTJlq7dq3y8vK0d+9e5eXlMUsAAAATOZQZDh8+rAEDBmj48OHq0aOHJOnhhx/W+vXrJUlff/21brzxxny3wUwBAABsshy++sAfxcXFKTExUTNmzFBERIQ6dOigMmXKqGnTpoqOjlZeXp7GjBlTcgMCAACF5lRmmDNnjk6ePKlZs2Zp1qxZkqT4+HhNmjRJZcuWVVhYWIEzBVyWZRl1wcTsw9s8PQTAeEHVWnl6CIDxcrL2OL6PI/fcYfu9f/ro82IciW/aVPseTw8BMF6j3T95egiA8Xw9MzBTAAAAm0pypgAAAPBeJmcG1hQAAAAAAMBHMVMAAAC7DG79AQCAQQzODJQCAADYZPJUQAAAYA6TMwOlAAAANpl8gAcAAOYwOTNQCgAAYJPJB3gAAGAOkzMDpQAAAHZZLk+PAAAAeAODMwOlAAAANpnc+gMAAHOYnBkoBQAAsMnKM7f1BwAA5jA5M/h5egAAAAAAAMAzmCkAAIBNJk8FBAAA5jA5M1AKAABgk2XwokEAAMAcJmcGSgEAAGwyufUHAADmMDkzUAoAAGCTyYsGAQAAc5icGSgFAACwybI8PQIAAOANTM4Mly0Fhg0bJpfr0m3G9OnTHRsQAADewuTWvySRGQAAyJ/JmeGypUDv3r1LchwAAMBLkRkAAPBely0FIiMjJUlpaWmaN2+eDh48qLZt2+qGG24oscEBAGAyk1v/kkRmAAAgfyZnBr+CXpCQkKAaNWpo586dCgsL06hRo0piXAAAGM+y7N9KIzIDAACXZnJmKLAUOH78uHr06CF/f381adJEeXkGX0sBAIASZOW5bN9KIzIDAACXZnJmKNTVB7Zu3SpJ2r9/v8qUKePogAAA8BaWVTr/cl8UZAYAAC5mcmYosBQYPXq0EhIStHXrVg0ZMkRjx44tiXEBAGA8ix/Cz0NmAADg0kzODAWWAtdff71mz56tPXv2qFatWgoNDS2JcQEAYLw8g1t/TyAzAABwaSZnhgJLgaVLl+q1115TnTp1tHXrVg0ePFidOnUqibEBAGA0k6cCegKZAQCASzM5MxRYCiQnJ+v9999XYGCgTp8+rf79+3OABwAAFyEzAADgfQosBSpVqiR//7MvK1euHFMBAQD4/0rrVQTsIjMAAHBpJmeGy5YCw4YNk8vl0tGjR9W9e3fddNNN2rRpk8qVK1eS4wMAwFglce1gb0BmAAAgfyZnhsuWAr17977osc6dOzs6GAAAvInJrX9JIjMAAJA/kzPDZUuByMhISdLx48e1du1a5eTkyLIsHTx40P0cAAC+zOSVhEsSmQEAgPyZnBkKXFPgiSeeUEREhH777TcFBgYqKCioJMYFAIDxTF5J2BPIDAAAXJrJmcGvoBdYlqXx48crPDxcb7zxho4fP14CwwIAwHyWZf9WGpEZAAC4NJMzQ4EzBcqUKaPMzEydOXNGLpdLubm5zo8KAAAflp2drfj4eO3Zs0d+fn6aMGGC/P39FR8fL5fLpbp162rs2LHy8yuw2y9RZAYAALxPgWmiX79+euutt9SiRQvdcccdql69ekmMCwAA4+VZLtu3/Hz++efKyclRcnKyBg0apBdeeEGTJ09WbGysFi1aJMuytGrVqhL6lIVHZgAA4NKcygzFocCZAh06dHD/+e6779bhw4cdHRAAAN6iKOcHpqSkKCUlxX0/Ojpa0dHRkqTw8HDl5uYqLy9PaWlp8vf3108//eRetK9169b68ssv1b59+6J9gGJGZgAA4NKcWlMgOztbCQkJ2rNnj7KysvT444+rTp06VzS7sMBS4I9CQkL04IMPaunSpUUePAAA3q4o5/n9sQS4UPny5bVnzx7dfffdOnbsmObMmaPvvvtOLtfZQBEcHKxTp07Z33kJIDMAAPA/Tq0NsHz5clWqVElJSUk6fvy4unbtqnr16ik2NlbNmjXTmDFjtGrVqnx/SLiiUkA6u4gQAABw7vJCb775plq2bKmnnnpK+/btU//+/ZWdne1+Pj09XaGhoY7suziRGQAAOMupzNCxY0f3TD3LslSmTBlt3LjximYXXnEpcO5XCqcEVWvl6PaB0uDM3i88PQQAcm4qYGhoqMqWLStJqlixonJyctSgQQOtW7dOzZo105o1a9S8eXNH9l2cnM4MjXb/5Oj2gdKAzACYwalTDoODgyVJaWlpGjJkiGJjYzV16tQrml142VJg2LBhFx3MLcvS7t277X0SAABKGada/wcffFAJCQnq27evsrOzNXToUDVs2FCJiYmaMWOGIiIizjt/39PIDAAA5K8omSG/Uw4lad++fRo0aJD69u2rqKgoJSUluZ8rzOzCy5YCvXv3vqLHAQDwNU5Njg8ODtaLL7540eMLFixwaI9FQ2YAACB/TmWGw4cPa8CAARozZoxuu+02Sbri2YWXLQXOnYMAAACQHzIDAACeMWfOHJ08eVKzZs3SrFmzJEmjRo3Ss88+W+jZhVe8pgAAADirJK4dDAAAvJ9TmWH06NEaPXr0RY9fyexCSgEAAGxyaqFBAABQupicGQosBQ4cOKCkpCQdPXpUHTt21A033KCbbrqpJMYGAIDR8jw9AMOQGQAAuDSTM4NfQS9ITEzUfffdp+zsbDVt2lQTJ04siXEBAGA8Sy7bt9KIzAAAwKWZnBkKLAUyMjJ02223yeVyKSIiQoGBgY4PCgAAb5Bn2b+VRmQGAAAuzeTMUODpA4GBgfriiy+Ul5enn376SQEBAc6PCgAAL5BXSn/xt4vMAADApZmcGQqcKTBhwgQtW7ZMx44d0+uvv65x48aVwLAAAIC3ITMAAOB9Cpwp8Oc//1nPP/98SYwFAACvUlrXBrCLzAAAwKWZnBkKLAVatmzp/vPx48dVo0YNffzxx44OCgAAb2DySsKeQGYAAODSTM4MBZYCa9eudf95z549evnllx0dEAAA3sLk1t8TyAwAAFyayZmhwFLgj6699lpt27bNqbEAAOBVTG79PY3MAADA/5icGQosBYYNGyaX62yrcfDgQf3pT39yfFAAAHgDkw/wnkBmAADg0kzODAWWAp06dVJoaKiks5caatiwoeODAgDAG5g8FdATyAwAAFyayZmhwFLgH//4h95+++2SGAsAAF4lz9zju0eQGQAAuDSTM0OBpUDFihX11ltvKTw8XH5+fpLOX10YAABAIjMAAOCNCiwFKleurF9//VW//vqr+zEO8AAASHkGTwX0BDIDAACXZnJmuGwpEBsbqxdeeEGTJ08uyfEAAOA1LE8PwBBkBgAA8mdyZrhsKXD06NGSHAcAAF7H5JWESxKZAQCA/JmcGS5bCuzevVszZsy45HPDhg1zbEAAAHiLPJe5UwFLEpkBAID8mZwZLlsKlCtXTuHh4SU5FgAAvIrJUwFLEpkBAID8mZwZLlsKhIWFqVu3biU5FgAAvIrJUwFLEpkBAID8mZwZ/C73RMOGDUtyHAAAwEuRGQAA8F6XnSkQFxdXkuMAAMDr5Jl7emCJIjMAAJA/kzPDZUsBAACQP5OvOQwAAMxhcmagFAAAwCaTFw0CAADmMDkzUAoAAGCTyVMBAQCAOUzODJQCAADYZPJKwgAAwBwmZwZKAQAAbDJ5KiAAADCHyZmBUgAAAJtMngoIAADMYXJmoBQAAMBAr776qj799FNlZ2erT58+ioyMVHx8vFwul+rWrauxY8fKz8/P08MEAABejjQBAIBNeUW45WfdunX68ccf9fbbb2v+/Pnav3+/Jk+erNjYWC1atEiWZWnVqlUOfSoAAFDcnMoMxYGZAgAA2FSUA3VKSopSUlLc96OjoxUdHS1JWrt2ra6//noNGjRIaWlpGjFihBYvXqzIyEhJUuvWrfXll1+qffv2RRk+AAAoISw0CABAKWQV4fzAP5YAFzp27Jj27t2rOXPmKDU1VY8//rgsy5LLdXaHwcHBOnXqlP2dAwCAElWUzOA0SgEAAGxyqvWvVKmSIiIiFBAQoIiICAUGBmr//v3u59PT0xUaGurQ3gEAQHEzeaYAawoAAGCTU+cH3nLLLfriiy9kWZYOHDigM2fO6LbbbtO6deskSWvWrFHTpk2d+EgAAMABTq8p8PPPPysmJkaStGnTJrVq1UoxMTGKiYnRihUr8n0vMwUAALDJqWsOt23bVt9995169Oghy7I0ZswYVa9eXYmJiZoxY4YiIiLUoUMHh/YOAACKm1OZQZLmzZun5cuXKygoSJK0ceNGPfTQQxowYECh3k8pAACAgUaMGHHRYwsWLPDASAAAgMlq1qypmTNnurPDhg0btH37dq1atUq1atVSQkKCQkJCLvt+Th8AAMCmPJf9GwAA8B1FyQwpKSnq3r27+/bHqxdJUocOHeTv/7/f+xs1aqQRI0Zo4cKFqlGjhl555ZV8x8ZMAQAAbDJ50SAAAGCOomSG/K5YdCnt27d3L0jcvn17TZgwId/XM1MAAACbnF40CAAAlA4lmRkefvhhrV+/XpL09ddf68Ybb8z39cwUAADAJicXDQIAAKVHSWaGcePGacKECSpbtqzCwsIKnClAKQAAgE2sDQAAAArD6cxQvXp1LV68WJJ04403Kjk5udDvpRQAAMAmTgMAAACFYXJmoBQAAMAmTh8AAACFYXJmYKFBAAAAAAB8FDMFAACwKc/o3h8AAJjC5MxAKQAAgE0mnx8IAADMYXJmoBQAAMAmczt/AABgEpMzA6UAAAA2mdz6AwAAc5icGSgFAACwyelrDgMAgNLB5MxAKQAAgE0mLxoEAADMYXJm4JKEAAAAAAD4KGYKAABgk7mdPwAAMInJmYFSAAAAm0xeNAgAAJjD5MxAKQAAgE0mnx8IAADMYXJmoBQAAMAmcw/vAADAJCZnBkoBAABsMnkqIAAAMIfJmYFSAAAAm0yeCggAAMxhcmZw5JKEU6ZMcWKzAAAYxSrCDWeRGQAAvsDkzOBIKfD777/r5MmTTmwaAACUImQGAAA8y5HTB7Zu3apmzZqpSpUqcrlckqS1a9c6sSsAADzG5PMDvQWZAQDgC0zODI6UAqtXr3ZiswAAGMXiRIAiIzMAAHyByZnBkdMH/vvf/+q+++5Ty5Yt1bVrV23atMmJ3QAA4FF5RbjhLDIDAMAXmJwZHJkp8Oyzz2rixImqV6+eNm/erGeeeUbJyclO7AoAAI8xeSVhb0FmAAD4ApMzg2OXJKxXr54kqX79+vL358qHAIDSx9zDu3chMwAASjuTM4Mjpw/4+flp9erVOnXqlD799FMFBAQ4sRsAADwqT5btG84iMwAAfIHJmcGROn7SpEmaOnWqpk+frtq1a2vChAlO7AYlIPLWxpo8KUF3te/p6aEAjlq/8VfNmP263nz5ufMe/2Xzf5X00jxZshRWpbKmjBmhwMAr+0vLZ2u/0ew3Fsm/TBl16/xX9bj3bp1KS1f8+OeUnn5a2dk5Gj7kUd3csH5xfiTAK5AZvJ+/v79emzdD19WqrsDAAE2c/KI+/HClp4cFGCE3N1djp76oHbv2yOWSxgwfrNycXI1Pmqky/mVUq8a1Gh8fKz8/R36rBQrFkVLg2muv1aRJk5SRkeG+vBC8z9NPPa5+/e7T6fQznh4K4KjXFy7RB598qqBygec9blmWxk15Sc9PHKWa1atp6fJPtHf/QYXXql7obWfn5GjqS3OV/NqLKh9UTvc/9pTatGyu5GUfqvktNysmupu270zViHFTtOSNl4v7o8FhTi/+c+TIEXXv3l2vv/66/P39FR8fL5fLpbp162rs2LGlIkSSGbxfv77ddeTIMT340BBVrlxJ33/3f5QCwP/32ZfrJEkL5kzXtz+s10uvviWXn0uPPdRXrW+PVNy4qVrz1bdq07K5h0cKp5m8yLAjpcCIESP0ww8/qEKFCrIsSy6XS++++64Tu4KDtm7bqZ69HtFbb7zk6aEAjqpR7Rq9MGm0Ro5POu/xHbv2qFLFCvpnyrv6fdsOtb49UuG1qis7J0fjk2Zq1+69yrPyNPiR/ops0sj9vjui+urzDxZJkrbt2K2a1aupYmgFSVKTRjfq+5826IHobgoIKCvp7K8ITJn2Tk5eXig7O1tjxoxRuXLlJEmTJ09WbGysmjVrpjFjxmjVqlVq3769Y/svKWQG77f0nQ/1zrKPJEkul0s5OTkeHhFgjrta3647bm8mSdq3/4AqhASrxrXX6MSpNFmWpfTTZ1hLxUeYfElCR/4fuH37dv373/92YtMoQe++u0K1ruAXUcBbtW/bUnv2Hbjo8WMnTuinXzYrYdjfVbN6NQ0aPlY31qur7btSVbliqCaMHKrjJ06q/9+H6/2Fr+qxpxKVkZmpEydP6cEnRqhq2J8U3e0ehQQHu7cZXD5Ip9LSFVohRJJ0+MhRxY9/TnFPDiyxz4viU5TWPyUlRSkpKe770dHRio6Odt+fOnWqevfurblz50qSNm7cqMjISElS69at9eWXX5aKUoDM4P3S009LkkJCgrU4ea7GjHuugHcAvsXfv4wSJkzTqjVfacazo3Ti5Ck9O/0VzX3zbYWEBOvWxo0K3gi8ns/NFGjUqJG2bdumiIgIJzYPACWiUsVQ1axeTbWvqylJatmsqTb+ukV79h3QDz9v1PpN/5V09pf+Y8dPaM70s+dC3xHV1702wX9/367Tp0+7t5l++oxCK5wtCX7bul3Dx0zR00/8jUDgpYrS+l9YAvzRsmXLVKVKFbVq1cpdCpz7FV2SgoODderUKdv7NgmZoXSoXr2ali55TXPmvKXk5Pc8PRzAOJMSn9bhI0fV55GhysjM0D9nTVOdiFp6+50PlPTyPI1+apCnhwiH+dxMgZCQEPXo0UPly5d3P7Z27VondgUAjqlR7c86feaMdqXuVc3q1fT9zxvUPaqDAgICVPWqMD3av7cyMjM1961k9+kBF4q4roZ2pu7ViZOnVD6onL7/eYMe7Huftm7fqadGT1LS+JGqV5e/DHkrp1r/d955Ry6XS19//bU2b96suLg4HT161P18enq6QkNDHdp7ySIzeL+rrw7TxysW6cknR+vT1fyzA/5o+SerdODgYT3yQLTKlQuUn59LFStUUHDw2f/mXRVWRT/+ssnDo0RJ8LmZAuvWrdO3337L+TEAvNJH/7dap8+cUc8unTR+ZKxGjJsqy7J0818a6I7bI5WVlaWxU1/Sg4OGKy39tHp373zegm/n1hOQpLL+/hox+BE9OnSULMtSt3v+qqpXhenZaa8oMytLU16cI0mqEBysmVPHlvhnRdHkWc60/gsXLnT/OSYmRuPGjVNSUpLWrVunZs2aac2aNWrevHQsSkVm8H7xcYNVuVJFjUp4UqMSnpQk3RMVo4yMDA+PDPC8dne0UOKkGer/9+HKyclR3JMDVSm0goaPnSL/Mn7y9y+rZ+Kf9PQwUQKcygzFwWVZxT+6+Ph4DR06VFWrVr3i9/oHXFvcwwFKnTN7v/D0EADjlQ1zfgbG/bW6237vgp3LCvW6c6WAn5+fEhMTlZ2drYiICD377LMqU6aM7f2bgswAOIvMABSstGQGuxyp5b///nvdeeedqly5svsxpgICAHDl5s+f7/7zggULPDgSZ5AZAADwLEdKgZUruTYtAKD0yzN40SBvQWYAAPgCpzPDzz//rGnTpmn+/PnauXOn4uPj5XK5VLduXY0dO/a8U10v5EgpMHLkyIsemzx5shO7AgDAY0xeSdhbkBkAAL7Aycwwb948LV++XEFBQZLOHkdjY2PVrFkzjRkzRqtWrcr3MsaOlAKdOnWSdPbySZs2bdLBgwed2A0AAB5l8krC3oLMAADwBU5mhpo1a2rmzJkaMWKEJGnjxo2KjIyUJLVu3VpffvllyZcCrVq1cv+5devWGjBggBO7AQDAozh9oOjIDAAAX1CUzJCSkqKUlBT3/ejoaEVHR7vvd+jQQampqe77lmXJ5XJJkoKDg3Xq1Kl8t+9IKfDHBYIOHTqkw4cPO7EbAAA8itMHio7MAADwBUXJDBeWAAX54/oB6enpCg0Nzff1xVoKxMbG6oUXXtBHH33kfiwgIECTJk0qzt0AAGAETh+wj8wAAPAlJZkZGjRooHXr1qlZs2Zas2aNmjdvnu/ri7UUOHr0qCQWCAIA+AbLYqaAXWQGAIAvKcnMEBcXp8TERM2YMUMRERHq0KFDvq8v1lJg9+7dmjFjxiWfGzZsWHHuCgAAeDEyAwAAxad69epavHixJCk8PFwLFiwo9HuLtRQoV66cwsPDi3OTAAAYi4UG7SMzAAB8icmZoVhLgbCwMHXr1q04NwkAgLFYU8A+MgMAwJeYnBmKtRRo2LBhcW4OAACjcfUB+8gMAABfYnJmKNZSIC4urjg3BwCA0UyeCmg6MgMAwJeYnBmKtRQAAMCXcPUBAABQGCZnBkoBAABsMvn8QAAAYA6TM4OfpwcAAAAAAAA8g5kCAADYZPKiQQAAwBwmZwZKAQAAbDJ50SAAAGAOkzMDpQAAADaZvGgQAAAwh8mZgVIAAACbTG79AQCAOUzODJQCAADYZPL5gQAAwBwmZwZKAQAAbMozeCogAAAwh8mZgVIAAACbzD28AwAAk5icGfw8PQAAAAAAAOAZzBQAAMAmkxcNAgAA5jA5M1AKAABgk8kHeAAAYA6TMwOlAAAANpl8zWEAAGAOkzMDpQAAADaZ3PoDAABzmJwZKAUAALDJ5GsOAwAAc5icGSgFAACwyeSpgAAAwBwmZwYuSQgAAAAAgI9ipgAAADY5dX5gdna2EhIStGfPHmVlZenxxx9XnTp1FB8fL5fLpbp162rs2LHy86PbBwDAG7CmAAAApZBTUwGXL1+uSpUqKSkpScePH1fXrl1Vr149xcbGqlmzZhozZoxWrVql9u3bO7J/AABQvDh9AACAUihPlu1bfjp27Kgnn3xS0tkQUaZMGW3cuFGRkZGSpNatW+urr75y/PMBAIDi4VRmKA6UAgAA2GQV4X8pKSnq3r27+5aSkuLebnBwsEJCQpSWlqYhQ4YoNjZWlmXJ5XK5nz916pSnPjYAALhCRckMTuP0AQAAbMorwlTA6OhoRUdHX/b5ffv2adCgQerbt6+ioqKUlJTkfi49PV2hoaG29w0AAEpWUTKD05gpAACATU61/ocPH9aAAQM0fPhw9ejRQ5LUoEEDrVu3TpK0Zs0aNW3a1PHPBwAAigczBQAAKIWcav3nzJmjkydPatasWZo1a5YkadSoUXr22Wc1Y8YMRUREqEOHDo7sGwAAFD+TZwq4LMOWQfQPuNbTQwCMd2bvF54eAmC8smERju+j/tWRtt+7+eC3xTgS30RmAApGZgAK5uuZgZkCAADYVBJT+gAAgPczOTNQCgAAYJPJUwEBAIA5TM4MlAIAANhkcusPAADMYXJmoBQAAMAmk1t/AABgDiczQ7du3RQSEiJJql69uiZPnnxF76cUAADAJpNbfwAAYA6nMkNmZqYsy9L8+fNtb4NSAAAAmywrz9NDAAAAXsCpzPDrr7/qzJkzGjBggHJycjRs2DDdfPPNV7QNSgEAAAAAAAyVkpKilJQU9/3o6GhFR0dLksqVK6eHH35YPXv21I4dO/TII4/ok08+kb9/4f+qTykAAIBNeZw+AAAACqEomeGPJcCFwsPDVatWLblcLoWHh6tSpUo6dOiQrrnmmkJv38/2yAAA8HGWZdm+AQAA3+FUZli6dKmmTJkiSTpw4IDS0tJ01VVXXdHYmCkAAIBNzBQAAACF4VRm6NGjh0aOHKk+ffrI5XJp0qRJV3TqgEQpAACAbfziDwAACsOpzBAQEKDp06cXaRuUAgAA2OTkNYcBAEDpYXJmoBQAAMAmp645DAAASheTMwOlAAAANnH6AAAAKAyTMwNXHwAAAAAAwEcxUwAAAJu4+gAAACgMkzMDpQAAADaZPBUQAACYw+TMQCkAAIBNJq8kDAAAzGFyZqAUAADAJpNbfwAAYA6TMwOlAAAANpl8fiAAADCHyZmBUgAAAJtMbv0BAIA5TM4MXJIQAAAAAAAfxUwBAABsMnnRIAAAYA6TMwOlAAAANlkGnx8IAADMYXJmoBQAAMAmk1t/AABgDpMzA6UAAAA2mbxoEAAAMIfJmYFSAAAAm0yeCggAAMxhcmagFAAAwCaTW38AAGAOkzMDpQAAADaZfIAHAADmMDkz+Hl6AAAAAAAAwDOYKQAAgE3mdv4AAMAkJmcGl2XyPAYAAAAAAOAYTh8AAAAAAMBHUQoAAAAAAOCjKAUAAAAAAPBRlAIAAAAAAPgoSgEAAAAAAHwUpQAAAAAAAD6KUgAAAAAAAB9FKeAj1q1bp1tuuUX79u1zPzZt2jQtW7bMsX2mpqaqV69ejm0fcMKUKVMUExOjjh07qk2bNoqJidGQIUM8PSwAKBHkBaDwyAwoLfw9PQCUnICAAI0cOVJvvPGGXC6Xp4cDGCk+Pl6StGzZMm3btk1PP/20h0cEACWLvAAUDpkBpQWlgA9p3ry58vLytHDhQt1///3ux19//XV99NFH8vf3V9OmTTV8+HDNnDlTP/74o06fPq2JEycqPj5e11xzjVJTU3XPPfdoy5Yt2rRpk9q0aaNhw4bp22+/1csvvyzLspSenq7p06erbNmyHvy0QPGJj49Xp06d1Lp1a61Zs0YrVqzQlClT1L59ezVu3Fg7duzQbbfdplOnTmn9+vUKDw9XUlKSUlNTlZCQoNzcXLlcLo0ePVr16tVT27ZtFRERodq1ayshIcHTHw8AzkNeAOwjM8AbUQr4mHHjxqlnz55q1aqVJCk9PV0ff/yxkpOT5e/vr8GDB2v16tWSpIiICI0ePVqpqanavXu3Xn/9dWVkZOiuu+7SmjVrFBQUpLZt22rYsGHasmWLkpKSVLVqVc2ZM0effPKJoqKiPPlRAcft2bNHb731lq666ipFRkZqyZIlSkxM1F133aWTJ0/queee0wMPPKB27dpp8+bNSkhI0LJly7Rv3z4tW7ZMlStX9vRHAIBLIi8AxYvMAJNRCviYypUrKyEhQXFxcWrSpIkyMzN10003uVv6pk2basuWLZKk8PBw9/tq1KihChUqKCAgQGFhYapUqZIkuacVVq1aVRMnTlT58uV14MABNWnSpGQ/GFBCLMty/7lSpUqqVq2aJKl8+fKqU6eOJKlChQrKzMzU1q1bdeutt0qS6tevr/3790s6++8hB3cAJiMvAEVHZoC3YKFBH3TnnXcqPDxc7777rgIDA7V+/Xrl5OTIsix999137oO7n9///u9R0DmFiYmJmjRpkqZMmaKrr776vP8IAt4uICBAhw4dkiRt2rTJ/XhB/17Url1b//nPfyRJmzdvVlhYmKTz/90CAFORF4ArR2aAN2KmgI8aNWqUvvnmGwUHB+vuu+9Wnz59lJeXp1tuuUXt2rXTr7/+ekXbu/fee9WvXz8FBQUpLCxMBw8edGjkQMnr2bOnEhIS9MEHH+i6664r9PtGjBihxMREvf7668rJydHEiROdGyQAOIC8AFwZMgO8kcuiogUAAAAAwCcxHwUAAAAAAB9FKQAAAAAAgI+iFAAAAAAAwEdRCgAAAAAA4KMoBQAAAAAA8FGUAkAhrVu3TrfddptiYmIUExOjXr16af78+ba2NW3aNC1btkybN2/Wyy+/fNnXrVy5UgcOHCjUNtesWaP4+PjzHktNTVWvXr0K9X6nXgsAgK8hM9h7LQDP8Pf0AABv0rx5cz3//POSpKysLHXs2FFdunRRaGiore3Vr19f9evXv+zz//znPzVu3DhVrVrV1vYBAIBnkBkAeAtKAcCmtLQ0+fn5qUyZMoqJiVGVKlV04sQJzZ07V+PGjdPOnTuVl5en2NhYNWvWTP/61780e/ZsValSRdnZ2YqIiNC6deuUnJys559/XkuWLNHbb7+tvLw83XnnnWrUqJE2b96suLg4LVq0SCkpKfrwww/lcrnUqVMnPfDAA9q6dasSEhIUFBSkoKAgVaxYsVBj//bbb/Xyyy/Lsiylp6dr+vTpKlu2rI4eParHHntMR44cUZs2bTRo0CDt27dPiYmJyszMVGBgoCZMmODwNwsAQOlCZgBgMkoB4Ap88803iomJkcvlUtmyZZWYmKjg4GBJUufOndW+fXstWrRIlStX1qRJk3Ts2DHdf//9eu+99zRlyhQtW7ZMlSpV0qOPPnredo8cOaJ58+Zp+fLlCgwM1PTp03Xrrbeqfv36GjdunHbt2qUVK1Zo0aJFkqSHHnpILVu21HPPPachQ4aoRYsWmjt3rrZt21aoz7FlyxYlJSWpatWqmjNnjj755BNFRUXp9OnTSkpKUvny5dWvXz/dddddmjNnjmJiYnTHHXfo66+/1rRp0zR06NDi/WIBAChlyAxkBsBbUAoAV+CPUwEvFB4eLkn67bff9P3332v9+vWSpJycHB06dEgVK1ZU5cqVJUmNGzc+7727d+9W3bp1Va5cOUnS008/fd7zv/32m/bu3asHH3xQknTixAnt3LlTO3bsUKNGjSRJTZo0KfQBvmrVqpo4caLKly+vAwcOqEmTJpKkevXqqUKFCpKkv/zlL9q+fbt+++03vfrqq3rttddkWZb8/fnPBgAABSEzkBkAb8G/qUAxcblckqSIiAj9+c9/1mOPPaaMjAzNnj1bYWFhOnnypI4ePaoqVarol19+0Z///Gf3e2vWrKlt27YpKytLAQEBGjJkiEaNGiWXyyXLshQREaE6derotddek8vl0ptvvqkbbrhBtWvX1o8//qjWrVtrw4YNhR5rYmKiVq5cqZCQEMXFxcmyLEnS1q1blZ6ersDAQK1fv17R0dGKiIjQgAED1KRJE23dulXfffdd8X5xAAD4GDIDAJNQCgDFrHfv3ho9erTuv/9+paWlqW/fvgoICNCYMWP08MMPq2LFihc151WqVNEjjzyi+++/Xy6XS23btlXVqlXVuHFjjRgxQq+//rpuu+029enTR1lZWWrUqJGqVq2q+Ph4xcXF6R//+IeqVKmiwMDAi8azZcsWde/e3X0/Pj5e9957r/r166egoCCFhYXp4MGDkqSKFStq6NChOnr0qDp16qQ6deooLi5O48aNU2ZmpjIyMjRq1Chnv0AAAHwEmQGACVzWuboPAAAAAAD4FD9PDwAAAAAAAHgGpQAAAAAAAD6KUgAAAAAAAB9FKQAAAAAAgI+iFAAAAAAAwEdRCgAAAAAA4KMoBQAAAAAA8FH/DzIsph6eKfMfAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1080x360 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create a confusion matrix for training sets\n",
    "plt.figure(figsize = (15, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "cnf_matrix_train = confusion_matrix(y_train_res, rfc_opt_pred_train)\n",
    "cnf_matrix_train_df = pd.DataFrame(cnf_matrix_train, index = ['Normal', 'Tumor'], columns = ['Normal', 'Tumor'])\n",
    "plt.title(\"Confusion Matrix for Training Set\")\n",
    "sns.heatmap(cnf_matrix_train_df, annot =True)\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "\n",
    "# create a confusion matrix for testing sets\n",
    "plt.subplot(1, 2, 2)\n",
    "cnf_matrix_test = confusion_matrix(y_test, rfc_opt_pred_test)\n",
    "cnf_matrix_test_df = pd.DataFrame(cnf_matrix_test, index = ['Normal', 'Tumor'], columns = ['Normal', 'Tumor'])\n",
    "plt.title(\"Confusion Matrix for Testing Set\")\n",
    "sns.heatmap(cnf_matrix_test_df, annot =True)\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrices provide a detailed breakdown of the performance of the optimized Random Forest Classifier on both the training and testing sets. In the training set, there were 162 true positives (TP) and 162 true negatives (TN), indicating that the model correctly classified instances of both classes. There was only one false positive (FP) and one false negative (FN), indicating a high level of accuracy and balance in classification. Similarly, in the testing set, there were 38 true positives and 21 true negatives, showing the model's ability to correctly identify instances of both classes in unseen data. However, there were two false positives and two false negatives, suggesting a slight decrease in performance compared to the training set. Overall, the results indicate strong performance and generalization of the model to new data, albeit with a small amount of misclassification."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
